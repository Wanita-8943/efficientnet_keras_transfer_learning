{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/%E0%B9%82%E0%B8%AD%E0%B9%80%E0%B8%84_1F_MAE_dataframe_Female_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "fe758649-7031-4954-fa58-f06c9f11db17"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "8f99b4cb-abb7-4509-967d-105b4f5c91f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "b246c361-8646-4918-c996-037c2d7872cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "99ea3ed7-4c50-47dc-f248-d39a7f4a623c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "48a89200-f70c-4086-c869-36cf23cc2742"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 75, 75, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 75, 75, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 75, 75, 32)  288         ['swish_49[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 32)     0           ['swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 1, 1, 8)      264         ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 1, 1, 8)      0           ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 32)     288         ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 32)     0           ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 75, 75, 32)   0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 75, 75, 16)   512         ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 75, 75, 16)  64          ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 75, 75, 96)   1536        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 75, 75, 96)  384         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 75, 75, 96)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 38, 38, 96)  864         ['swish_52[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 38, 38, 96)  384         ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 38, 38, 96)   0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 96)     0           ['swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 1, 1, 4)      388         ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 1, 1, 4)      0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 96)     480         ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 96)     0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 38, 38, 96)   0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 38, 38, 24)   2304        ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 38, 38, 24)  96          ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 38, 38, 144)  3456        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 38, 38, 144)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 38, 38, 144)  1296       ['swish_55[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 38, 38, 144)  576        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 144)    0           ['swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 1, 1, 6)      0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 144)    0           ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 38, 38, 144)  0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 38, 38, 24)  96          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 38, 38, 24)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 38, 38, 24)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 38, 38, 144)  3456        ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 38, 38, 144)  576        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 19, 19, 144)  3600       ['swish_58[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 144)    0           ['swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 1, 1, 6)      0           ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 144)    0           ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 19, 19, 144)  0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 19, 19, 40)  160         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 19, 19, 240)  960        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 19, 19, 240)  6000       ['swish_61[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 240)    0           ['swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 1, 1, 10)     0           ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 240)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 19, 19, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 19, 19, 40)  160         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 19, 19, 240)  9600        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 19, 19, 240)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 10, 10, 240)  2160       ['swish_64[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 240)    0           ['swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 1, 1, 10)     0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 240)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 10, 10, 240)  0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 10, 10, 80)  320         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 10, 10, 480)  4320       ['swish_67[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 480)    0           ['swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 1, 1, 20)     0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 480)    0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 10, 10, 480)  0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 10, 10, 80)  320         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 10, 10, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 10, 10, 480)  4320       ['swish_70[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 480)    0           ['swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 1, 1, 20)     0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 480)    0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 10, 10, 480)  0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 10, 10, 80)  320         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 10, 10, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 10, 10, 480)  12000      ['swish_73[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 480)    0           ['swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 1, 1, 20)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 480)    0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 10, 10, 480)  0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 10, 10, 112)  448        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 10, 10, 672)  16800      ['swish_76[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 672)    0           ['swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_78 (Swish)               (None, 1, 1, 28)     0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_78[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 10, 10, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 10, 10, 112)  448        ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 10, 10, 672)  75264       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_79 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 10, 10, 672)  16800      ['swish_79[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_80 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_26 (Lambda)             (None, 1, 1, 672)    0           ['swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_26[0][0]']              \n",
            "                                                                                                  \n",
            " swish_81 (Swish)               (None, 1, 1, 28)     0           ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_81[0][0]']               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 10, 10, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 10, 10, 112)  448        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 10, 10, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_82 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 5, 5, 672)   16800       ['swish_82[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_83 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1, 1, 672)    0           ['swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            " swish_84 (Swish)               (None, 1, 1, 28)     0           ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_84[0][0]']               \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 5, 5, 672)    0           ['activation_27[0][0]',          \n",
            "                                                                  'swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   768         ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_85 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_85[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_86 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1, 1, 1152)   0           ['swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            " swish_87 (Swish)               (None, 1, 1, 48)     0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_87[0][0]']               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 5, 5, 1152)   0           ['activation_28[0][0]',          \n",
            "                                                                  'swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   768         ['conv2d_116[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_88 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_88[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_89 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_29 (Lambda)             (None, 1, 1, 1152)   0           ['swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_29[0][0]']              \n",
            "                                                                                                  \n",
            " swish_90 (Swish)               (None, 1, 1, 48)     0           ['conv2d_118[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_90[0][0]']               \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 5, 5, 1152)   0           ['activation_29[0][0]',          \n",
            "                                                                  'swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 192)   768         ['conv2d_120[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_91 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_91[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_92 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_30 (Lambda)             (None, 1, 1, 1152)   0           ['swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_30[0][0]']              \n",
            "                                                                                                  \n",
            " swish_93 (Swish)               (None, 1, 1, 48)     0           ['conv2d_122[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_93[0][0]']               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_123[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 5, 5, 1152)   0           ['activation_30[0][0]',          \n",
            "                                                                  'swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   768         ['conv2d_124[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_94 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_94[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_95 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_31 (Lambda)             (None, 1, 1, 1152)   0           ['swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_31[0][0]']              \n",
            "                                                                                                  \n",
            " swish_96 (Swish)               (None, 1, 1, 48)     0           ['conv2d_126[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_96[0][0]']               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_127[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 5, 5, 1152)   0           ['activation_31[0][0]',          \n",
            "                                                                  'swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_128[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_97 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Female125.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "da736246-b438-4a6d-d4df-7cdb781964d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         0         V1.jpg   \n",
              "1           2               1          7  Y07F         0    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         0         V2.jpg   \n",
              "3           4               2          7  Y07F         0    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              65         25  Y25F        18  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F        18  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F        18  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F        18  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F        18  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Female125/train/Y0...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Female125/train/Y0...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Female125/train/Y0...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Female125/train/Y0...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Female125/train/Y0...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Female125/test/Y25...  Female     Lt  \n",
              "2371  /content/drive/My Drive/TVT_Female125/test/Y25...  Female     Lt  \n",
              "2372  /content/drive/My Drive/TVT_Female125/test/Y25...  Female     Lt  \n",
              "2373  /content/drive/My Drive/TVT_Female125/test/Y25...  Female     Lt  \n",
              "2374  /content/drive/My Drive/TVT_Female125/test/Y25...  Female     Lt  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4335df77-e6fc-4f9c-887e-d2cb13885b7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/train/Y0...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/train/Y0...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/train/Y0...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/train/Y0...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/train/Y0...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/test/Y25...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/test/Y25...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/test/Y25...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/test/Y25...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Female125/test/Y25...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4335df77-e6fc-4f9c-887e-d2cb13885b7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4335df77-e6fc-4f9c-887e-d2cb13885b7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4335df77-e6fc-4f9c-887e-d2cb13885b7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Female125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "6244fdfb-4be9-41db-8fe2-0e860e42f306"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Female125/train\n",
            "/content/drive/My Drive/TVT_Female125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "ecf63337-7c48-4606-a018-8a1e709166c4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(lr=2e-6),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "0e21885d-8256-476a-c515-d50c7924e511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-39-90b2ae0efec2>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 37s 288ms/step - loss: 100.5833 - mae: 8.4631 - val_loss: 98.5220 - val_mae: 8.3308\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 97.1091 - mae: 8.2803 - val_loss: 96.9640 - val_mae: 8.2724\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 94.4401 - mae: 8.1272 - val_loss: 92.9357 - val_mae: 8.0455\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 91.0390 - mae: 7.9558 - val_loss: 89.5545 - val_mae: 7.8828\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 25s 281ms/step - loss: 89.0676 - mae: 7.8587 - val_loss: 87.2756 - val_mae: 7.7674\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 86.5204 - mae: 7.7245 - val_loss: 84.8174 - val_mae: 7.6451\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 83.2974 - mae: 7.5557 - val_loss: 82.4727 - val_mae: 7.5131\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 81.4324 - mae: 7.4532 - val_loss: 79.9845 - val_mae: 7.3612\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 78.4826 - mae: 7.2874 - val_loss: 78.5176 - val_mae: 7.2770\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 76.7791 - mae: 7.2067 - val_loss: 75.8486 - val_mae: 7.1641\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 75.0062 - mae: 7.1220 - val_loss: 74.0345 - val_mae: 7.0727\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 72.7308 - mae: 7.0014 - val_loss: 72.1390 - val_mae: 6.9628\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 70.7551 - mae: 6.8946 - val_loss: 68.9574 - val_mae: 6.7946\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 68.7618 - mae: 6.7862 - val_loss: 68.6642 - val_mae: 6.7964\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 66.5122 - mae: 6.6561 - val_loss: 65.6706 - val_mae: 6.6104\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 65.0182 - mae: 6.5767 - val_loss: 64.2230 - val_mae: 6.5399\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 63.4692 - mae: 6.5066 - val_loss: 62.1658 - val_mae: 6.4515\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 61.4744 - mae: 6.4072 - val_loss: 60.9122 - val_mae: 6.3942\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 59.8742 - mae: 6.3215 - val_loss: 59.4466 - val_mae: 6.3050\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 58.5199 - mae: 6.2493 - val_loss: 57.6835 - val_mae: 6.2094\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 56.9145 - mae: 6.1532 - val_loss: 56.2306 - val_mae: 6.1221\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 55.5562 - mae: 6.0848 - val_loss: 53.7001 - val_mae: 5.9744\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 54.1660 - mae: 6.0116 - val_loss: 53.2785 - val_mae: 5.9685\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 52.6517 - mae: 5.9370 - val_loss: 51.5828 - val_mae: 5.8764\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 51.6152 - mae: 5.8862 - val_loss: 51.0702 - val_mae: 5.8671\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 50.3530 - mae: 5.8194 - val_loss: 49.5286 - val_mae: 5.7854\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 48.9743 - mae: 5.7502 - val_loss: 48.3667 - val_mae: 5.7198\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 48.1183 - mae: 5.7074 - val_loss: 47.3408 - val_mae: 5.6557\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 46.2693 - mae: 5.5913 - val_loss: 45.9479 - val_mae: 5.5669\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 45.6653 - mae: 5.5656 - val_loss: 45.5625 - val_mae: 5.5567\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 44.6420 - mae: 5.5081 - val_loss: 44.4460 - val_mae: 5.5073\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 43.7342 - mae: 5.4613 - val_loss: 43.3826 - val_mae: 5.4568\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 42.7633 - mae: 5.4159 - val_loss: 42.5902 - val_mae: 5.4144\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 42.1194 - mae: 5.3924 - val_loss: 41.5929 - val_mae: 5.3602\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 41.2499 - mae: 5.3395 - val_loss: 41.0894 - val_mae: 5.3373\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 40.3715 - mae: 5.2915 - val_loss: 39.9892 - val_mae: 5.2764\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 39.7792 - mae: 5.2608 - val_loss: 39.9125 - val_mae: 5.2796\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 38.9882 - mae: 5.2113 - val_loss: 38.8532 - val_mae: 5.2139\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 38.3611 - mae: 5.1862 - val_loss: 37.7307 - val_mae: 5.1411\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 37.5200 - mae: 5.1429 - val_loss: 36.8350 - val_mae: 5.0944\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 37.1812 - mae: 5.1255 - val_loss: 36.8238 - val_mae: 5.1140\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 36.5923 - mae: 5.0976 - val_loss: 36.3467 - val_mae: 5.0821\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 35.9924 - mae: 5.0700 - val_loss: 35.7149 - val_mae: 5.0402\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 35.4537 - mae: 5.0296 - val_loss: 35.4597 - val_mae: 5.0323\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 34.7422 - mae: 4.9890 - val_loss: 34.8145 - val_mae: 4.9987\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 34.3634 - mae: 4.9623 - val_loss: 34.3910 - val_mae: 4.9747\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 34.1329 - mae: 4.9580 - val_loss: 33.7728 - val_mae: 4.9252\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 33.8195 - mae: 4.9456 - val_loss: 33.2276 - val_mae: 4.9037\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 22s 238ms/step - loss: 33.4448 - mae: 4.9222 - val_loss: 33.5299 - val_mae: 4.9387\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 33.2146 - mae: 4.9200 - val_loss: 32.8383 - val_mae: 4.8888\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 32.7863 - mae: 4.8958 - val_loss: 32.6642 - val_mae: 4.8886\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 32.5246 - mae: 4.8866 - val_loss: 32.5809 - val_mae: 4.8941\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 32.2858 - mae: 4.8717 - val_loss: 32.4901 - val_mae: 4.8855\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 32.1256 - mae: 4.8677 - val_loss: 31.5409 - val_mae: 4.8183\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 20s 216ms/step - loss: 31.8948 - mae: 4.8570 - val_loss: 31.4903 - val_mae: 4.8157\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 31.6010 - mae: 4.8307 - val_loss: 31.5255 - val_mae: 4.8265\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 31.4949 - mae: 4.8259 - val_loss: 31.1654 - val_mae: 4.7942\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 31.2438 - mae: 4.8041 - val_loss: 31.3756 - val_mae: 4.8146\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 31.0302 - mae: 4.7898 - val_loss: 31.0901 - val_mae: 4.7985\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 30.9218 - mae: 4.7812 - val_loss: 30.9129 - val_mae: 4.7914\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 30.6879 - mae: 4.7711 - val_loss: 31.2171 - val_mae: 4.8229\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 30.7580 - mae: 4.7819 - val_loss: 30.4895 - val_mae: 4.7517\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 30.6527 - mae: 4.7762 - val_loss: 30.7188 - val_mae: 4.7871\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 30.6450 - mae: 4.7825 - val_loss: 30.5798 - val_mae: 4.7814\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 30.4354 - mae: 4.7695 - val_loss: 30.6276 - val_mae: 4.7873\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 30.4223 - mae: 4.7736 - val_loss: 30.5275 - val_mae: 4.7827\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 30.3499 - mae: 4.7681 - val_loss: 30.0612 - val_mae: 4.7452\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 30.0846 - mae: 4.7457 - val_loss: 30.3916 - val_mae: 4.7669\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 30.3204 - mae: 4.7705 - val_loss: 30.5735 - val_mae: 4.7948\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 30.1886 - mae: 4.7581 - val_loss: 30.3336 - val_mae: 4.7629\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 30.0853 - mae: 4.7532 - val_loss: 30.2506 - val_mae: 4.7731\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 30.1848 - mae: 4.7598 - val_loss: 30.3826 - val_mae: 4.7773\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 30.1444 - mae: 4.7571 - val_loss: 30.0474 - val_mae: 4.7510\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 30.2169 - mae: 4.7657 - val_loss: 30.2887 - val_mae: 4.7700\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 30.0936 - mae: 4.7505 - val_loss: 29.9710 - val_mae: 4.7492\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 30.0535 - mae: 4.7488 - val_loss: 30.3580 - val_mae: 4.7715\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 30.0678 - mae: 4.7522 - val_loss: 30.3874 - val_mae: 4.7894\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 30.0081 - mae: 4.7474 - val_loss: 30.2610 - val_mae: 4.7713\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 30.1867 - mae: 4.7629 - val_loss: 29.7530 - val_mae: 4.7187\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 30.0459 - mae: 4.7477 - val_loss: 29.8777 - val_mae: 4.7306\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 30.0555 - mae: 4.7484 - val_loss: 30.2335 - val_mae: 4.7684\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 29.8666 - mae: 4.7308 - val_loss: 30.2918 - val_mae: 4.7655\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 30.1024 - mae: 4.7528 - val_loss: 30.0035 - val_mae: 4.7490\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 30.0021 - mae: 4.7442 - val_loss: 29.6872 - val_mae: 4.7076\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 30.0098 - mae: 4.7424 - val_loss: 30.1619 - val_mae: 4.7631\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 29.9637 - mae: 4.7402 - val_loss: 30.2612 - val_mae: 4.7710\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 30.0970 - mae: 4.7498 - val_loss: 30.0640 - val_mae: 4.7495\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 30.0961 - mae: 4.7508 - val_loss: 30.1710 - val_mae: 4.7526\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 29.9310 - mae: 4.7304 - val_loss: 29.8152 - val_mae: 4.7154\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 30.0374 - mae: 4.7401 - val_loss: 29.9658 - val_mae: 4.7357\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 29.9027 - mae: 4.7284 - val_loss: 30.1340 - val_mae: 4.7591\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 29.9315 - mae: 4.7339 - val_loss: 29.8257 - val_mae: 4.7134\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 30.0360 - mae: 4.7422 - val_loss: 30.1407 - val_mae: 4.7457\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 29.8584 - mae: 4.7208 - val_loss: 29.8455 - val_mae: 4.7304\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 25.8863 - mae: 4.2985 - val_loss: 20.9089 - val_mae: 3.8814\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 21.8983 - mae: 3.9006 - val_loss: 23.0325 - val_mae: 3.8216\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 20.0735 - mae: 3.7284 - val_loss: 19.4924 - val_mae: 3.5885\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 19.2023 - mae: 3.6443 - val_loss: 29.4764 - val_mae: 4.3015\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 19.0457 - mae: 3.6220 - val_loss: 18.9352 - val_mae: 3.5131\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 18.6147 - mae: 3.5796 - val_loss: 17.7570 - val_mae: 3.5548\n",
            "Epoch 101/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 17.7118 - mae: 3.4803 - val_loss: 17.0376 - val_mae: 3.4426\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 22s 230ms/step - loss: 17.9879 - mae: 3.5224 - val_loss: 16.8654 - val_mae: 3.4441\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 17.3154 - mae: 3.4635 - val_loss: 23.4124 - val_mae: 3.7936\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 17.5059 - mae: 3.4186 - val_loss: 15.8905 - val_mae: 3.2893\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 16.3210 - mae: 3.3181 - val_loss: 21.0723 - val_mae: 3.5672\n",
            "Epoch 106/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 16.4460 - mae: 3.3160 - val_loss: 16.1709 - val_mae: 3.2805\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 16.5226 - mae: 3.3506 - val_loss: 17.7825 - val_mae: 3.3041\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 16.2537 - mae: 3.2884 - val_loss: 15.1913 - val_mae: 3.2015\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 25s 283ms/step - loss: 16.5034 - mae: 3.4051 - val_loss: 15.0890 - val_mae: 3.2139\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 15.5172 - mae: 3.2851 - val_loss: 14.9741 - val_mae: 3.2050\n",
            "Epoch 111/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 15.5668 - mae: 3.2476 - val_loss: 15.6686 - val_mae: 3.3509\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 15.1990 - mae: 3.2141 - val_loss: 16.9503 - val_mae: 3.2512\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 15.3729 - mae: 3.2301 - val_loss: 15.5457 - val_mae: 3.3427\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 15.9592 - mae: 3.3036 - val_loss: 18.9718 - val_mae: 3.4423\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 15.2963 - mae: 3.2177 - val_loss: 21.7156 - val_mae: 3.6278\n",
            "Epoch 116/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 14.9161 - mae: 3.1878 - val_loss: 19.9170 - val_mae: 3.4623\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 14.6907 - mae: 3.1545 - val_loss: 14.1122 - val_mae: 3.0537\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 15.2776 - mae: 3.2163 - val_loss: 13.6973 - val_mae: 3.0141\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 14.4043 - mae: 3.0957 - val_loss: 15.5390 - val_mae: 3.0909\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 14.2304 - mae: 3.1207 - val_loss: 16.5058 - val_mae: 3.1914\n",
            "Epoch 121/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 14.9139 - mae: 3.1477 - val_loss: 18.9174 - val_mae: 3.3685\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 14.3735 - mae: 3.1120 - val_loss: 15.7306 - val_mae: 3.1099\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 14.4808 - mae: 3.1231 - val_loss: 13.7755 - val_mae: 2.9958\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 14.7892 - mae: 3.1440 - val_loss: 16.4242 - val_mae: 3.1797\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 14.6908 - mae: 3.1350 - val_loss: 13.8070 - val_mae: 3.0391\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 14.3215 - mae: 3.0955 - val_loss: 14.4119 - val_mae: 3.0074\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.8598 - mae: 3.0674 - val_loss: 16.6046 - val_mae: 3.1567\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 14.0377 - mae: 3.0544 - val_loss: 13.4578 - val_mae: 2.9802\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.7285 - mae: 3.0261 - val_loss: 13.4027 - val_mae: 2.9376\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 14.0729 - mae: 3.0513 - val_loss: 15.3005 - val_mae: 3.0652\n",
            "Epoch 131/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.9475 - mae: 3.0561 - val_loss: 15.4625 - val_mae: 3.0613\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 27s 284ms/step - loss: 14.4910 - mae: 3.1122 - val_loss: 21.1552 - val_mae: 3.5036\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 14.2674 - mae: 3.0373 - val_loss: 22.2697 - val_mae: 3.6126\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 14.5321 - mae: 3.0966 - val_loss: 12.7968 - val_mae: 2.9430\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.6050 - mae: 3.0267 - val_loss: 13.9396 - val_mae: 2.9927\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.4864 - mae: 3.0139 - val_loss: 17.6293 - val_mae: 3.2228\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.6077 - mae: 3.0112 - val_loss: 16.1910 - val_mae: 3.0923\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.3227 - mae: 2.9681 - val_loss: 14.7072 - val_mae: 3.0030\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.5316 - mae: 2.9705 - val_loss: 15.4968 - val_mae: 3.0521\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.5700 - mae: 2.9868 - val_loss: 13.6393 - val_mae: 2.9224\n",
            "Epoch 141/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 14.1700 - mae: 3.0666 - val_loss: 13.6288 - val_mae: 2.9289\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 13.2831 - mae: 2.9847 - val_loss: 18.0777 - val_mae: 3.2401\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 14.1027 - mae: 3.0414 - val_loss: 13.9143 - val_mae: 2.9181\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 26s 278ms/step - loss: 13.6131 - mae: 3.0171 - val_loss: 12.2036 - val_mae: 2.8393\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 14.1692 - mae: 3.0214 - val_loss: 16.8001 - val_mae: 3.1289\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - 27s 286ms/step - loss: 13.5217 - mae: 2.9760 - val_loss: 14.0693 - val_mae: 2.9378\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 13.6411 - mae: 3.0105 - val_loss: 12.3616 - val_mae: 2.8766\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.4068 - mae: 2.9674 - val_loss: 17.6462 - val_mae: 3.2412\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 13.6304 - mae: 2.9670 - val_loss: 14.4964 - val_mae: 2.9547\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 14.6836 - mae: 3.0581 - val_loss: 15.3281 - val_mae: 3.0270\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 14.2897 - mae: 3.0592 - val_loss: 28.6961 - val_mae: 4.0979\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.9168 - mae: 3.0129 - val_loss: 14.6163 - val_mae: 2.9623\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.9878 - mae: 2.9338 - val_loss: 14.6369 - val_mae: 2.9704\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.5594 - mae: 2.9964 - val_loss: 11.9735 - val_mae: 2.8107\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.2186 - mae: 2.9587 - val_loss: 16.8993 - val_mae: 3.1525\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 14.0045 - mae: 3.0195 - val_loss: 11.9984 - val_mae: 2.8387\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 12.9500 - mae: 2.9527 - val_loss: 20.4232 - val_mae: 3.4133\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 14.8196 - mae: 3.1176 - val_loss: 11.8187 - val_mae: 2.8298\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 13.7138 - mae: 2.9993 - val_loss: 13.5655 - val_mae: 2.8969\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 14.0466 - mae: 3.0396 - val_loss: 16.3704 - val_mae: 3.1233\n",
            "Epoch 161/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.2921 - mae: 2.9541 - val_loss: 12.2171 - val_mae: 2.8325\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.7736 - mae: 3.0062 - val_loss: 14.8180 - val_mae: 3.0021\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.2821 - mae: 2.9456 - val_loss: 22.4938 - val_mae: 3.6130\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 14.1375 - mae: 3.0209 - val_loss: 12.4851 - val_mae: 2.8193\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.9560 - mae: 2.9917 - val_loss: 12.3246 - val_mae: 2.8684\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 14.2247 - mae: 3.0556 - val_loss: 12.2504 - val_mae: 2.8419\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 14.4498 - mae: 3.0412 - val_loss: 20.8059 - val_mae: 3.4337\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.4139 - mae: 2.9622 - val_loss: 15.9540 - val_mae: 3.0935\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.3620 - mae: 2.9651 - val_loss: 15.8235 - val_mae: 3.0864\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 13.3206 - mae: 2.9681 - val_loss: 13.7974 - val_mae: 2.9473\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - 26s 276ms/step - loss: 13.4412 - mae: 2.9982 - val_loss: 13.8433 - val_mae: 2.9638\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 13.1918 - mae: 2.9561 - val_loss: 12.9087 - val_mae: 2.9070\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.5755 - mae: 2.9862 - val_loss: 13.8661 - val_mae: 2.9628\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.0629 - mae: 2.9362 - val_loss: 26.2875 - val_mae: 3.8361\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.6446 - mae: 2.9042 - val_loss: 15.4778 - val_mae: 3.0266\n",
            "Epoch 176/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.0233 - mae: 2.9195 - val_loss: 15.2518 - val_mae: 3.0372\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.0909 - mae: 2.9393 - val_loss: 22.7615 - val_mae: 3.5722\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.9853 - mae: 3.0389 - val_loss: 14.4386 - val_mae: 2.9850\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 13.4516 - mae: 2.9775 - val_loss: 16.9425 - val_mae: 3.1522\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.9728 - mae: 2.9514 - val_loss: 13.7642 - val_mae: 2.9821\n",
            "Epoch 181/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.1490 - mae: 2.9632 - val_loss: 20.5069 - val_mae: 3.4161\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.9021 - mae: 3.0127 - val_loss: 19.8345 - val_mae: 3.3543\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.8242 - mae: 3.0049 - val_loss: 14.1464 - val_mae: 2.9764\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 13.3831 - mae: 2.9754 - val_loss: 16.3753 - val_mae: 3.1114\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.7589 - mae: 2.8915 - val_loss: 18.8629 - val_mae: 3.2750\n",
            "Epoch 186/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.9319 - mae: 3.0037 - val_loss: 12.4113 - val_mae: 2.8519\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.4650 - mae: 2.9725 - val_loss: 14.5739 - val_mae: 2.9735\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 14.4550 - mae: 3.0473 - val_loss: 18.3818 - val_mae: 3.2853\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 13.5739 - mae: 2.9833 - val_loss: 25.6315 - val_mae: 3.8168\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.0442 - mae: 2.9276 - val_loss: 15.1145 - val_mae: 3.0300\n",
            "Epoch 191/500\n",
            "89/89 [==============================] - 26s 276ms/step - loss: 13.2971 - mae: 2.9630 - val_loss: 17.0987 - val_mae: 3.1612\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.4572 - mae: 2.8886 - val_loss: 17.2933 - val_mae: 3.1716\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.8062 - mae: 2.9834 - val_loss: 15.9558 - val_mae: 3.1232\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.1320 - mae: 2.9617 - val_loss: 16.0292 - val_mae: 3.0845\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 13.7415 - mae: 3.0069 - val_loss: 15.8881 - val_mae: 3.0837\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 14.1962 - mae: 3.0576 - val_loss: 14.0898 - val_mae: 2.9669\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.2378 - mae: 2.9631 - val_loss: 14.7802 - val_mae: 3.0382\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 14.2985 - mae: 3.0193 - val_loss: 13.8767 - val_mae: 2.9817\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 26s 278ms/step - loss: 13.5752 - mae: 2.9900 - val_loss: 17.8955 - val_mae: 3.2303\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.7270 - mae: 2.9979 - val_loss: 14.7664 - val_mae: 3.0339\n",
            "Epoch 201/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.4760 - mae: 2.9621 - val_loss: 13.5917 - val_mae: 2.9483\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 23s 249ms/step - loss: 13.8152 - mae: 3.0253 - val_loss: 12.5673 - val_mae: 2.9168\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.7110 - mae: 2.9956 - val_loss: 14.3291 - val_mae: 2.9900\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 13.6743 - mae: 2.9954 - val_loss: 16.6279 - val_mae: 3.1273\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 13.3886 - mae: 2.9752 - val_loss: 12.3068 - val_mae: 2.8514\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.8933 - mae: 3.0130 - val_loss: 19.2069 - val_mae: 3.3241\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 14.7755 - mae: 3.1219 - val_loss: 18.7882 - val_mae: 3.3026\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 14.1290 - mae: 3.0341 - val_loss: 15.0149 - val_mae: 3.0239\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.8575 - mae: 2.9302 - val_loss: 12.6599 - val_mae: 2.8783\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 13.3887 - mae: 2.9743 - val_loss: 26.3334 - val_mae: 3.8544\n",
            "Epoch 211/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.0367 - mae: 2.9337 - val_loss: 12.3765 - val_mae: 2.8609\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 13.0036 - mae: 2.9418 - val_loss: 13.1074 - val_mae: 2.9118\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 21s 220ms/step - loss: 12.8671 - mae: 2.9218 - val_loss: 20.3772 - val_mae: 3.4153\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.4438 - mae: 2.9774 - val_loss: 14.9488 - val_mae: 3.0127\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 13.5412 - mae: 2.9554 - val_loss: 19.0995 - val_mae: 3.3103\n",
            "Epoch 216/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.1625 - mae: 2.9708 - val_loss: 14.9891 - val_mae: 3.0128\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 14.0561 - mae: 3.0456 - val_loss: 28.9871 - val_mae: 4.1025\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 14.1715 - mae: 3.0339 - val_loss: 19.1546 - val_mae: 3.3354\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.5001 - mae: 3.0000 - val_loss: 16.1801 - val_mae: 3.1005\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.8849 - mae: 2.9907 - val_loss: 14.4565 - val_mae: 2.9753\n",
            "Epoch 221/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 13.7728 - mae: 3.0157 - val_loss: 16.5352 - val_mae: 3.1330\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 13.4226 - mae: 2.9978 - val_loss: 12.4513 - val_mae: 2.8557\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.5639 - mae: 2.9963 - val_loss: 16.0759 - val_mae: 3.0793\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.4046 - mae: 2.9949 - val_loss: 16.1110 - val_mae: 3.0781\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 13.9385 - mae: 3.0318 - val_loss: 22.7380 - val_mae: 3.5835\n",
            "Epoch 226/500\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 13.6268 - mae: 2.9779 - val_loss: 18.5480 - val_mae: 3.2456\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.3932 - mae: 2.9680 - val_loss: 14.1104 - val_mae: 2.9469\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.0158 - mae: 2.9438 - val_loss: 14.4157 - val_mae: 2.9831\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.6796 - mae: 2.9935 - val_loss: 21.4117 - val_mae: 3.5022\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 14.4882 - mae: 3.0515 - val_loss: 23.1551 - val_mae: 3.6594\n",
            "Epoch 231/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.9921 - mae: 2.9322 - val_loss: 18.0765 - val_mae: 3.2309\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.4693 - mae: 2.9561 - val_loss: 25.1875 - val_mae: 3.7993\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.0788 - mae: 2.9147 - val_loss: 20.0754 - val_mae: 3.3890\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 12.9654 - mae: 2.9117 - val_loss: 29.8000 - val_mae: 4.1803\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.4635 - mae: 2.9764 - val_loss: 14.7760 - val_mae: 2.9874\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.3163 - mae: 2.9706 - val_loss: 22.9164 - val_mae: 3.6216\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 16.9590 - mae: 3.2511 - val_loss: 15.7447 - val_mae: 3.0681\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.2111 - mae: 2.9412 - val_loss: 32.9422 - val_mae: 4.3967\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.5240 - mae: 2.9825 - val_loss: 14.9437 - val_mae: 3.0016\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.4886 - mae: 2.9868 - val_loss: 12.5627 - val_mae: 2.8464\n",
            "Epoch 241/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 12.6217 - mae: 2.9025 - val_loss: 18.7613 - val_mae: 3.2791\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.4416 - mae: 2.9682 - val_loss: 15.1076 - val_mae: 3.0342\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.3528 - mae: 2.9824 - val_loss: 29.8707 - val_mae: 4.1542\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.2924 - mae: 2.9661 - val_loss: 22.7606 - val_mae: 3.6265\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.8543 - mae: 3.0250 - val_loss: 14.3129 - val_mae: 2.9341\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 13.7542 - mae: 3.0219 - val_loss: 16.9990 - val_mae: 3.1309\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 13.3298 - mae: 2.9764 - val_loss: 19.5477 - val_mae: 3.3301\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.7582 - mae: 2.9188 - val_loss: 12.5485 - val_mae: 2.8845\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 14.3957 - mae: 3.0475 - val_loss: 12.8899 - val_mae: 2.8478\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 27s 306ms/step - loss: 13.3884 - mae: 2.9655 - val_loss: 16.6715 - val_mae: 3.1237\n",
            "Epoch 251/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.6817 - mae: 2.9814 - val_loss: 17.1745 - val_mae: 3.1565\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.1666 - mae: 2.9610 - val_loss: 15.0809 - val_mae: 3.0119\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.3002 - mae: 2.9568 - val_loss: 12.2798 - val_mae: 2.8436\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.5043 - mae: 2.9775 - val_loss: 12.4219 - val_mae: 2.8608\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.4214 - mae: 2.9425 - val_loss: 12.2252 - val_mae: 2.8396\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.2530 - mae: 2.9674 - val_loss: 17.5977 - val_mae: 3.1884\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 14.2780 - mae: 3.0327 - val_loss: 15.1865 - val_mae: 3.0144\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 26s 275ms/step - loss: 13.3817 - mae: 2.9701 - val_loss: 20.2667 - val_mae: 3.4029\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 13.0027 - mae: 2.9157 - val_loss: 12.9542 - val_mae: 2.8647\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 14.2415 - mae: 3.0594 - val_loss: 15.0388 - val_mae: 2.9928\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 12.5313 - mae: 2.9011 - val_loss: 13.9374 - val_mae: 2.9410\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.6183 - mae: 2.9683 - val_loss: 15.3170 - val_mae: 3.0307\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.8893 - mae: 2.9208 - val_loss: 13.0458 - val_mae: 2.8874\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.5144 - mae: 2.9770 - val_loss: 15.9235 - val_mae: 3.0605\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 13.8283 - mae: 2.9880 - val_loss: 24.1641 - val_mae: 3.7163\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.7599 - mae: 2.8990 - val_loss: 16.8722 - val_mae: 3.1398\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.0459 - mae: 2.9199 - val_loss: 12.6327 - val_mae: 2.8588\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 22s 240ms/step - loss: 13.2457 - mae: 2.9507 - val_loss: 13.5207 - val_mae: 2.8627\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.4488 - mae: 2.9999 - val_loss: 18.6902 - val_mae: 3.2832\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.7008 - mae: 2.9894 - val_loss: 15.0181 - val_mae: 3.0073\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.0337 - mae: 2.9275 - val_loss: 18.7533 - val_mae: 3.3081\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.8439 - mae: 2.9585 - val_loss: 26.9733 - val_mae: 3.9127\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.2699 - mae: 2.9531 - val_loss: 21.8286 - val_mae: 3.5092\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.6285 - mae: 2.8888 - val_loss: 14.2099 - val_mae: 2.9291\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 14.2243 - mae: 3.0442 - val_loss: 33.0268 - val_mae: 4.3861\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 14.1291 - mae: 2.9874 - val_loss: 12.1954 - val_mae: 2.8395\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.6315 - mae: 3.0019 - val_loss: 27.8932 - val_mae: 3.9797\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 13.8340 - mae: 3.0228 - val_loss: 12.3898 - val_mae: 2.8798\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.8997 - mae: 3.0214 - val_loss: 14.8502 - val_mae: 3.0156\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.6841 - mae: 3.0127 - val_loss: 17.0051 - val_mae: 3.1771\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.0384 - mae: 2.9137 - val_loss: 15.1503 - val_mae: 3.0329\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 14.6144 - mae: 3.0821 - val_loss: 14.6084 - val_mae: 2.9626\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 14.2113 - mae: 3.0285 - val_loss: 13.7265 - val_mae: 2.9329\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 13.1666 - mae: 2.9550 - val_loss: 12.9801 - val_mae: 2.8876\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.3802 - mae: 2.9802 - val_loss: 12.9399 - val_mae: 2.8793\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 13.9159 - mae: 3.0345 - val_loss: 18.0050 - val_mae: 3.2228\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.6598 - mae: 2.9983 - val_loss: 15.1629 - val_mae: 3.0258\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 14.0328 - mae: 3.0266 - val_loss: 12.3549 - val_mae: 2.8537\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.2245 - mae: 2.9706 - val_loss: 16.7504 - val_mae: 3.1196\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.8523 - mae: 3.0058 - val_loss: 20.3608 - val_mae: 3.4458\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.4717 - mae: 2.9511 - val_loss: 18.9804 - val_mae: 3.3347\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.4556 - mae: 2.9801 - val_loss: 16.6476 - val_mae: 3.1183\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 14.1610 - mae: 3.0551 - val_loss: 12.4561 - val_mae: 2.8665\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 14.1308 - mae: 3.0122 - val_loss: 12.3820 - val_mae: 2.8588\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.8625 - mae: 2.9112 - val_loss: 16.1531 - val_mae: 3.0691\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 14.0990 - mae: 3.0346 - val_loss: 15.8592 - val_mae: 3.0548\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.0286 - mae: 2.9291 - val_loss: 12.3223 - val_mae: 2.8455\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 15.0262 - mae: 3.0930 - val_loss: 12.4386 - val_mae: 2.8362\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.9304 - mae: 3.0134 - val_loss: 17.4820 - val_mae: 3.1806\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 14.5328 - mae: 3.0950 - val_loss: 13.6002 - val_mae: 2.9197\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.2144 - mae: 2.9807 - val_loss: 12.5048 - val_mae: 2.8814\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.8381 - mae: 3.0237 - val_loss: 17.4805 - val_mae: 3.1616\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.9406 - mae: 3.0026 - val_loss: 13.7270 - val_mae: 2.9534\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.0738 - mae: 2.9510 - val_loss: 17.5061 - val_mae: 3.1539\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 13.8625 - mae: 3.0054 - val_loss: 12.7117 - val_mae: 2.8527\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.1381 - mae: 2.9516 - val_loss: 14.6594 - val_mae: 3.0007\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.6028 - mae: 2.9849 - val_loss: 13.2111 - val_mae: 2.9043\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 26s 294ms/step - loss: 13.7010 - mae: 2.9880 - val_loss: 28.1014 - val_mae: 4.0256\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 14.9489 - mae: 3.0781 - val_loss: 12.5210 - val_mae: 2.9004\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 14.1656 - mae: 3.0703 - val_loss: 12.4825 - val_mae: 2.8615\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.6361 - mae: 2.9934 - val_loss: 14.5555 - val_mae: 2.9739\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.8604 - mae: 3.0002 - val_loss: 19.0668 - val_mae: 3.3016\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.8320 - mae: 2.9986 - val_loss: 12.6432 - val_mae: 2.8402\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 13.1734 - mae: 2.9416 - val_loss: 14.7421 - val_mae: 3.0072\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.6466 - mae: 2.9888 - val_loss: 13.4377 - val_mae: 2.9283\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 13.7205 - mae: 3.0097 - val_loss: 18.9876 - val_mae: 3.2646\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.9765 - mae: 3.0283 - val_loss: 19.3451 - val_mae: 3.3205\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.3059 - mae: 2.9741 - val_loss: 13.7626 - val_mae: 2.9709\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.5724 - mae: 2.9699 - val_loss: 15.5005 - val_mae: 3.0827\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 14.4127 - mae: 3.0104 - val_loss: 17.7464 - val_mae: 3.1810\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 13.2922 - mae: 2.9574 - val_loss: 13.1805 - val_mae: 2.9106\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.8734 - mae: 3.0256 - val_loss: 13.4364 - val_mae: 2.9387\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.8895 - mae: 2.9386 - val_loss: 17.9270 - val_mae: 3.2131\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.3582 - mae: 2.9648 - val_loss: 14.8816 - val_mae: 3.0260\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 14.4514 - mae: 3.1040 - val_loss: 13.9463 - val_mae: 3.0773\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.8971 - mae: 3.0437 - val_loss: 15.6886 - val_mae: 3.0625\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.8629 - mae: 2.9308 - val_loss: 16.3605 - val_mae: 3.1052\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.7972 - mae: 2.9960 - val_loss: 14.5863 - val_mae: 2.9908\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.9443 - mae: 3.0106 - val_loss: 12.7894 - val_mae: 2.9005\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.9716 - mae: 2.9267 - val_loss: 17.6863 - val_mae: 3.1730\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.0520 - mae: 2.9513 - val_loss: 14.2442 - val_mae: 2.9655\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.2063 - mae: 2.9163 - val_loss: 15.2107 - val_mae: 3.0288\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 12.7611 - mae: 2.9119 - val_loss: 16.7307 - val_mae: 3.1271\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 13.4175 - mae: 2.9835 - val_loss: 16.7718 - val_mae: 3.1133\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.6092 - mae: 2.9807 - val_loss: 14.3633 - val_mae: 2.9648\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.7856 - mae: 3.0204 - val_loss: 12.8248 - val_mae: 2.9167\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.5608 - mae: 3.0039 - val_loss: 14.6008 - val_mae: 2.9736\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 14.0300 - mae: 3.0353 - val_loss: 15.3899 - val_mae: 3.0380\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.4116 - mae: 2.9923 - val_loss: 18.9964 - val_mae: 3.2835\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 13.3045 - mae: 2.9481 - val_loss: 22.7301 - val_mae: 3.5799\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 13.2838 - mae: 2.9384 - val_loss: 14.8152 - val_mae: 3.0047\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 14.0402 - mae: 3.0302 - val_loss: 14.6719 - val_mae: 2.9887\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.8807 - mae: 3.0251 - val_loss: 14.8739 - val_mae: 2.9848\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 13.2838 - mae: 2.9325 - val_loss: 14.5803 - val_mae: 3.0022\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 13.6298 - mae: 2.9847 - val_loss: 18.8047 - val_mae: 3.2674\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 14.1049 - mae: 3.0259 - val_loss: 22.2416 - val_mae: 3.5342\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.8712 - mae: 3.0062 - val_loss: 17.5434 - val_mae: 3.1861\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 13.9730 - mae: 2.9950 - val_loss: 30.3809 - val_mae: 4.2096\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 14.1455 - mae: 3.0227 - val_loss: 18.4743 - val_mae: 3.2560\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 13.6097 - mae: 3.0038 - val_loss: 13.4897 - val_mae: 2.9296\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 14.6775 - mae: 3.1357 - val_loss: 20.4416 - val_mae: 3.4079\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.0548 - mae: 2.9327 - val_loss: 18.1978 - val_mae: 3.2195\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 14.1865 - mae: 3.0338 - val_loss: 23.2532 - val_mae: 3.5940\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.4967 - mae: 3.0045 - val_loss: 14.9838 - val_mae: 2.9972\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.4812 - mae: 2.9699 - val_loss: 12.8878 - val_mae: 2.8666\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 13.7097 - mae: 2.9738 - val_loss: 16.4074 - val_mae: 3.0879\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.7643 - mae: 2.9241 - val_loss: 21.0980 - val_mae: 3.4455\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.7610 - mae: 2.9892 - val_loss: 15.1848 - val_mae: 3.0210\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 13.7729 - mae: 3.0177 - val_loss: 22.8596 - val_mae: 3.5654\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.2182 - mae: 2.9585 - val_loss: 16.9797 - val_mae: 3.1640\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.5563 - mae: 2.9915 - val_loss: 14.7351 - val_mae: 2.9924\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 23s 254ms/step - loss: 13.2509 - mae: 2.9609 - val_loss: 20.9716 - val_mae: 3.4094\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 13.5731 - mae: 2.9935 - val_loss: 17.0526 - val_mae: 3.1548\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 12.4643 - mae: 2.8807 - val_loss: 21.4398 - val_mae: 3.4358\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.7000 - mae: 2.9877 - val_loss: 34.0800 - val_mae: 4.4734\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.0431 - mae: 2.9388 - val_loss: 19.5581 - val_mae: 3.3358\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 13.9518 - mae: 2.9943 - val_loss: 14.8619 - val_mae: 2.9951\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 15.3223 - mae: 3.1240 - val_loss: 13.9401 - val_mae: 2.9731\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 13.4431 - mae: 2.9654 - val_loss: 16.0507 - val_mae: 3.0777\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 13.6227 - mae: 3.0280 - val_loss: 17.1342 - val_mae: 3.1567\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 13.4161 - mae: 2.9619 - val_loss: 19.1763 - val_mae: 3.2833\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 13.5795 - mae: 3.0080 - val_loss: 15.2126 - val_mae: 3.0117\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 14.0377 - mae: 2.9838 - val_loss: 16.1594 - val_mae: 3.0487\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.6730 - mae: 2.9992 - val_loss: 17.1424 - val_mae: 3.1754\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.4750 - mae: 2.9440 - val_loss: 26.5709 - val_mae: 3.9094\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.2031 - mae: 2.9344 - val_loss: 28.4305 - val_mae: 4.0421\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.7554 - mae: 2.9735 - val_loss: 18.4545 - val_mae: 3.2240\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 24s 259ms/step - loss: 12.9003 - mae: 2.9149 - val_loss: 16.6764 - val_mae: 3.1142\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 12.8386 - mae: 2.9207 - val_loss: 16.3961 - val_mae: 3.0652\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.6130 - mae: 2.9927 - val_loss: 12.5995 - val_mae: 2.8672\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.6309 - mae: 2.9610 - val_loss: 15.5454 - val_mae: 3.0487\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 14.3875 - mae: 3.0906 - val_loss: 18.2494 - val_mae: 3.2249\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.2245 - mae: 2.9739 - val_loss: 14.3650 - val_mae: 2.9475\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.3037 - mae: 2.9639 - val_loss: 13.6991 - val_mae: 2.8798\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.6914 - mae: 3.0001 - val_loss: 14.5572 - val_mae: 2.9700\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.2536 - mae: 2.9508 - val_loss: 14.2280 - val_mae: 2.9554\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.6414 - mae: 3.0009 - val_loss: 15.0045 - val_mae: 3.0321\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.4722 - mae: 3.0082 - val_loss: 14.0552 - val_mae: 2.9624\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 12.9793 - mae: 2.9326 - val_loss: 12.5725 - val_mae: 2.8771\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.3771 - mae: 2.9863 - val_loss: 11.9759 - val_mae: 2.8052\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.7009 - mae: 3.0072 - val_loss: 14.9786 - val_mae: 3.0334\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.1919 - mae: 2.9546 - val_loss: 13.4028 - val_mae: 2.9141\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 13.0876 - mae: 2.9615 - val_loss: 14.0795 - val_mae: 2.9572\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.0552 - mae: 2.9288 - val_loss: 17.2905 - val_mae: 3.1870\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 22s 231ms/step - loss: 13.9831 - mae: 3.0032 - val_loss: 19.0877 - val_mae: 3.3069\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.3607 - mae: 2.9759 - val_loss: 20.7629 - val_mae: 3.4147\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.7729 - mae: 3.0002 - val_loss: 17.9267 - val_mae: 3.2277\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.1356 - mae: 2.9405 - val_loss: 14.2173 - val_mae: 2.9564\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 13.4320 - mae: 2.9761 - val_loss: 13.5717 - val_mae: 2.9346\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.7735 - mae: 3.0001 - val_loss: 12.5428 - val_mae: 2.8538\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.4910 - mae: 2.9926 - val_loss: 17.9374 - val_mae: 3.2384\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.3454 - mae: 2.9436 - val_loss: 12.2773 - val_mae: 2.8447\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 13.2110 - mae: 2.9757 - val_loss: 15.7262 - val_mae: 3.0374\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.5742 - mae: 2.9671 - val_loss: 13.8040 - val_mae: 2.9400\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 25s 272ms/step - loss: 13.5700 - mae: 2.9577 - val_loss: 13.5427 - val_mae: 2.9361\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 13.7630 - mae: 3.0061 - val_loss: 13.1476 - val_mae: 2.9035\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.6135 - mae: 2.9694 - val_loss: 17.9280 - val_mae: 3.2182\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.4260 - mae: 2.9772 - val_loss: 16.0836 - val_mae: 3.0903\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.2439 - mae: 2.9727 - val_loss: 16.3108 - val_mae: 3.1140\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.9724 - mae: 3.0407 - val_loss: 13.0388 - val_mae: 2.8914\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 20s 217ms/step - loss: 13.1337 - mae: 2.9538 - val_loss: 15.8046 - val_mae: 3.0731\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 13.9078 - mae: 3.0009 - val_loss: 18.6074 - val_mae: 3.2702\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.9793 - mae: 3.0301 - val_loss: 27.6272 - val_mae: 3.9939\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.3877 - mae: 2.9668 - val_loss: 25.8643 - val_mae: 3.8058\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.0096 - mae: 2.9349 - val_loss: 16.4195 - val_mae: 3.1097\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.7260 - mae: 3.0052 - val_loss: 14.7961 - val_mae: 3.0061\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.2662 - mae: 2.9448 - val_loss: 16.2056 - val_mae: 3.0996\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.4630 - mae: 2.9819 - val_loss: 19.3405 - val_mae: 3.3424\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.2525 - mae: 2.9651 - val_loss: 15.2427 - val_mae: 3.0277\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 13.8123 - mae: 3.0208 - val_loss: 15.9244 - val_mae: 3.0594\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 13.5522 - mae: 2.9677 - val_loss: 36.4124 - val_mae: 4.6343\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 14.2829 - mae: 3.0411 - val_loss: 13.7588 - val_mae: 2.9329\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 13.5856 - mae: 3.0120 - val_loss: 20.8583 - val_mae: 3.4760\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 13.8319 - mae: 2.9851 - val_loss: 12.7520 - val_mae: 2.8808\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.6291 - mae: 2.9925 - val_loss: 13.1660 - val_mae: 2.9026\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 13.8235 - mae: 3.0362 - val_loss: 23.2138 - val_mae: 3.6172\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 12.7924 - mae: 2.9036 - val_loss: 13.2975 - val_mae: 2.9098\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 13.7202 - mae: 3.0085 - val_loss: 20.9008 - val_mae: 3.4569\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.5431 - mae: 2.9783 - val_loss: 20.4073 - val_mae: 3.4296\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.4841 - mae: 2.9705 - val_loss: 24.1496 - val_mae: 3.7115\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 22s 240ms/step - loss: 13.4403 - mae: 2.9674 - val_loss: 19.0270 - val_mae: 3.3314\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.1868 - mae: 2.9369 - val_loss: 17.1448 - val_mae: 3.1920\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.9999 - mae: 3.0368 - val_loss: 28.0191 - val_mae: 4.0165\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 22s 239ms/step - loss: 13.6492 - mae: 2.9696 - val_loss: 25.1328 - val_mae: 3.7955\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.3050 - mae: 2.9377 - val_loss: 19.0509 - val_mae: 3.3095\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 22s 232ms/step - loss: 13.7181 - mae: 3.0199 - val_loss: 18.1693 - val_mae: 3.2369\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.2570 - mae: 2.9397 - val_loss: 19.1901 - val_mae: 3.3121\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.8303 - mae: 3.0037 - val_loss: 20.6089 - val_mae: 3.4278\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 13.6881 - mae: 3.0035 - val_loss: 18.0278 - val_mae: 3.2333\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.2521 - mae: 2.9329 - val_loss: 17.9571 - val_mae: 3.2309\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 25s 280ms/step - loss: 13.2506 - mae: 2.9618 - val_loss: 17.4563 - val_mae: 3.1843\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 13.7322 - mae: 3.0073 - val_loss: 15.7613 - val_mae: 3.0766\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.5559 - mae: 2.9637 - val_loss: 13.8230 - val_mae: 2.9240\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.4329 - mae: 2.9800 - val_loss: 18.9583 - val_mae: 3.3184\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 13.0772 - mae: 2.9585 - val_loss: 19.3813 - val_mae: 3.3319\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.6364 - mae: 3.0015 - val_loss: 18.2219 - val_mae: 3.2587\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 12.8377 - mae: 2.9122 - val_loss: 15.9539 - val_mae: 3.0696\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 22s 231ms/step - loss: 13.3423 - mae: 2.9324 - val_loss: 13.6400 - val_mae: 2.9268\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.5334 - mae: 2.9572 - val_loss: 16.6872 - val_mae: 3.1475\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.4346 - mae: 2.9767 - val_loss: 14.8691 - val_mae: 2.9811\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.0169 - mae: 2.9537 - val_loss: 13.0660 - val_mae: 2.9137\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.1541 - mae: 2.9515 - val_loss: 15.9941 - val_mae: 3.0610\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.8255 - mae: 2.9609 - val_loss: 13.1462 - val_mae: 2.8726\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.9216 - mae: 2.9351 - val_loss: 15.0590 - val_mae: 2.9792\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 13.3604 - mae: 2.9698 - val_loss: 14.4229 - val_mae: 2.9379\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.7997 - mae: 3.0018 - val_loss: 12.6936 - val_mae: 2.8804\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 13.4830 - mae: 2.9785 - val_loss: 16.9185 - val_mae: 3.1667\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 13.1166 - mae: 2.9516 - val_loss: 15.6157 - val_mae: 3.0536\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 22s 235ms/step - loss: 13.5210 - mae: 2.9659 - val_loss: 12.5428 - val_mae: 2.9238\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 14.0372 - mae: 3.0179 - val_loss: 12.4238 - val_mae: 2.9053\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 14.0338 - mae: 2.9802 - val_loss: 12.8666 - val_mae: 2.8741\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 13.6175 - mae: 2.9699 - val_loss: 12.7091 - val_mae: 2.8963\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 23s 251ms/step - loss: 13.1813 - mae: 2.9512 - val_loss: 12.9173 - val_mae: 2.8924\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.0252 - mae: 2.9333 - val_loss: 13.2010 - val_mae: 2.9051\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.4990 - mae: 2.9898 - val_loss: 13.6066 - val_mae: 2.9323\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 13.6204 - mae: 3.0148 - val_loss: 12.6014 - val_mae: 2.9066\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.6856 - mae: 3.0224 - val_loss: 14.5099 - val_mae: 2.9732\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.0457 - mae: 2.9374 - val_loss: 14.3103 - val_mae: 2.9683\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.2020 - mae: 2.9693 - val_loss: 12.5958 - val_mae: 2.8908\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 14.5838 - mae: 3.0735 - val_loss: 13.1838 - val_mae: 2.9015\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 13.2553 - mae: 2.9554 - val_loss: 14.2706 - val_mae: 2.9771\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.2324 - mae: 2.9640 - val_loss: 12.7756 - val_mae: 2.9406\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.6300 - mae: 2.9799 - val_loss: 16.3202 - val_mae: 3.0911\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 22s 242ms/step - loss: 12.9783 - mae: 2.9344 - val_loss: 12.7961 - val_mae: 2.9011\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.3231 - mae: 2.9697 - val_loss: 13.1809 - val_mae: 2.8999\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.3868 - mae: 2.9527 - val_loss: 22.1039 - val_mae: 3.5116\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.4638 - mae: 2.9799 - val_loss: 12.3521 - val_mae: 2.8368\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.6212 - mae: 3.0000 - val_loss: 13.4819 - val_mae: 2.8941\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 14.1224 - mae: 3.0502 - val_loss: 15.1623 - val_mae: 3.0091\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 14.0511 - mae: 3.0559 - val_loss: 16.9314 - val_mae: 3.1302\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.9075 - mae: 3.0331 - val_loss: 12.8158 - val_mae: 2.8768\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 13.0505 - mae: 2.9301 - val_loss: 15.3828 - val_mae: 3.0324\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.6395 - mae: 2.9664 - val_loss: 21.7486 - val_mae: 3.5113\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.2595 - mae: 2.9322 - val_loss: 19.6873 - val_mae: 3.3139\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.9722 - mae: 2.9320 - val_loss: 20.7387 - val_mae: 3.3996\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.6852 - mae: 3.0094 - val_loss: 12.1860 - val_mae: 2.8257\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 14.0143 - mae: 3.0393 - val_loss: 18.0097 - val_mae: 3.2354\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.6738 - mae: 3.0155 - val_loss: 23.2964 - val_mae: 3.6155\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.6450 - mae: 2.9979 - val_loss: 15.0922 - val_mae: 2.9948\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.4489 - mae: 2.9688 - val_loss: 12.7289 - val_mae: 2.8890\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.7415 - mae: 3.0139 - val_loss: 15.6073 - val_mae: 3.0356\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.7064 - mae: 2.9905 - val_loss: 14.3395 - val_mae: 2.9596\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.3103 - mae: 2.9800 - val_loss: 24.9935 - val_mae: 3.7420\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.2314 - mae: 2.9802 - val_loss: 12.3895 - val_mae: 2.8585\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 14.1559 - mae: 3.0529 - val_loss: 13.1719 - val_mae: 2.9864\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 14.2401 - mae: 3.0532 - val_loss: 21.3419 - val_mae: 3.4205\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.1909 - mae: 2.9466 - val_loss: 12.3648 - val_mae: 2.8667\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 13.0378 - mae: 2.9485 - val_loss: 13.7314 - val_mae: 2.9510\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 23s 248ms/step - loss: 13.6512 - mae: 2.9905 - val_loss: 18.7102 - val_mae: 3.2777\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 25s 274ms/step - loss: 13.9677 - mae: 2.9981 - val_loss: 12.8511 - val_mae: 2.9270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'mo', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "03263f2b-c8e0-4c07-ca56-355ca55a77da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "8f507fd8-7233-4f74-9830-ffa5d1ff5f4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1_New_MAE_Flimpano_Female18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}