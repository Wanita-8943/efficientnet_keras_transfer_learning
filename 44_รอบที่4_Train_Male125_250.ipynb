{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/44_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%884_Train_Male125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QKBBAXcZMFil"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "I4vbqUrvMU1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3477cdb7-caf3-4ef9-fe77-e07f408c82c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Male_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mIs8btgZMWy7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "8b3e50d9-7582-4b40-a8e7-b9af16d1eacb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07M       VV03.jpg   \n",
              "1           2               1          7  Y07M  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M       VV04.jpg   \n",
              "3           4               2          7  Y07M  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M       VV05.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              77         25  Y25M  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M       J464.jpg   \n",
              "2372      123              78         25  Y25M  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M       J465.jpg   \n",
              "2374      125              79         25  Y25M  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-048b8ffa-694a-4aee-a593-f2c3b52c6db2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-048b8ffa-694a-4aee-a593-f2c3b52c6db2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-048b8ffa-694a-4aee-a593-f2c3b52c6db2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-048b8ffa-694a-4aee-a593-f2c3b52c6db2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ZqFXnmK3MZc9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 473\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "yJZ74hTXMbpZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "id": "BqiFCQPoMt5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcf4525-c101-4757-a59e-8c3725fd69d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 548, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 548 (delta 259), reused 266 (delta 199), pack-reused 184\u001b[K\n",
            "Receiving objects: 100% (548/548), 10.27 MiB | 24.62 MiB/s, done.\n",
            "Resolving deltas: 100% (332/332), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "wVAvRBnuMueC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "B62LaXYGMujs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34e5da9-bf67-43f5-d7f6-bc0df5d8b8ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "pN0MW1soMz3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7695f7-1f38-4c3e-9619-c54c502505c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "aLWDZYExM0Vn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "Pg0E1N9hM-kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d64b3c-8019-4eff-f14a-cf6ff698dfb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 473 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model"
      ],
      "metadata": {
        "id": "vUgDNxYONQe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "metadata": {
        "id": "-hMmmkT2NPMF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/33_รอบที่3_Flimpano_Male125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ],
      "metadata": {
        "id": "r0iHAfjtNV1C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Uw9UdpQDNWdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ca5099-f9c4-4cc1-9a55-5228304b564d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmtsk7QfNabQ",
        "outputId": "1bf5c448-a0ce-4fdb-99ea-6a6883b1c9a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-15-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 180s 2s/step - loss: 2.2106 - acc: 0.2590 - val_loss: 2.6783 - val_acc: 0.1638\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1987 - acc: 0.2590 - val_loss: 2.6750 - val_acc: 0.1616\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.2372 - acc: 0.2477 - val_loss: 2.7015 - val_acc: 0.1552\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.2042 - acc: 0.2520 - val_loss: 2.6997 - val_acc: 0.1552\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.1962 - acc: 0.2690 - val_loss: 2.6921 - val_acc: 0.1509\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 76s 804ms/step - loss: 2.2274 - acc: 0.2456 - val_loss: 2.6860 - val_acc: 0.1595\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.2182 - acc: 0.2498 - val_loss: 2.6911 - val_acc: 0.1552\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.2030 - acc: 0.2661 - val_loss: 2.6689 - val_acc: 0.1487\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 75s 814ms/step - loss: 2.2361 - acc: 0.2548 - val_loss: 2.6908 - val_acc: 0.1444\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 74s 841ms/step - loss: 2.2041 - acc: 0.2463 - val_loss: 2.6957 - val_acc: 0.1552\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 79s 867ms/step - loss: 2.2270 - acc: 0.2342 - val_loss: 2.6962 - val_acc: 0.1552\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.1776 - acc: 0.2456 - val_loss: 2.6989 - val_acc: 0.1509\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 82s 876ms/step - loss: 2.2376 - acc: 0.2612 - val_loss: 2.6982 - val_acc: 0.1552\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.2115 - acc: 0.2520 - val_loss: 2.6882 - val_acc: 0.1466\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 80s 879ms/step - loss: 2.2035 - acc: 0.2633 - val_loss: 2.7045 - val_acc: 0.1509\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2785 - acc: 0.2264 - val_loss: 2.6941 - val_acc: 0.1552\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.1826 - acc: 0.2598 - val_loss: 2.6956 - val_acc: 0.1466\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 2.2415 - acc: 0.2470 - val_loss: 2.7232 - val_acc: 0.1466\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2263 - acc: 0.2505 - val_loss: 2.7108 - val_acc: 0.1466\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 79s 853ms/step - loss: 2.1885 - acc: 0.2640 - val_loss: 2.7038 - val_acc: 0.1444\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.2126 - acc: 0.2484 - val_loss: 2.7131 - val_acc: 0.1509\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 79s 867ms/step - loss: 2.2024 - acc: 0.2626 - val_loss: 2.7263 - val_acc: 0.1487\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.2233 - acc: 0.2583 - val_loss: 2.6909 - val_acc: 0.1466\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 2.2324 - acc: 0.2654 - val_loss: 2.7037 - val_acc: 0.1509\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 78s 857ms/step - loss: 2.1964 - acc: 0.2669 - val_loss: 2.7164 - val_acc: 0.1466\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.1961 - acc: 0.2647 - val_loss: 2.7005 - val_acc: 0.1401\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.2219 - acc: 0.2555 - val_loss: 2.6997 - val_acc: 0.1509\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 81s 886ms/step - loss: 2.1757 - acc: 0.2669 - val_loss: 2.6943 - val_acc: 0.1487\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.2102 - acc: 0.2583 - val_loss: 2.6964 - val_acc: 0.1509\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.2042 - acc: 0.2420 - val_loss: 2.7114 - val_acc: 0.1422\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2067 - acc: 0.2520 - val_loss: 2.7190 - val_acc: 0.1422\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 75s 843ms/step - loss: 2.1990 - acc: 0.2590 - val_loss: 2.6874 - val_acc: 0.1466\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.2103 - acc: 0.2583 - val_loss: 2.7094 - val_acc: 0.1422\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2339 - acc: 0.2505 - val_loss: 2.6895 - val_acc: 0.1530\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.2079 - acc: 0.2527 - val_loss: 2.6992 - val_acc: 0.1530\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.2364 - acc: 0.2356 - val_loss: 2.7147 - val_acc: 0.1487\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.2134 - acc: 0.2484 - val_loss: 2.7234 - val_acc: 0.1401\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 77s 827ms/step - loss: 2.1852 - acc: 0.2711 - val_loss: 2.7068 - val_acc: 0.1401\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.2166 - acc: 0.2470 - val_loss: 2.6976 - val_acc: 0.1573\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.1766 - acc: 0.2640 - val_loss: 2.7070 - val_acc: 0.1422\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 81s 889ms/step - loss: 2.2845 - acc: 0.2328 - val_loss: 2.6947 - val_acc: 0.1552\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 77s 840ms/step - loss: 2.1973 - acc: 0.2570 - val_loss: 2.7127 - val_acc: 0.1509\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1761 - acc: 0.2647 - val_loss: 2.7172 - val_acc: 0.1552\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 79s 870ms/step - loss: 2.1704 - acc: 0.2569 - val_loss: 2.6981 - val_acc: 0.1530\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.1821 - acc: 0.2612 - val_loss: 2.7045 - val_acc: 0.1509\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2195 - acc: 0.2562 - val_loss: 2.7233 - val_acc: 0.1487\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 77s 828ms/step - loss: 2.1710 - acc: 0.2576 - val_loss: 2.7114 - val_acc: 0.1487\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 75s 816ms/step - loss: 2.1666 - acc: 0.2541 - val_loss: 2.6906 - val_acc: 0.1466\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 79s 868ms/step - loss: 2.1652 - acc: 0.2654 - val_loss: 2.6957 - val_acc: 0.1444\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.1826 - acc: 0.2690 - val_loss: 2.7172 - val_acc: 0.1422\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.2142 - acc: 0.2477 - val_loss: 2.7073 - val_acc: 0.1422\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 79s 872ms/step - loss: 2.1517 - acc: 0.2576 - val_loss: 2.7042 - val_acc: 0.1530\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.1777 - acc: 0.2661 - val_loss: 2.6903 - val_acc: 0.1509\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.2044 - acc: 0.2590 - val_loss: 2.7070 - val_acc: 0.1401\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 80s 878ms/step - loss: 2.1862 - acc: 0.2555 - val_loss: 2.7166 - val_acc: 0.1422\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.1932 - acc: 0.2534 - val_loss: 2.7050 - val_acc: 0.1509\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.1945 - acc: 0.2590 - val_loss: 2.6997 - val_acc: 0.1487\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 80s 875ms/step - loss: 2.1882 - acc: 0.2491 - val_loss: 2.6931 - val_acc: 0.1444\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1694 - acc: 0.2484 - val_loss: 2.7083 - val_acc: 0.1379\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.2237 - acc: 0.2548 - val_loss: 2.7003 - val_acc: 0.1595\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 81s 891ms/step - loss: 2.2007 - acc: 0.2555 - val_loss: 2.6787 - val_acc: 0.1573\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.1700 - acc: 0.2640 - val_loss: 2.7051 - val_acc: 0.1573\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.1996 - acc: 0.2505 - val_loss: 2.7041 - val_acc: 0.1573\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 81s 889ms/step - loss: 2.1841 - acc: 0.2598 - val_loss: 2.7119 - val_acc: 0.1466\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1330 - acc: 0.2740 - val_loss: 2.7247 - val_acc: 0.1552\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.1848 - acc: 0.2406 - val_loss: 2.7081 - val_acc: 0.1444\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 80s 874ms/step - loss: 2.2281 - acc: 0.2619 - val_loss: 2.6929 - val_acc: 0.1616\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.2113 - acc: 0.2406 - val_loss: 2.7186 - val_acc: 0.1509\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.1982 - acc: 0.2626 - val_loss: 2.6997 - val_acc: 0.1509\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 81s 884ms/step - loss: 2.1584 - acc: 0.2669 - val_loss: 2.7107 - val_acc: 0.1444\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.2311 - acc: 0.2498 - val_loss: 2.6921 - val_acc: 0.1509\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2021 - acc: 0.2527 - val_loss: 2.6892 - val_acc: 0.1487\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 80s 877ms/step - loss: 2.1996 - acc: 0.2385 - val_loss: 2.6758 - val_acc: 0.1466\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.1725 - acc: 0.2647 - val_loss: 2.6890 - val_acc: 0.1379\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.1957 - acc: 0.2520 - val_loss: 2.6925 - val_acc: 0.1422\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.2003 - acc: 0.2555 - val_loss: 2.6963 - val_acc: 0.1444\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.1815 - acc: 0.2598 - val_loss: 2.7163 - val_acc: 0.1336\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.1933 - acc: 0.2576 - val_loss: 2.6995 - val_acc: 0.1422\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.1771 - acc: 0.2626 - val_loss: 2.6874 - val_acc: 0.1401\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.2222 - acc: 0.2427 - val_loss: 2.7189 - val_acc: 0.1444\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 73s 808ms/step - loss: 2.2048 - acc: 0.2803 - val_loss: 2.7437 - val_acc: 0.1336\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.1782 - acc: 0.2577 - val_loss: 2.7121 - val_acc: 0.1487\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.1420 - acc: 0.2818 - val_loss: 2.7112 - val_acc: 0.1379\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1525 - acc: 0.2697 - val_loss: 2.7062 - val_acc: 0.1444\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.1874 - acc: 0.2605 - val_loss: 2.7123 - val_acc: 0.1401\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.1421 - acc: 0.2725 - val_loss: 2.7193 - val_acc: 0.1466\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.2033 - acc: 0.2541 - val_loss: 2.7123 - val_acc: 0.1422\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 79s 862ms/step - loss: 2.1783 - acc: 0.2711 - val_loss: 2.7279 - val_acc: 0.1422\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.1661 - acc: 0.2732 - val_loss: 2.6845 - val_acc: 0.1552\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.1673 - acc: 0.2732 - val_loss: 2.7127 - val_acc: 0.1444\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.1718 - acc: 0.2704 - val_loss: 2.7017 - val_acc: 0.1466\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.2047 - acc: 0.2555 - val_loss: 2.7104 - val_acc: 0.1530\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 78s 859ms/step - loss: 2.1620 - acc: 0.2633 - val_loss: 2.7058 - val_acc: 0.1379\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.1903 - acc: 0.2612 - val_loss: 2.7282 - val_acc: 0.1466\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.1583 - acc: 0.2725 - val_loss: 2.7321 - val_acc: 0.1573\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2199 - acc: 0.2520 - val_loss: 2.7143 - val_acc: 0.1487\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.1434 - acc: 0.2839 - val_loss: 2.7286 - val_acc: 0.1509\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.1399 - acc: 0.2598 - val_loss: 2.7270 - val_acc: 0.1444\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 79s 869ms/step - loss: 2.2048 - acc: 0.2512 - val_loss: 2.7131 - val_acc: 0.1466\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 75s 816ms/step - loss: 2.1445 - acc: 0.2583 - val_loss: 2.7058 - val_acc: 0.1509\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.1848 - acc: 0.2661 - val_loss: 2.7446 - val_acc: 0.1466\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.1567 - acc: 0.2583 - val_loss: 2.7197 - val_acc: 0.1336\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.1962 - acc: 0.2527 - val_loss: 2.7168 - val_acc: 0.1487\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.2100 - acc: 0.2463 - val_loss: 2.6982 - val_acc: 0.1444\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.1814 - acc: 0.2740 - val_loss: 2.7064 - val_acc: 0.1509\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.1260 - acc: 0.2633 - val_loss: 2.7465 - val_acc: 0.1401\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 78s 857ms/step - loss: 2.1605 - acc: 0.2697 - val_loss: 2.7258 - val_acc: 0.1487\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 75s 816ms/step - loss: 2.1355 - acc: 0.2711 - val_loss: 2.7064 - val_acc: 0.1466\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.2139 - acc: 0.2583 - val_loss: 2.7168 - val_acc: 0.1573\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.1628 - acc: 0.2541 - val_loss: 2.7205 - val_acc: 0.1509\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.1689 - acc: 0.2732 - val_loss: 2.7285 - val_acc: 0.1487\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.1386 - acc: 0.2725 - val_loss: 2.7186 - val_acc: 0.1444\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 79s 839ms/step - loss: 2.1392 - acc: 0.2832 - val_loss: 2.7181 - val_acc: 0.1466\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 2.1971 - acc: 0.2654 - val_loss: 2.7383 - val_acc: 0.1466\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.1475 - acc: 0.2889 - val_loss: 2.7176 - val_acc: 0.1487\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1551 - acc: 0.2754 - val_loss: 2.7268 - val_acc: 0.1487\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.1807 - acc: 0.2811 - val_loss: 2.7065 - val_acc: 0.1509\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2118 - acc: 0.2725 - val_loss: 2.7243 - val_acc: 0.1487\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.1927 - acc: 0.2747 - val_loss: 2.7237 - val_acc: 0.1422\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.1901 - acc: 0.2626 - val_loss: 2.7126 - val_acc: 0.1444\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.1880 - acc: 0.2598 - val_loss: 2.7290 - val_acc: 0.1401\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.1714 - acc: 0.2612 - val_loss: 2.7088 - val_acc: 0.1466\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.1955 - acc: 0.2612 - val_loss: 2.7382 - val_acc: 0.1422\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.1433 - acc: 0.2789 - val_loss: 2.7505 - val_acc: 0.1336\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.1739 - acc: 0.2612 - val_loss: 2.7439 - val_acc: 0.1444\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1651 - acc: 0.2725 - val_loss: 2.7492 - val_acc: 0.1444\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2041 - acc: 0.2520 - val_loss: 2.7474 - val_acc: 0.1358\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.1692 - acc: 0.2704 - val_loss: 2.7348 - val_acc: 0.1401\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 77s 840ms/step - loss: 2.1655 - acc: 0.2683 - val_loss: 2.7444 - val_acc: 0.1422\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 78s 850ms/step - loss: 2.1752 - acc: 0.2740 - val_loss: 2.7266 - val_acc: 0.1595\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.1835 - acc: 0.2527 - val_loss: 2.7363 - val_acc: 0.1444\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.1967 - acc: 0.2619 - val_loss: 2.7166 - val_acc: 0.1422\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 78s 859ms/step - loss: 2.1589 - acc: 0.2768 - val_loss: 2.7027 - val_acc: 0.1487\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 2.1674 - acc: 0.2605 - val_loss: 2.7280 - val_acc: 0.1401\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.1468 - acc: 0.2789 - val_loss: 2.7110 - val_acc: 0.1530\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.1988 - acc: 0.2590 - val_loss: 2.7469 - val_acc: 0.1422\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 80s 881ms/step - loss: 2.2144 - acc: 0.2548 - val_loss: 2.7549 - val_acc: 0.1422\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 80s 875ms/step - loss: 2.1446 - acc: 0.2683 - val_loss: 2.7364 - val_acc: 0.1466\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 79s 866ms/step - loss: 2.1750 - acc: 0.2633 - val_loss: 2.7102 - val_acc: 0.1552\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.1959 - acc: 0.2576 - val_loss: 2.7246 - val_acc: 0.1444\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.1669 - acc: 0.2619 - val_loss: 2.7329 - val_acc: 0.1530\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.1832 - acc: 0.2711 - val_loss: 2.7164 - val_acc: 0.1509\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2156 - acc: 0.2669 - val_loss: 2.7378 - val_acc: 0.1293\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.2044 - acc: 0.2633 - val_loss: 2.7143 - val_acc: 0.1401\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.2101 - acc: 0.2498 - val_loss: 2.7225 - val_acc: 0.1466\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.1639 - acc: 0.2654 - val_loss: 2.7214 - val_acc: 0.1530\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.1496 - acc: 0.2853 - val_loss: 2.7468 - val_acc: 0.1401\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.1564 - acc: 0.2740 - val_loss: 2.7292 - val_acc: 0.1466\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 78s 835ms/step - loss: 2.1724 - acc: 0.2633 - val_loss: 2.7111 - val_acc: 0.1466\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.1326 - acc: 0.2633 - val_loss: 2.7437 - val_acc: 0.1422\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 76s 839ms/step - loss: 2.1925 - acc: 0.2583 - val_loss: 2.7187 - val_acc: 0.1466\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 76s 840ms/step - loss: 2.1943 - acc: 0.2654 - val_loss: 2.7180 - val_acc: 0.1466\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.1430 - acc: 0.2619 - val_loss: 2.7259 - val_acc: 0.1509\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.1503 - acc: 0.2669 - val_loss: 2.7347 - val_acc: 0.1401\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.1766 - acc: 0.2740 - val_loss: 2.7274 - val_acc: 0.1573\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 78s 850ms/step - loss: 2.1747 - acc: 0.2704 - val_loss: 2.7262 - val_acc: 0.1444\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1857 - acc: 0.2626 - val_loss: 2.7541 - val_acc: 0.1379\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.1242 - acc: 0.2867 - val_loss: 2.7350 - val_acc: 0.1401\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 77s 836ms/step - loss: 2.1522 - acc: 0.2619 - val_loss: 2.7381 - val_acc: 0.1422\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.1608 - acc: 0.2661 - val_loss: 2.7381 - val_acc: 0.1444\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1924 - acc: 0.2633 - val_loss: 2.7198 - val_acc: 0.1444\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.1510 - acc: 0.2768 - val_loss: 2.7210 - val_acc: 0.1336\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.1551 - acc: 0.2775 - val_loss: 2.7386 - val_acc: 0.1466\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.1285 - acc: 0.2754 - val_loss: 2.7418 - val_acc: 0.1336\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.2029 - acc: 0.2768 - val_loss: 2.7460 - val_acc: 0.1401\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.1715 - acc: 0.2590 - val_loss: 2.7195 - val_acc: 0.1358\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.2238 - acc: 0.2477 - val_loss: 2.7234 - val_acc: 0.1466\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.1336 - acc: 0.2896 - val_loss: 2.7137 - val_acc: 0.1358\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.1571 - acc: 0.2874 - val_loss: 2.7208 - val_acc: 0.1358\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.1736 - acc: 0.2775 - val_loss: 2.7320 - val_acc: 0.1401\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.1974 - acc: 0.2505 - val_loss: 2.7453 - val_acc: 0.1401\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.1156 - acc: 0.2718 - val_loss: 2.7293 - val_acc: 0.1487\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1553 - acc: 0.2633 - val_loss: 2.7443 - val_acc: 0.1422\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.1727 - acc: 0.2740 - val_loss: 2.7386 - val_acc: 0.1315\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1936 - acc: 0.2370 - val_loss: 2.7574 - val_acc: 0.1315\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.1655 - acc: 0.2512 - val_loss: 2.7495 - val_acc: 0.1358\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.1644 - acc: 0.2576 - val_loss: 2.7390 - val_acc: 0.1358\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.1314 - acc: 0.2839 - val_loss: 2.7307 - val_acc: 0.1315\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.1681 - acc: 0.2683 - val_loss: 2.7221 - val_acc: 0.1379\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.1480 - acc: 0.2576 - val_loss: 2.7367 - val_acc: 0.1228\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.1352 - acc: 0.2718 - val_loss: 2.7419 - val_acc: 0.1336\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.1790 - acc: 0.2718 - val_loss: 2.7397 - val_acc: 0.1401\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.1134 - acc: 0.2952 - val_loss: 2.7293 - val_acc: 0.1315\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.1918 - acc: 0.2633 - val_loss: 2.7236 - val_acc: 0.1401\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.1676 - acc: 0.2704 - val_loss: 2.7127 - val_acc: 0.1358\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.1499 - acc: 0.2825 - val_loss: 2.7148 - val_acc: 0.1401\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 2.1774 - acc: 0.2534 - val_loss: 2.7223 - val_acc: 0.1422\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.1558 - acc: 0.2903 - val_loss: 2.7127 - val_acc: 0.1336\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.2129 - acc: 0.2633 - val_loss: 2.6974 - val_acc: 0.1336\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.1174 - acc: 0.2889 - val_loss: 2.7345 - val_acc: 0.1336\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.1488 - acc: 0.2463 - val_loss: 2.7215 - val_acc: 0.1444\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.1203 - acc: 0.2725 - val_loss: 2.7558 - val_acc: 0.1401\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.1631 - acc: 0.2647 - val_loss: 2.7545 - val_acc: 0.1401\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.1948 - acc: 0.2520 - val_loss: 2.7319 - val_acc: 0.1401\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.1626 - acc: 0.2740 - val_loss: 2.7388 - val_acc: 0.1401\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.1197 - acc: 0.2803 - val_loss: 2.7469 - val_acc: 0.1336\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.1342 - acc: 0.2803 - val_loss: 2.7551 - val_acc: 0.1401\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1305 - acc: 0.2768 - val_loss: 2.7653 - val_acc: 0.1401\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1487 - acc: 0.2654 - val_loss: 2.7258 - val_acc: 0.1466\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.1171 - acc: 0.2974 - val_loss: 2.7397 - val_acc: 0.1358\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.2133 - acc: 0.2534 - val_loss: 2.7397 - val_acc: 0.1315\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.1616 - acc: 0.2640 - val_loss: 2.7235 - val_acc: 0.1379\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.1899 - acc: 0.2583 - val_loss: 2.7324 - val_acc: 0.1379\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 73s 826ms/step - loss: 2.1676 - acc: 0.2825 - val_loss: 2.7489 - val_acc: 0.1422\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.1597 - acc: 0.2761 - val_loss: 2.7509 - val_acc: 0.1379\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.1704 - acc: 0.2775 - val_loss: 2.7398 - val_acc: 0.1379\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.1667 - acc: 0.2768 - val_loss: 2.7414 - val_acc: 0.1379\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.1258 - acc: 0.2775 - val_loss: 2.7372 - val_acc: 0.1336\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1449 - acc: 0.2775 - val_loss: 2.7255 - val_acc: 0.1466\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.2210 - acc: 0.2562 - val_loss: 2.7316 - val_acc: 0.1379\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.1608 - acc: 0.2669 - val_loss: 2.7248 - val_acc: 0.1509\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.1667 - acc: 0.2562 - val_loss: 2.7351 - val_acc: 0.1509\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.1554 - acc: 0.2619 - val_loss: 2.7546 - val_acc: 0.1401\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.1735 - acc: 0.2385 - val_loss: 2.7376 - val_acc: 0.1336\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.1566 - acc: 0.2796 - val_loss: 2.7476 - val_acc: 0.1336\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.2012 - acc: 0.2690 - val_loss: 2.7482 - val_acc: 0.1401\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.1404 - acc: 0.2825 - val_loss: 2.7217 - val_acc: 0.1444\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.1535 - acc: 0.2683 - val_loss: 2.7213 - val_acc: 0.1466\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.1285 - acc: 0.2711 - val_loss: 2.7241 - val_acc: 0.1422\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1210 - acc: 0.2839 - val_loss: 2.7458 - val_acc: 0.1422\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.1419 - acc: 0.2654 - val_loss: 2.7721 - val_acc: 0.1401\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.1345 - acc: 0.2683 - val_loss: 2.7509 - val_acc: 0.1401\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.1378 - acc: 0.2676 - val_loss: 2.7244 - val_acc: 0.1422\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.1559 - acc: 0.2704 - val_loss: 2.7060 - val_acc: 0.1379\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.1384 - acc: 0.2725 - val_loss: 2.7161 - val_acc: 0.1422\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 2.1846 - acc: 0.2839 - val_loss: 2.7308 - val_acc: 0.1358\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.1288 - acc: 0.2903 - val_loss: 2.7063 - val_acc: 0.1401\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.1354 - acc: 0.2640 - val_loss: 2.7163 - val_acc: 0.1466\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1720 - acc: 0.2633 - val_loss: 2.7198 - val_acc: 0.1444\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.1665 - acc: 0.2725 - val_loss: 2.7096 - val_acc: 0.1422\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.1329 - acc: 0.2647 - val_loss: 2.7139 - val_acc: 0.1466\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.0772 - acc: 0.2825 - val_loss: 2.7260 - val_acc: 0.1401\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.1496 - acc: 0.2605 - val_loss: 2.7251 - val_acc: 0.1466\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1507 - acc: 0.2654 - val_loss: 2.7265 - val_acc: 0.1573\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1495 - acc: 0.2740 - val_loss: 2.7203 - val_acc: 0.1487\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.1384 - acc: 0.2683 - val_loss: 2.7171 - val_acc: 0.1401\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.1717 - acc: 0.2633 - val_loss: 2.7468 - val_acc: 0.1379\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1581 - acc: 0.2818 - val_loss: 2.7315 - val_acc: 0.1444\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.1737 - acc: 0.2576 - val_loss: 2.7448 - val_acc: 0.1422\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.1604 - acc: 0.2676 - val_loss: 2.7303 - val_acc: 0.1379\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.1702 - acc: 0.2761 - val_loss: 2.7441 - val_acc: 0.1466\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.1217 - acc: 0.2725 - val_loss: 2.7271 - val_acc: 0.1379\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 2.1033 - acc: 0.2931 - val_loss: 2.7278 - val_acc: 0.1422\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.1368 - acc: 0.2725 - val_loss: 2.7509 - val_acc: 0.1444\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.1148 - acc: 0.2768 - val_loss: 2.7472 - val_acc: 0.1487\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 73s 789ms/step - loss: 2.1686 - acc: 0.2754 - val_loss: 2.7312 - val_acc: 0.1379\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 77s 840ms/step - loss: 2.1454 - acc: 0.2704 - val_loss: 2.7265 - val_acc: 0.1379\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.1309 - acc: 0.2818 - val_loss: 2.7558 - val_acc: 0.1466\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.1149 - acc: 0.2853 - val_loss: 2.7156 - val_acc: 0.1336\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 2.1446 - acc: 0.2754 - val_loss: 2.7127 - val_acc: 0.1358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_cvzvlMyNeXS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "27e7eaea-4dc5-472f-e140-0ea0f54aace9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model"
      ],
      "metadata": {
        "id": "WV6O06e2NiRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/44_รอบที่4_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "Vzynw2K2Ni42"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/My Drive/cut_panoramic/Model/44_รอบที่4_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "dHVn2cC6NnDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ca7d12b2-ebeb-4e84-97cc-f362e5bcb1e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54842e48-2598-48b6-aecc-8b90ae8396a9\", \"44_\\u0e23\\u0e2d\\u0e1a\\u0e17\\u0e35\\u0e484_Flimpano_Male125_250.h5\", 16779664)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQJi4Iglg67i"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}