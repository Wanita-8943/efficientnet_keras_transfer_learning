{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/NEW_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%881_Train_Male125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "27975ce6-db20-48da-df08-d3d8869ff197"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Male_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "04619af4-23d8-41eb-c03d-e3cdeeb8ff87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07M       VV03.jpg   \n",
              "1           2               1          7  Y07M  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M       VV04.jpg   \n",
              "3           4               2          7  Y07M  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M       VV05.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              77         25  Y25M  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M       J464.jpg   \n",
              "2372      123              78         25  Y25M  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M       J465.jpg   \n",
              "2374      125              79         25  Y25M  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c64f4da6-428a-4a61-9037-ac8897e60ccb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c64f4da6-428a-4a61-9037-ac8897e60ccb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c64f4da6-428a-4a61-9037-ac8897e60ccb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c64f4da6-428a-4a61-9037-ac8897e60ccb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "9ffbafcc-ebee-4ff4-ff19-378cb6bfa009"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "20c45c52-a26c-46c6-a764-392b5434a4b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "9b41f17d-8f2d-47b4-bc46-1db35e959d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "a71513d2-3c76-47a0-dcd5-d8cebd0476ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "077fec2b-0840-46f4-e594-4736c8db0b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "a5c8ba8e-984b-4229-f209-4048b6e9cd31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-15-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 164s 2s/step - loss: 4.9868 - acc: 0.0525 - val_loss: 4.4458 - val_acc: 0.0560\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 4.6045 - acc: 0.0568 - val_loss: 4.1775 - val_acc: 0.0625\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 4.3050 - acc: 0.0483 - val_loss: 4.0103 - val_acc: 0.0797\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 4.1504 - acc: 0.0660 - val_loss: 3.8313 - val_acc: 0.0711\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 4.0478 - acc: 0.0653 - val_loss: 3.7671 - val_acc: 0.0819\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.9903 - acc: 0.0625 - val_loss: 3.7204 - val_acc: 0.0819\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.9423 - acc: 0.0575 - val_loss: 3.6293 - val_acc: 0.0905\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.8794 - acc: 0.0717 - val_loss: 3.6595 - val_acc: 0.0841\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.9219 - acc: 0.0717 - val_loss: 3.6226 - val_acc: 0.0862\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.8207 - acc: 0.0795 - val_loss: 3.5791 - val_acc: 0.0884\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 17s 186ms/step - loss: 3.8918 - acc: 0.0681 - val_loss: 3.5358 - val_acc: 0.0927\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 17s 177ms/step - loss: 3.8352 - acc: 0.0681 - val_loss: 3.5152 - val_acc: 0.0884\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.8020 - acc: 0.0639 - val_loss: 3.4384 - val_acc: 0.0884\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.7937 - acc: 0.0625 - val_loss: 3.4349 - val_acc: 0.0884\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.7711 - acc: 0.0781 - val_loss: 3.3822 - val_acc: 0.0970\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.7266 - acc: 0.0674 - val_loss: 3.3646 - val_acc: 0.0948\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.6131 - acc: 0.0774 - val_loss: 3.3172 - val_acc: 0.0970\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.7118 - acc: 0.0795 - val_loss: 3.3098 - val_acc: 0.1056\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.6212 - acc: 0.0916 - val_loss: 3.3130 - val_acc: 0.1056\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.5594 - acc: 0.0823 - val_loss: 3.2628 - val_acc: 0.1078\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5939 - acc: 0.0802 - val_loss: 3.2588 - val_acc: 0.1078\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.6277 - acc: 0.0816 - val_loss: 3.2323 - val_acc: 0.1164\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5358 - acc: 0.1100 - val_loss: 3.2023 - val_acc: 0.1207\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.4875 - acc: 0.0816 - val_loss: 3.2033 - val_acc: 0.1185\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.5061 - acc: 0.0873 - val_loss: 3.1727 - val_acc: 0.1336\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.4697 - acc: 0.0916 - val_loss: 3.1501 - val_acc: 0.1272\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.5054 - acc: 0.0937 - val_loss: 3.1828 - val_acc: 0.1121\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.4962 - acc: 0.0951 - val_loss: 3.1530 - val_acc: 0.1164\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.5445 - acc: 0.0908 - val_loss: 3.1208 - val_acc: 0.1272\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 3.4683 - acc: 0.0979 - val_loss: 3.1275 - val_acc: 0.1185\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.5206 - acc: 0.0795 - val_loss: 3.1019 - val_acc: 0.1336\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.4260 - acc: 0.0972 - val_loss: 3.0818 - val_acc: 0.1293\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.4212 - acc: 0.0930 - val_loss: 3.0470 - val_acc: 0.1336\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.3880 - acc: 0.0987 - val_loss: 3.0488 - val_acc: 0.1444\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.4149 - acc: 0.0908 - val_loss: 3.0184 - val_acc: 0.1530\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3865 - acc: 0.0979 - val_loss: 2.9949 - val_acc: 0.1422\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3409 - acc: 0.1107 - val_loss: 2.9855 - val_acc: 0.1444\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3789 - acc: 0.0994 - val_loss: 2.9802 - val_acc: 0.1422\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3622 - acc: 0.0937 - val_loss: 2.9952 - val_acc: 0.1401\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 3.3207 - acc: 0.1043 - val_loss: 2.9924 - val_acc: 0.1466\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3044 - acc: 0.1043 - val_loss: 2.9860 - val_acc: 0.1401\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.3168 - acc: 0.1110 - val_loss: 2.9471 - val_acc: 0.1422\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.3167 - acc: 0.1100 - val_loss: 2.9464 - val_acc: 0.1401\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.3585 - acc: 0.0944 - val_loss: 2.9559 - val_acc: 0.1487\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2761 - acc: 0.1221 - val_loss: 2.9456 - val_acc: 0.1466\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.3262 - acc: 0.0958 - val_loss: 2.9573 - val_acc: 0.1466\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2881 - acc: 0.1093 - val_loss: 2.9272 - val_acc: 0.1466\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 3.3034 - acc: 0.1043 - val_loss: 2.9438 - val_acc: 0.1487\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2278 - acc: 0.1114 - val_loss: 2.9298 - val_acc: 0.1552\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.2777 - acc: 0.1079 - val_loss: 2.9250 - val_acc: 0.1595\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.2477 - acc: 0.1150 - val_loss: 2.9009 - val_acc: 0.1573\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.2084 - acc: 0.1150 - val_loss: 2.8862 - val_acc: 0.1573\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2460 - acc: 0.1065 - val_loss: 2.9269 - val_acc: 0.1466\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1964 - acc: 0.1178 - val_loss: 2.9241 - val_acc: 0.1487\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1775 - acc: 0.1214 - val_loss: 2.9053 - val_acc: 0.1530\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2298 - acc: 0.1121 - val_loss: 2.8575 - val_acc: 0.1616\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1969 - acc: 0.1327 - val_loss: 2.8546 - val_acc: 0.1638\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.2490 - acc: 0.1001 - val_loss: 2.8854 - val_acc: 0.1638\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1538 - acc: 0.1128 - val_loss: 2.8706 - val_acc: 0.1681\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1659 - acc: 0.1121 - val_loss: 2.8585 - val_acc: 0.1616\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0941 - acc: 0.1207 - val_loss: 2.8779 - val_acc: 0.1595\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1456 - acc: 0.1192 - val_loss: 2.8651 - val_acc: 0.1552\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.1546 - acc: 0.1285 - val_loss: 2.8281 - val_acc: 0.1573\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.1581 - acc: 0.1228 - val_loss: 2.8402 - val_acc: 0.1638\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.1196 - acc: 0.1256 - val_loss: 2.8546 - val_acc: 0.1638\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1906 - acc: 0.1036 - val_loss: 2.8199 - val_acc: 0.1573\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 3.1058 - acc: 0.1356 - val_loss: 2.8260 - val_acc: 0.1616\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.1922 - acc: 0.1150 - val_loss: 2.8181 - val_acc: 0.1659\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1305 - acc: 0.1157 - val_loss: 2.8025 - val_acc: 0.1573\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0690 - acc: 0.1171 - val_loss: 2.7880 - val_acc: 0.1552\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0945 - acc: 0.1185 - val_loss: 2.8040 - val_acc: 0.1681\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.2045 - acc: 0.1072 - val_loss: 2.8366 - val_acc: 0.1466\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0833 - acc: 0.1228 - val_loss: 2.8482 - val_acc: 0.1466\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.1234 - acc: 0.1207 - val_loss: 2.8233 - val_acc: 0.1509\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.0899 - acc: 0.1306 - val_loss: 2.8169 - val_acc: 0.1509\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.1460 - acc: 0.1242 - val_loss: 2.8060 - val_acc: 0.1530\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0815 - acc: 0.1313 - val_loss: 2.7753 - val_acc: 0.1616\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0394 - acc: 0.1412 - val_loss: 2.7888 - val_acc: 0.1487\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0870 - acc: 0.1192 - val_loss: 2.7998 - val_acc: 0.1509\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0461 - acc: 0.1356 - val_loss: 2.7945 - val_acc: 0.1530\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1177 - acc: 0.1100 - val_loss: 2.7639 - val_acc: 0.1573\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0642 - acc: 0.1292 - val_loss: 2.7651 - val_acc: 0.1530\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 3.0771 - acc: 0.1320 - val_loss: 2.7640 - val_acc: 0.1595\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0285 - acc: 0.1370 - val_loss: 2.7727 - val_acc: 0.1487\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 17s 185ms/step - loss: 3.0535 - acc: 0.1334 - val_loss: 2.7689 - val_acc: 0.1509\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 17s 176ms/step - loss: 2.9998 - acc: 0.1434 - val_loss: 2.7461 - val_acc: 0.1466\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0233 - acc: 0.1285 - val_loss: 2.7519 - val_acc: 0.1573\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.1189 - acc: 0.1207 - val_loss: 2.7615 - val_acc: 0.1659\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.0473 - acc: 0.1278 - val_loss: 2.7696 - val_acc: 0.1573\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 3.0198 - acc: 0.1405 - val_loss: 2.7506 - val_acc: 0.1638\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9899 - acc: 0.1434 - val_loss: 2.7521 - val_acc: 0.1552\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9928 - acc: 0.1363 - val_loss: 2.7245 - val_acc: 0.1552\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 3.0667 - acc: 0.1391 - val_loss: 2.7327 - val_acc: 0.1552\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 3.0254 - acc: 0.1334 - val_loss: 2.7284 - val_acc: 0.1616\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9624 - acc: 0.1533 - val_loss: 2.7351 - val_acc: 0.1552\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0188 - acc: 0.1434 - val_loss: 2.7293 - val_acc: 0.1595\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.9984 - acc: 0.1356 - val_loss: 2.7270 - val_acc: 0.1552\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 17s 180ms/step - loss: 2.9983 - acc: 0.1363 - val_loss: 2.7186 - val_acc: 0.1595\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0456 - acc: 0.1313 - val_loss: 2.7167 - val_acc: 0.1573\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.9840 - acc: 0.1356 - val_loss: 2.7311 - val_acc: 0.1595\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0012 - acc: 0.1057 - val_loss: 2.7217 - val_acc: 0.1573\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.9766 - acc: 0.1348 - val_loss: 2.7362 - val_acc: 0.1573\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 3.0201 - acc: 0.1334 - val_loss: 2.7346 - val_acc: 0.1616\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 2.9503 - acc: 0.1512 - val_loss: 2.7316 - val_acc: 0.1638\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.9724 - acc: 0.1384 - val_loss: 2.7366 - val_acc: 0.1509\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 3.0094 - acc: 0.1363 - val_loss: 2.7245 - val_acc: 0.1638\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9500 - acc: 0.1611 - val_loss: 2.7319 - val_acc: 0.1552\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9296 - acc: 0.1370 - val_loss: 2.7328 - val_acc: 0.1530\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.9004 - acc: 0.1476 - val_loss: 2.7010 - val_acc: 0.1530\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8948 - acc: 0.1576 - val_loss: 2.7128 - val_acc: 0.1681\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 3.0147 - acc: 0.1356 - val_loss: 2.6903 - val_acc: 0.1638\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.9699 - acc: 0.1363 - val_loss: 2.7044 - val_acc: 0.1638\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.9191 - acc: 0.1576 - val_loss: 2.7007 - val_acc: 0.1638\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9434 - acc: 0.1356 - val_loss: 2.6907 - val_acc: 0.1616\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.9044 - acc: 0.1221 - val_loss: 2.6756 - val_acc: 0.1681\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8972 - acc: 0.1405 - val_loss: 2.6867 - val_acc: 0.1659\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.9608 - acc: 0.1469 - val_loss: 2.7019 - val_acc: 0.1659\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.9178 - acc: 0.1498 - val_loss: 2.7212 - val_acc: 0.1595\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8984 - acc: 0.1370 - val_loss: 2.6965 - val_acc: 0.1552\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8915 - acc: 0.1490 - val_loss: 2.6856 - val_acc: 0.1616\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.9079 - acc: 0.1554 - val_loss: 2.7006 - val_acc: 0.1573\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.9185 - acc: 0.1313 - val_loss: 2.6849 - val_acc: 0.1638\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 2.9479 - acc: 0.1469 - val_loss: 2.6942 - val_acc: 0.1573\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.9919 - acc: 0.1412 - val_loss: 2.6730 - val_acc: 0.1659\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.9295 - acc: 0.1377 - val_loss: 2.6694 - val_acc: 0.1638\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.9351 - acc: 0.1419 - val_loss: 2.6767 - val_acc: 0.1724\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.9058 - acc: 0.1434 - val_loss: 2.6837 - val_acc: 0.1595\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.8437 - acc: 0.1462 - val_loss: 2.6901 - val_acc: 0.1681\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 16s 178ms/step - loss: 2.9028 - acc: 0.1434 - val_loss: 2.6844 - val_acc: 0.1724\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8761 - acc: 0.1448 - val_loss: 2.6913 - val_acc: 0.1638\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8986 - acc: 0.1391 - val_loss: 2.6862 - val_acc: 0.1638\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9117 - acc: 0.1455 - val_loss: 2.6891 - val_acc: 0.1659\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 2.8789 - acc: 0.1391 - val_loss: 2.6528 - val_acc: 0.1810\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9246 - acc: 0.1483 - val_loss: 2.6725 - val_acc: 0.1767\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8390 - acc: 0.1519 - val_loss: 2.6678 - val_acc: 0.1724\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.8848 - acc: 0.1647 - val_loss: 2.6882 - val_acc: 0.1681\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.9025 - acc: 0.1434 - val_loss: 2.6984 - val_acc: 0.1681\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.8405 - acc: 0.1540 - val_loss: 2.6625 - val_acc: 0.1681\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8720 - acc: 0.1498 - val_loss: 2.6803 - val_acc: 0.1638\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8168 - acc: 0.1519 - val_loss: 2.6721 - val_acc: 0.1724\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8278 - acc: 0.1519 - val_loss: 2.6692 - val_acc: 0.1746\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 2.8526 - acc: 0.1391 - val_loss: 2.6733 - val_acc: 0.1746\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.9053 - acc: 0.1419 - val_loss: 2.6707 - val_acc: 0.1767\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8795 - acc: 0.1576 - val_loss: 2.6764 - val_acc: 0.1746\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7899 - acc: 0.1462 - val_loss: 2.6651 - val_acc: 0.1659\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8341 - acc: 0.1483 - val_loss: 2.6763 - val_acc: 0.1681\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8268 - acc: 0.1547 - val_loss: 2.6781 - val_acc: 0.1767\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.8066 - acc: 0.1576 - val_loss: 2.6782 - val_acc: 0.1703\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7914 - acc: 0.1796 - val_loss: 2.6721 - val_acc: 0.1746\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.8132 - acc: 0.1540 - val_loss: 2.6572 - val_acc: 0.1789\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8654 - acc: 0.1455 - val_loss: 2.6512 - val_acc: 0.1767\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7753 - acc: 0.1746 - val_loss: 2.6591 - val_acc: 0.1767\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.8179 - acc: 0.1618 - val_loss: 2.6644 - val_acc: 0.1703\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.8385 - acc: 0.1462 - val_loss: 2.6653 - val_acc: 0.1681\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8297 - acc: 0.1547 - val_loss: 2.6519 - val_acc: 0.1724\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.8528 - acc: 0.1320 - val_loss: 2.6640 - val_acc: 0.1767\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.8423 - acc: 0.1490 - val_loss: 2.6599 - val_acc: 0.1746\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7951 - acc: 0.1568 - val_loss: 2.6675 - val_acc: 0.1746\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7709 - acc: 0.1552 - val_loss: 2.6571 - val_acc: 0.1681\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 16s 179ms/step - loss: 2.7284 - acc: 0.1767 - val_loss: 2.6702 - val_acc: 0.1681\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 2.7964 - acc: 0.1505 - val_loss: 2.6464 - val_acc: 0.1767\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7982 - acc: 0.1636 - val_loss: 2.6474 - val_acc: 0.1724\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.8359 - acc: 0.1455 - val_loss: 2.6673 - val_acc: 0.1703\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7700 - acc: 0.1639 - val_loss: 2.6522 - val_acc: 0.1789\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7827 - acc: 0.1583 - val_loss: 2.6491 - val_acc: 0.1681\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.8064 - acc: 0.1604 - val_loss: 2.6378 - val_acc: 0.1703\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.8058 - acc: 0.1682 - val_loss: 2.6250 - val_acc: 0.1746\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.7372 - acc: 0.1689 - val_loss: 2.6332 - val_acc: 0.1789\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7539 - acc: 0.1561 - val_loss: 2.6451 - val_acc: 0.1746\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7877 - acc: 0.1554 - val_loss: 2.6443 - val_acc: 0.1767\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7323 - acc: 0.1703 - val_loss: 2.6721 - val_acc: 0.1724\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7628 - acc: 0.1647 - val_loss: 2.6445 - val_acc: 0.1703\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.8109 - acc: 0.1590 - val_loss: 2.6415 - val_acc: 0.1681\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7848 - acc: 0.1604 - val_loss: 2.6614 - val_acc: 0.1724\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.7515 - acc: 0.1462 - val_loss: 2.6594 - val_acc: 0.1703\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6957 - acc: 0.1739 - val_loss: 2.6797 - val_acc: 0.1746\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7814 - acc: 0.1625 - val_loss: 2.6804 - val_acc: 0.1746\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7685 - acc: 0.1675 - val_loss: 2.6774 - val_acc: 0.1638\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 2.7993 - acc: 0.1540 - val_loss: 2.6577 - val_acc: 0.1746\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.7534 - acc: 0.1668 - val_loss: 2.6568 - val_acc: 0.1724\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7436 - acc: 0.1568 - val_loss: 2.6492 - val_acc: 0.1746\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7338 - acc: 0.1689 - val_loss: 2.6679 - val_acc: 0.1703\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6910 - acc: 0.1703 - val_loss: 2.6402 - val_acc: 0.1746\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.7075 - acc: 0.1739 - val_loss: 2.6660 - val_acc: 0.1724\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7600 - acc: 0.1576 - val_loss: 2.6796 - val_acc: 0.1724\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7698 - acc: 0.1547 - val_loss: 2.6454 - val_acc: 0.1724\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 16s 181ms/step - loss: 2.7444 - acc: 0.1654 - val_loss: 2.6401 - val_acc: 0.1703\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7824 - acc: 0.1604 - val_loss: 2.6450 - val_acc: 0.1789\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7173 - acc: 0.1654 - val_loss: 2.6321 - val_acc: 0.1789\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.7160 - acc: 0.1625 - val_loss: 2.6603 - val_acc: 0.1746\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.7169 - acc: 0.1647 - val_loss: 2.6511 - val_acc: 0.1767\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.6944 - acc: 0.1618 - val_loss: 2.6442 - val_acc: 0.1746\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7158 - acc: 0.1767 - val_loss: 2.6594 - val_acc: 0.1703\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7474 - acc: 0.1696 - val_loss: 2.6552 - val_acc: 0.1746\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7279 - acc: 0.1767 - val_loss: 2.6168 - val_acc: 0.1853\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.7069 - acc: 0.1689 - val_loss: 2.6465 - val_acc: 0.1746\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 16s 177ms/step - loss: 2.6663 - acc: 0.1618 - val_loss: 2.6568 - val_acc: 0.1724\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 17s 179ms/step - loss: 2.7730 - acc: 0.1519 - val_loss: 2.6416 - val_acc: 0.1724\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7284 - acc: 0.1512 - val_loss: 2.6556 - val_acc: 0.1746\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7340 - acc: 0.1739 - val_loss: 2.6487 - val_acc: 0.1810\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 16s 170ms/step - loss: 2.7261 - acc: 0.1590 - val_loss: 2.6376 - val_acc: 0.1789\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6863 - acc: 0.1540 - val_loss: 2.6279 - val_acc: 0.1810\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.7187 - acc: 0.1746 - val_loss: 2.6482 - val_acc: 0.1789\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.7179 - acc: 0.1632 - val_loss: 2.6605 - val_acc: 0.1746\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6872 - acc: 0.1774 - val_loss: 2.6551 - val_acc: 0.1746\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6507 - acc: 0.1810 - val_loss: 2.6576 - val_acc: 0.1810\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6576 - acc: 0.1654 - val_loss: 2.6428 - val_acc: 0.1810\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.6505 - acc: 0.1739 - val_loss: 2.6489 - val_acc: 0.1767\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7013 - acc: 0.1923 - val_loss: 2.6541 - val_acc: 0.1746\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.6510 - acc: 0.1682 - val_loss: 2.6721 - val_acc: 0.1746\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6597 - acc: 0.1583 - val_loss: 2.6600 - val_acc: 0.1767\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6507 - acc: 0.1888 - val_loss: 2.6809 - val_acc: 0.1810\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6576 - acc: 0.1767 - val_loss: 2.6736 - val_acc: 0.1789\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6675 - acc: 0.1703 - val_loss: 2.6663 - val_acc: 0.1767\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7372 - acc: 0.1618 - val_loss: 2.6629 - val_acc: 0.1810\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6798 - acc: 0.1810 - val_loss: 2.6486 - val_acc: 0.1767\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6884 - acc: 0.1710 - val_loss: 2.6572 - val_acc: 0.1746\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6413 - acc: 0.1859 - val_loss: 2.6489 - val_acc: 0.1746\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6747 - acc: 0.1824 - val_loss: 2.6659 - val_acc: 0.1810\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6733 - acc: 0.1789 - val_loss: 2.6797 - val_acc: 0.1724\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6696 - acc: 0.1689 - val_loss: 2.6516 - val_acc: 0.1767\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7066 - acc: 0.1661 - val_loss: 2.6696 - val_acc: 0.1703\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6716 - acc: 0.1611 - val_loss: 2.6430 - val_acc: 0.1746\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6452 - acc: 0.1930 - val_loss: 2.6410 - val_acc: 0.1767\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6768 - acc: 0.1718 - val_loss: 2.6585 - val_acc: 0.1767\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.6488 - acc: 0.1703 - val_loss: 2.6738 - val_acc: 0.1767\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6516 - acc: 0.1682 - val_loss: 2.6695 - val_acc: 0.1767\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.6245 - acc: 0.1852 - val_loss: 2.6621 - val_acc: 0.1853\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6087 - acc: 0.1824 - val_loss: 2.6567 - val_acc: 0.1853\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 2.6577 - acc: 0.1767 - val_loss: 2.6546 - val_acc: 0.1767\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6451 - acc: 0.1746 - val_loss: 2.6371 - val_acc: 0.1767\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.6650 - acc: 0.1909 - val_loss: 2.6636 - val_acc: 0.1724\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 16s 171ms/step - loss: 2.5985 - acc: 0.1994 - val_loss: 2.6380 - val_acc: 0.1789\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 2.6524 - acc: 0.1668 - val_loss: 2.6508 - val_acc: 0.1789\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.7097 - acc: 0.1760 - val_loss: 2.6186 - val_acc: 0.1789\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 17s 183ms/step - loss: 2.6616 - acc: 0.1682 - val_loss: 2.6285 - val_acc: 0.1853\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6192 - acc: 0.1874 - val_loss: 2.6446 - val_acc: 0.1853\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.6103 - acc: 0.1831 - val_loss: 2.6167 - val_acc: 0.1918\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6228 - acc: 0.1838 - val_loss: 2.6361 - val_acc: 0.1853\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.5514 - acc: 0.1859 - val_loss: 2.6571 - val_acc: 0.1746\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 16s 175ms/step - loss: 2.6059 - acc: 0.1938 - val_loss: 2.6327 - val_acc: 0.1832\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6471 - acc: 0.1930 - val_loss: 2.6388 - val_acc: 0.1810\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.6375 - acc: 0.1789 - val_loss: 2.6431 - val_acc: 0.1746\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.6282 - acc: 0.1732 - val_loss: 2.6311 - val_acc: 0.1746\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6842 - acc: 0.1710 - val_loss: 2.6449 - val_acc: 0.1767\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 16s 173ms/step - loss: 2.6106 - acc: 0.2051 - val_loss: 2.6411 - val_acc: 0.1724\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.5835 - acc: 0.1867 - val_loss: 2.6361 - val_acc: 0.1746\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 16s 172ms/step - loss: 2.6183 - acc: 0.1803 - val_loss: 2.6332 - val_acc: 0.1810\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 16s 176ms/step - loss: 2.6472 - acc: 0.1789 - val_loss: 2.6218 - val_acc: 0.1853\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 16s 174ms/step - loss: 2.5823 - acc: 0.1845 - val_loss: 2.6353 - val_acc: 0.1832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "992373f0-d50f-4b28-b8ed-14fb79c4bb48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}