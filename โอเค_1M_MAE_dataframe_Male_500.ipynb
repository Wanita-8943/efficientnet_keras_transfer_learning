{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/%E0%B9%82%E0%B8%AD%E0%B9%80%E0%B8%84_1M_MAE_dataframe_Male_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DlQ2oT7cIR6o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "d9bb63e4-31a3-4bb0-8467-07dc4e6d470f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "057da2c3-e8da-40a5-b29d-f3ee11a2fbf3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 792, done.\u001b[K\n",
            "remote: Counting objects: 100% (314/314), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 792 (delta 225), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (792/792), 13.36 MiB | 11.92 MiB/s, done.\n",
            "Resolving deltas: 100% (465/465), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "Vbdblwbv89fe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "vnLrobY_-GCx",
        "outputId": "52344d07-01dc-4e3f-80f7-b9b4ddc0efe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "624425a0-32eb-4507-e8d0-7f272496c474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "a27725e0-9649-4684-f558-667bfb5d734b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "fa3de278-70f9-41bd-fbf8-f19ad24e309e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "aa4ac66a-3173-44df-bca2-8ef505eaad32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Male125.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "37168c01-a0fb-4e01-e7b6-a8cccd3ff774"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07M         0       VV03.jpg   \n",
              "1           2               1          7  Y07M         0  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M         0       VV04.jpg   \n",
              "3           4               2          7  Y07M         0  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M         0       VV05.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M        18       J464.jpg   \n",
              "2372      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M        18       J465.jpg   \n",
              "2374      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f820abde-162e-4a3a-83cf-3f2ee0866111\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f820abde-162e-4a3a-83cf-3f2ee0866111')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f820abde-162e-4a3a-83cf-3f2ee0866111 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f820abde-162e-4a3a-83cf-3f2ee0866111');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Male125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "96bd194c-ad80-4a46-9c4d-203950fc75fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Male125/train\n",
            "/content/drive/My Drive/TVT_Male125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "f9d4b829-ca18-4739-8e34-429f7232051b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(lr=2e-6),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "6d7acf2c-ac2e-4854-c1dc-9f2ec013839a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-21-90b2ae0efec2>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 393s 4s/step - loss: 101.2726 - mae: 8.5014 - val_loss: 99.2340 - val_mae: 8.4031\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 26s 292ms/step - loss: 98.4481 - mae: 8.3544 - val_loss: 95.9539 - val_mae: 8.2169\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 95.7735 - mae: 8.2020 - val_loss: 94.6851 - val_mae: 8.1490\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 92.5843 - mae: 8.0393 - val_loss: 92.1374 - val_mae: 8.0296\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 90.2524 - mae: 7.9231 - val_loss: 88.1433 - val_mae: 7.8153\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 87.2384 - mae: 7.7610 - val_loss: 85.6794 - val_mae: 7.6739\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 85.0007 - mae: 7.6399 - val_loss: 84.0768 - val_mae: 7.5961\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 82.9469 - mae: 7.5420 - val_loss: 80.4462 - val_mae: 7.3896\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 80.1583 - mae: 7.3837 - val_loss: 78.2987 - val_mae: 7.2725\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 23s 250ms/step - loss: 77.6464 - mae: 7.2460 - val_loss: 75.9857 - val_mae: 7.1657\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 28s 295ms/step - loss: 75.3237 - mae: 7.1290 - val_loss: 74.7690 - val_mae: 7.0936\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 28s 294ms/step - loss: 73.6948 - mae: 7.0527 - val_loss: 73.7025 - val_mae: 7.0785\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 28s 297ms/step - loss: 71.4423 - mae: 6.9255 - val_loss: 70.6638 - val_mae: 6.8900\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 69.5230 - mae: 6.8262 - val_loss: 69.6910 - val_mae: 6.8483\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 67.7521 - mae: 6.7275 - val_loss: 66.9747 - val_mae: 6.6946\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 22s 234ms/step - loss: 65.7404 - mae: 6.6228 - val_loss: 64.3596 - val_mae: 6.5421\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 24s 256ms/step - loss: 64.0918 - mae: 6.5392 - val_loss: 62.4197 - val_mae: 6.4588\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 62.3950 - mae: 6.4557 - val_loss: 61.9986 - val_mae: 6.4325\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 60.7323 - mae: 6.3619 - val_loss: 59.5572 - val_mae: 6.2913\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 59.4398 - mae: 6.3027 - val_loss: 58.5489 - val_mae: 6.2571\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 57.7137 - mae: 6.2050 - val_loss: 57.3759 - val_mae: 6.1871\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 56.2010 - mae: 6.1236 - val_loss: 55.6397 - val_mae: 6.0894\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 54.8809 - mae: 6.0508 - val_loss: 54.0873 - val_mae: 6.0071\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 53.6580 - mae: 5.9929 - val_loss: 52.4637 - val_mae: 5.9173\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 22s 235ms/step - loss: 52.0117 - mae: 5.9073 - val_loss: 51.4535 - val_mae: 5.8665\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 50.8530 - mae: 5.8480 - val_loss: 49.8872 - val_mae: 5.7951\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 49.7488 - mae: 5.7869 - val_loss: 48.7225 - val_mae: 5.7377\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 48.3595 - mae: 5.7120 - val_loss: 47.9556 - val_mae: 5.6949\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 47.4311 - mae: 5.6574 - val_loss: 47.4770 - val_mae: 5.6854\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 46.3991 - mae: 5.6012 - val_loss: 45.0764 - val_mae: 5.5146\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 45.1189 - mae: 5.5308 - val_loss: 45.2497 - val_mae: 5.5478\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 44.0538 - mae: 5.4837 - val_loss: 43.2146 - val_mae: 5.4343\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 43.3519 - mae: 5.4480 - val_loss: 43.1018 - val_mae: 5.4391\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 42.6938 - mae: 5.4191 - val_loss: 42.5158 - val_mae: 5.4078\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 27s 286ms/step - loss: 41.7165 - mae: 5.3657 - val_loss: 41.5659 - val_mae: 5.3687\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 40.8681 - mae: 5.3198 - val_loss: 40.8877 - val_mae: 5.3282\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 39.9186 - mae: 5.2646 - val_loss: 39.9443 - val_mae: 5.2732\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 39.5105 - mae: 5.2435 - val_loss: 39.0031 - val_mae: 5.2023\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 38.6102 - mae: 5.1929 - val_loss: 38.5388 - val_mae: 5.1944\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 38.0984 - mae: 5.1694 - val_loss: 37.1287 - val_mae: 5.1192\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 37.5885 - mae: 5.1525 - val_loss: 37.1164 - val_mae: 5.1205\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 36.5367 - mae: 5.0890 - val_loss: 37.0018 - val_mae: 5.1252\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 36.1984 - mae: 5.0726 - val_loss: 36.1618 - val_mae: 5.0906\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 35.8581 - mae: 5.0595 - val_loss: 35.7371 - val_mae: 5.0608\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 35.1878 - mae: 5.0181 - val_loss: 35.1038 - val_mae: 5.0189\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 34.9277 - mae: 5.0073 - val_loss: 33.9653 - val_mae: 4.9336\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 34.0961 - mae: 4.9478 - val_loss: 33.9936 - val_mae: 4.9491\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 33.7842 - mae: 4.9308 - val_loss: 33.7262 - val_mae: 4.9329\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 33.4888 - mae: 4.9253 - val_loss: 33.7360 - val_mae: 4.9384\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 33.2810 - mae: 4.9145 - val_loss: 32.8336 - val_mae: 4.8905\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 32.9744 - mae: 4.9041 - val_loss: 32.8870 - val_mae: 4.9063\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 32.5429 - mae: 4.8780 - val_loss: 32.2425 - val_mae: 4.8466\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 32.4120 - mae: 4.8817 - val_loss: 31.9843 - val_mae: 4.8447\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 23s 250ms/step - loss: 30.6471 - mae: 4.6475 - val_loss: 25.4131 - val_mae: 3.9826\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 25.6443 - mae: 4.0461 - val_loss: 24.1510 - val_mae: 3.8686\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 24.5249 - mae: 3.9442 - val_loss: 23.5881 - val_mae: 3.8588\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 23.7362 - mae: 3.8803 - val_loss: 22.1344 - val_mae: 3.6879\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 23.0149 - mae: 3.8148 - val_loss: 22.0749 - val_mae: 3.7166\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 22.0603 - mae: 3.7304 - val_loss: 22.6493 - val_mae: 3.7210\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 21.5366 - mae: 3.7120 - val_loss: 22.5112 - val_mae: 3.7089\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 20.7493 - mae: 3.6441 - val_loss: 22.0789 - val_mae: 3.6568\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 20.3236 - mae: 3.5873 - val_loss: 19.8151 - val_mae: 3.5323\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 19.9269 - mae: 3.5882 - val_loss: 19.2745 - val_mae: 3.4457\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 19.3098 - mae: 3.5215 - val_loss: 18.5777 - val_mae: 3.3966\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 19.0083 - mae: 3.4870 - val_loss: 17.8076 - val_mae: 3.3355\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 18.3168 - mae: 3.4326 - val_loss: 16.7417 - val_mae: 3.2097\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 17.8017 - mae: 3.3606 - val_loss: 18.8362 - val_mae: 3.3800\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 17.9630 - mae: 3.4054 - val_loss: 19.7699 - val_mae: 3.4597\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 23s 249ms/step - loss: 17.4576 - mae: 3.3887 - val_loss: 17.9460 - val_mae: 3.2973\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 17.0510 - mae: 3.3245 - val_loss: 15.2947 - val_mae: 3.1107\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 16.6195 - mae: 3.2918 - val_loss: 20.8301 - val_mae: 3.5363\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 16.3825 - mae: 3.2626 - val_loss: 14.8982 - val_mae: 3.0881\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 22s 235ms/step - loss: 16.1249 - mae: 3.2464 - val_loss: 14.4766 - val_mae: 3.0138\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 16.2910 - mae: 3.2780 - val_loss: 26.0981 - val_mae: 3.9166\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 15.3457 - mae: 3.1853 - val_loss: 22.2788 - val_mae: 3.6306\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 15.0405 - mae: 3.1166 - val_loss: 15.7444 - val_mae: 3.0802\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 15.7546 - mae: 3.2455 - val_loss: 18.7501 - val_mae: 3.3469\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 15.2147 - mae: 3.1900 - val_loss: 18.7570 - val_mae: 3.3665\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 17.2702 - mae: 3.4195 - val_loss: 25.0349 - val_mae: 3.8565\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 14.7071 - mae: 3.1377 - val_loss: 18.4009 - val_mae: 3.3039\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 14.8950 - mae: 3.1653 - val_loss: 19.7126 - val_mae: 3.4314\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 25s 276ms/step - loss: 14.3327 - mae: 3.0876 - val_loss: 22.0748 - val_mae: 3.6094\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 14.5708 - mae: 3.0998 - val_loss: 15.8637 - val_mae: 3.1094\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 14.0537 - mae: 3.0844 - val_loss: 18.5610 - val_mae: 3.3464\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 14.3157 - mae: 3.0838 - val_loss: 17.1596 - val_mae: 3.2240\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 13.9979 - mae: 3.0378 - val_loss: 21.6195 - val_mae: 3.5748\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 13.5232 - mae: 3.0179 - val_loss: 15.8199 - val_mae: 3.0874\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.2829 - mae: 2.9826 - val_loss: 16.1369 - val_mae: 3.1438\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 13.2784 - mae: 2.9945 - val_loss: 17.6902 - val_mae: 3.2629\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 26s 278ms/step - loss: 14.4555 - mae: 3.0956 - val_loss: 11.5214 - val_mae: 2.7616\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.9898 - mae: 3.0273 - val_loss: 11.4482 - val_mae: 2.7542\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 14.2469 - mae: 3.0518 - val_loss: 15.5742 - val_mae: 3.0586\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 25s 273ms/step - loss: 13.4842 - mae: 2.9868 - val_loss: 12.1217 - val_mae: 2.7992\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.4701 - mae: 3.0030 - val_loss: 15.5996 - val_mae: 3.0583\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 27s 304ms/step - loss: 13.3748 - mae: 2.9767 - val_loss: 12.0344 - val_mae: 2.7762\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.5673 - mae: 2.9867 - val_loss: 14.1435 - val_mae: 2.9200\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.7678 - mae: 3.0372 - val_loss: 12.6208 - val_mae: 2.8034\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.7674 - mae: 2.8986 - val_loss: 12.1428 - val_mae: 2.7676\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.4575 - mae: 2.9937 - val_loss: 11.4017 - val_mae: 2.7765\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.5836 - mae: 3.0040 - val_loss: 13.7165 - val_mae: 2.8922\n",
            "Epoch 101/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.3427 - mae: 2.9820 - val_loss: 14.3196 - val_mae: 2.9280\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.6919 - mae: 3.0172 - val_loss: 14.6228 - val_mae: 2.9688\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.8860 - mae: 2.9336 - val_loss: 15.0081 - val_mae: 2.9878\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 22s 229ms/step - loss: 13.1704 - mae: 2.9607 - val_loss: 14.0392 - val_mae: 2.9417\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.9568 - mae: 2.9414 - val_loss: 13.1823 - val_mae: 2.8650\n",
            "Epoch 106/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.5055 - mae: 2.9990 - val_loss: 12.4644 - val_mae: 2.8069\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 21s 224ms/step - loss: 12.9731 - mae: 2.9287 - val_loss: 13.3807 - val_mae: 2.9003\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 13.2775 - mae: 2.9415 - val_loss: 15.7786 - val_mae: 3.0599\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 13.1426 - mae: 2.9739 - val_loss: 19.7201 - val_mae: 3.4050\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 25s 275ms/step - loss: 12.3413 - mae: 2.8808 - val_loss: 13.4154 - val_mae: 2.8776\n",
            "Epoch 111/500\n",
            "89/89 [==============================] - 25s 278ms/step - loss: 13.1195 - mae: 2.9554 - val_loss: 13.6690 - val_mae: 2.9016\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.9096 - mae: 2.9466 - val_loss: 16.6443 - val_mae: 3.1365\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 13.2863 - mae: 2.9919 - val_loss: 18.8990 - val_mae: 3.3499\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 13.0261 - mae: 2.9479 - val_loss: 11.9789 - val_mae: 2.7701\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.9239 - mae: 2.9427 - val_loss: 12.1799 - val_mae: 2.7700\n",
            "Epoch 116/500\n",
            "89/89 [==============================] - 25s 281ms/step - loss: 13.1218 - mae: 2.9612 - val_loss: 11.8392 - val_mae: 2.7452\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 25s 277ms/step - loss: 12.8268 - mae: 2.9175 - val_loss: 13.2543 - val_mae: 2.8723\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.5191 - mae: 3.0015 - val_loss: 12.2420 - val_mae: 2.7899\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 13.3669 - mae: 2.9845 - val_loss: 11.8521 - val_mae: 2.7567\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.0126 - mae: 2.9377 - val_loss: 10.0035 - val_mae: 2.5964\n",
            "Epoch 121/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.0652 - mae: 2.9383 - val_loss: 10.2535 - val_mae: 2.6362\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.2229 - mae: 2.9673 - val_loss: 10.8751 - val_mae: 2.6950\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.7454 - mae: 3.0418 - val_loss: 11.1167 - val_mae: 2.7347\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 12.8881 - mae: 2.9058 - val_loss: 12.5015 - val_mae: 2.8079\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.9774 - mae: 2.9083 - val_loss: 12.6580 - val_mae: 2.8213\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 12.7679 - mae: 2.9428 - val_loss: 10.2045 - val_mae: 2.6542\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 27s 287ms/step - loss: 12.7649 - mae: 2.9168 - val_loss: 11.8875 - val_mae: 2.7527\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 27s 288ms/step - loss: 13.4448 - mae: 2.9876 - val_loss: 17.9087 - val_mae: 3.2454\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 13.6753 - mae: 3.0255 - val_loss: 10.8781 - val_mae: 2.6944\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.2411 - mae: 2.9830 - val_loss: 11.8011 - val_mae: 2.7359\n",
            "Epoch 131/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.9686 - mae: 2.9238 - val_loss: 12.6648 - val_mae: 2.8130\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 12.6089 - mae: 2.8887 - val_loss: 16.7107 - val_mae: 3.1438\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.5576 - mae: 2.9090 - val_loss: 19.7080 - val_mae: 3.3851\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 13.2540 - mae: 2.9448 - val_loss: 11.9850 - val_mae: 2.7848\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 28s 301ms/step - loss: 12.8918 - mae: 2.9174 - val_loss: 20.0721 - val_mae: 3.4424\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 12.2746 - mae: 2.8804 - val_loss: 16.1445 - val_mae: 3.0900\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 13.1263 - mae: 2.9634 - val_loss: 12.8758 - val_mae: 2.8559\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 13.4717 - mae: 2.9891 - val_loss: 10.9914 - val_mae: 2.7123\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 23s 242ms/step - loss: 12.7093 - mae: 2.9212 - val_loss: 11.9966 - val_mae: 2.7772\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 13.5078 - mae: 2.9608 - val_loss: 15.0459 - val_mae: 3.0087\n",
            "Epoch 141/500\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 12.4528 - mae: 2.8690 - val_loss: 11.8619 - val_mae: 2.7667\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.0344 - mae: 2.9527 - val_loss: 11.4117 - val_mae: 2.7527\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.4435 - mae: 2.8862 - val_loss: 19.7682 - val_mae: 3.3949\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 27s 285ms/step - loss: 13.0593 - mae: 2.9356 - val_loss: 16.1816 - val_mae: 3.1063\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 21s 227ms/step - loss: 12.9072 - mae: 2.9396 - val_loss: 10.6956 - val_mae: 2.6865\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.5155 - mae: 2.8930 - val_loss: 11.7437 - val_mae: 2.7594\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 13.0106 - mae: 2.9404 - val_loss: 12.6832 - val_mae: 2.8222\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.7616 - mae: 2.8899 - val_loss: 17.6229 - val_mae: 3.2127\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 12.8904 - mae: 2.9213 - val_loss: 10.9655 - val_mae: 2.7078\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.4996 - mae: 2.8967 - val_loss: 18.9070 - val_mae: 3.3069\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.6790 - mae: 2.9089 - val_loss: 13.2542 - val_mae: 2.8914\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.9774 - mae: 2.9197 - val_loss: 20.9628 - val_mae: 3.4784\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.7414 - mae: 2.9079 - val_loss: 10.2568 - val_mae: 2.6386\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 13.3799 - mae: 2.9525 - val_loss: 16.1243 - val_mae: 3.1215\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.3403 - mae: 2.9560 - val_loss: 10.3820 - val_mae: 2.6645\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.3108 - mae: 2.9551 - val_loss: 12.1477 - val_mae: 2.7861\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.7770 - mae: 2.8963 - val_loss: 10.7261 - val_mae: 2.6892\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 12.7207 - mae: 2.9030 - val_loss: 10.6306 - val_mae: 2.6803\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 13.7769 - mae: 3.0139 - val_loss: 10.0437 - val_mae: 2.6132\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.5371 - mae: 2.8963 - val_loss: 9.9890 - val_mae: 2.6073\n",
            "Epoch 161/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.8323 - mae: 2.9116 - val_loss: 10.7679 - val_mae: 2.6818\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.2436 - mae: 2.9596 - val_loss: 12.5987 - val_mae: 2.8270\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.2922 - mae: 2.9609 - val_loss: 10.7782 - val_mae: 2.6739\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.1707 - mae: 2.8590 - val_loss: 9.9553 - val_mae: 2.6294\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.9804 - mae: 2.9561 - val_loss: 15.7400 - val_mae: 3.0758\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - 29s 318ms/step - loss: 12.9229 - mae: 2.9117 - val_loss: 16.9121 - val_mae: 3.1645\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.4573 - mae: 2.9008 - val_loss: 11.5199 - val_mae: 2.7427\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.3684 - mae: 2.9683 - val_loss: 18.1197 - val_mae: 3.2660\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 13.3414 - mae: 2.9549 - val_loss: 10.3049 - val_mae: 2.6508\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 28s 299ms/step - loss: 13.2121 - mae: 2.9586 - val_loss: 12.3797 - val_mae: 2.8095\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.0543 - mae: 2.8318 - val_loss: 14.7405 - val_mae: 3.0186\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 28s 298ms/step - loss: 13.4053 - mae: 2.9423 - val_loss: 10.7638 - val_mae: 2.6742\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 12.4028 - mae: 2.8840 - val_loss: 22.1931 - val_mae: 3.6403\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 27s 286ms/step - loss: 13.2340 - mae: 2.9477 - val_loss: 12.8874 - val_mae: 2.8621\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.4737 - mae: 2.9608 - val_loss: 9.9436 - val_mae: 2.6227\n",
            "Epoch 176/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 13.3336 - mae: 2.9500 - val_loss: 15.0204 - val_mae: 3.0374\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.4913 - mae: 2.8890 - val_loss: 13.6923 - val_mae: 2.9129\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.3157 - mae: 2.9581 - val_loss: 10.3287 - val_mae: 2.6444\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 14.0108 - mae: 3.0390 - val_loss: 10.8825 - val_mae: 2.6875\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.7276 - mae: 2.9148 - val_loss: 10.4456 - val_mae: 2.6622\n",
            "Epoch 181/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 12.5506 - mae: 2.8882 - val_loss: 13.9073 - val_mae: 2.9268\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.5875 - mae: 2.8994 - val_loss: 11.1246 - val_mae: 2.6894\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 13.6993 - mae: 2.9873 - val_loss: 9.7012 - val_mae: 2.5922\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.5228 - mae: 2.8990 - val_loss: 11.1939 - val_mae: 2.7145\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 25s 279ms/step - loss: 13.0642 - mae: 2.9391 - val_loss: 13.2040 - val_mae: 2.8839\n",
            "Epoch 186/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.7324 - mae: 2.9049 - val_loss: 12.6282 - val_mae: 2.8295\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.3484 - mae: 2.8604 - val_loss: 10.7335 - val_mae: 2.6701\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.1691 - mae: 2.9490 - val_loss: 13.3263 - val_mae: 2.8933\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.0716 - mae: 2.9289 - val_loss: 13.4619 - val_mae: 2.9032\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.6945 - mae: 2.9039 - val_loss: 14.5562 - val_mae: 2.9816\n",
            "Epoch 191/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.5419 - mae: 2.8705 - val_loss: 13.0142 - val_mae: 2.8529\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.9947 - mae: 2.8962 - val_loss: 12.2713 - val_mae: 2.7934\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 13.3157 - mae: 2.9342 - val_loss: 10.1008 - val_mae: 2.6111\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.0753 - mae: 2.9523 - val_loss: 10.5424 - val_mae: 2.6562\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 13.2635 - mae: 2.9728 - val_loss: 10.1151 - val_mae: 2.6191\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.7552 - mae: 2.9020 - val_loss: 10.3407 - val_mae: 2.6584\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 13.0708 - mae: 2.9590 - val_loss: 10.7167 - val_mae: 2.6738\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 26s 279ms/step - loss: 12.9124 - mae: 2.9162 - val_loss: 9.9085 - val_mae: 2.6080\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.9090 - mae: 2.9178 - val_loss: 16.1398 - val_mae: 3.1361\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 12.6209 - mae: 2.8827 - val_loss: 12.9991 - val_mae: 2.8712\n",
            "Epoch 201/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 13.1236 - mae: 2.9168 - val_loss: 11.1612 - val_mae: 2.7086\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 12.8079 - mae: 2.9147 - val_loss: 9.9534 - val_mae: 2.5956\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.3965 - mae: 2.8684 - val_loss: 10.1441 - val_mae: 2.6397\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.9800 - mae: 2.9010 - val_loss: 10.8276 - val_mae: 2.6870\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.7478 - mae: 2.9128 - val_loss: 11.0229 - val_mae: 2.7001\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 12.5155 - mae: 2.8883 - val_loss: 10.8181 - val_mae: 2.6876\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.4700 - mae: 2.8664 - val_loss: 10.5414 - val_mae: 2.6296\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.0666 - mae: 2.8343 - val_loss: 14.8190 - val_mae: 3.0153\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.7125 - mae: 2.9109 - val_loss: 12.8477 - val_mae: 2.8507\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 13.1725 - mae: 2.9374 - val_loss: 19.1786 - val_mae: 3.3805\n",
            "Epoch 211/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.2448 - mae: 2.9434 - val_loss: 21.8264 - val_mae: 3.5799\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.1792 - mae: 2.9550 - val_loss: 11.3903 - val_mae: 2.7307\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.2066 - mae: 2.8607 - val_loss: 18.3145 - val_mae: 3.3318\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.3778 - mae: 2.9616 - val_loss: 10.7996 - val_mae: 2.6808\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.0579 - mae: 2.9370 - val_loss: 22.2782 - val_mae: 3.6383\n",
            "Epoch 216/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.7685 - mae: 2.9101 - val_loss: 12.4740 - val_mae: 2.8331\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.7283 - mae: 2.9136 - val_loss: 17.7500 - val_mae: 3.2567\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.6355 - mae: 2.9663 - val_loss: 18.0771 - val_mae: 3.2856\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 23s 259ms/step - loss: 12.8195 - mae: 2.9034 - val_loss: 17.2349 - val_mae: 3.2197\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.4084 - mae: 2.8793 - val_loss: 14.9206 - val_mae: 3.0040\n",
            "Epoch 221/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.7882 - mae: 2.8931 - val_loss: 17.2894 - val_mae: 3.2247\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 13.0871 - mae: 2.9301 - val_loss: 14.6490 - val_mae: 3.0048\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.8646 - mae: 2.9040 - val_loss: 15.3721 - val_mae: 3.0509\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.8853 - mae: 2.9019 - val_loss: 15.8041 - val_mae: 3.0869\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 13.2718 - mae: 2.9652 - val_loss: 11.7103 - val_mae: 2.7619\n",
            "Epoch 226/500\n",
            "89/89 [==============================] - 23s 249ms/step - loss: 13.1102 - mae: 2.9482 - val_loss: 21.6095 - val_mae: 3.5807\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.6767 - mae: 2.9063 - val_loss: 12.7037 - val_mae: 2.8424\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.6458 - mae: 2.8874 - val_loss: 14.0333 - val_mae: 2.9513\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.0169 - mae: 2.9376 - val_loss: 12.2819 - val_mae: 2.8174\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 14.0798 - mae: 3.0363 - val_loss: 15.6399 - val_mae: 3.0772\n",
            "Epoch 231/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.7403 - mae: 2.9080 - val_loss: 14.0375 - val_mae: 2.9495\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.5950 - mae: 2.9033 - val_loss: 11.3745 - val_mae: 2.7340\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.6586 - mae: 2.9100 - val_loss: 11.2185 - val_mae: 2.7203\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.9080 - mae: 2.9127 - val_loss: 15.1121 - val_mae: 3.0344\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.4648 - mae: 2.8665 - val_loss: 13.2082 - val_mae: 2.8584\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - 26s 281ms/step - loss: 12.7141 - mae: 2.9072 - val_loss: 10.2376 - val_mae: 2.6501\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.6332 - mae: 2.9082 - val_loss: 13.3629 - val_mae: 2.8890\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.6547 - mae: 2.8825 - val_loss: 11.7404 - val_mae: 2.7736\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.1959 - mae: 2.8442 - val_loss: 12.3765 - val_mae: 2.7854\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.0671 - mae: 2.8330 - val_loss: 11.9167 - val_mae: 2.7655\n",
            "Epoch 241/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.8548 - mae: 2.8920 - val_loss: 13.9092 - val_mae: 2.9273\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.0701 - mae: 2.9202 - val_loss: 11.6716 - val_mae: 2.7463\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 12.6917 - mae: 2.8869 - val_loss: 14.3616 - val_mae: 2.9827\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 21s 229ms/step - loss: 13.0671 - mae: 2.9276 - val_loss: 16.2719 - val_mae: 3.1340\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 13.0826 - mae: 2.9163 - val_loss: 15.6821 - val_mae: 3.0861\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.3032 - mae: 2.9479 - val_loss: 10.8313 - val_mae: 2.6891\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 26s 283ms/step - loss: 12.5826 - mae: 2.8836 - val_loss: 30.7739 - val_mae: 4.2628\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 26s 280ms/step - loss: 12.3332 - mae: 2.8529 - val_loss: 22.8426 - val_mae: 3.6531\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.9950 - mae: 2.9399 - val_loss: 15.8587 - val_mae: 3.0985\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.9321 - mae: 2.9365 - val_loss: 11.2421 - val_mae: 2.7204\n",
            "Epoch 251/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.7141 - mae: 2.8955 - val_loss: 16.1300 - val_mae: 3.1174\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.0413 - mae: 2.9023 - val_loss: 20.8489 - val_mae: 3.4951\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 13.0103 - mae: 2.9231 - val_loss: 11.9935 - val_mae: 2.7878\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.9807 - mae: 2.9359 - val_loss: 10.3075 - val_mae: 2.6489\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 22s 245ms/step - loss: 12.8759 - mae: 2.9380 - val_loss: 11.0890 - val_mae: 2.7189\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 13.0901 - mae: 2.9470 - val_loss: 11.5712 - val_mae: 2.7553\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.6065 - mae: 2.9129 - val_loss: 12.8524 - val_mae: 2.8506\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.7011 - mae: 2.8960 - val_loss: 16.8931 - val_mae: 3.1689\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 12.7523 - mae: 2.9094 - val_loss: 12.8259 - val_mae: 2.8493\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.9886 - mae: 2.9215 - val_loss: 15.1475 - val_mae: 3.0199\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.1920 - mae: 2.9334 - val_loss: 14.6579 - val_mae: 2.9681\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.1809 - mae: 2.8475 - val_loss: 16.7030 - val_mae: 3.1650\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 13.0435 - mae: 2.9326 - val_loss: 11.0368 - val_mae: 2.6848\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.7262 - mae: 2.9103 - val_loss: 17.5228 - val_mae: 3.2405\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.6864 - mae: 2.8897 - val_loss: 15.1409 - val_mae: 3.0307\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.4328 - mae: 2.8633 - val_loss: 16.3451 - val_mae: 3.1450\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.2606 - mae: 2.8735 - val_loss: 28.6721 - val_mae: 4.0999\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 23s 246ms/step - loss: 12.9041 - mae: 2.9115 - val_loss: 19.5136 - val_mae: 3.3911\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.2403 - mae: 2.9759 - val_loss: 13.2475 - val_mae: 2.8907\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.7636 - mae: 2.8904 - val_loss: 13.1454 - val_mae: 2.8560\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.9454 - mae: 2.9313 - val_loss: 18.7899 - val_mae: 3.3289\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.6373 - mae: 2.8989 - val_loss: 13.2536 - val_mae: 2.8728\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 13.2958 - mae: 2.9522 - val_loss: 17.4545 - val_mae: 3.2180\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.2642 - mae: 2.8513 - val_loss: 12.6557 - val_mae: 2.8317\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.4353 - mae: 2.8589 - val_loss: 13.7276 - val_mae: 2.9083\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 13.2546 - mae: 2.9234 - val_loss: 13.5419 - val_mae: 2.8854\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 12.1904 - mae: 2.8374 - val_loss: 10.4312 - val_mae: 2.6488\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.3939 - mae: 2.8801 - val_loss: 10.8735 - val_mae: 2.6964\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.8025 - mae: 2.9095 - val_loss: 10.9361 - val_mae: 2.6931\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.2141 - mae: 2.8504 - val_loss: 12.5501 - val_mae: 2.8454\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 11.9275 - mae: 2.8167 - val_loss: 11.4519 - val_mae: 2.7384\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.7904 - mae: 2.8923 - val_loss: 19.8365 - val_mae: 3.4323\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.2182 - mae: 2.8419 - val_loss: 15.5227 - val_mae: 3.0610\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.3971 - mae: 2.8530 - val_loss: 15.6396 - val_mae: 3.0608\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 14.3229 - mae: 3.0174 - val_loss: 13.9034 - val_mae: 2.9275\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.5307 - mae: 2.8852 - val_loss: 15.7723 - val_mae: 3.0774\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.3080 - mae: 2.9732 - val_loss: 13.9781 - val_mae: 2.9263\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.7815 - mae: 2.9061 - val_loss: 12.2149 - val_mae: 2.7871\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 21s 228ms/step - loss: 12.6553 - mae: 2.8842 - val_loss: 11.9910 - val_mae: 2.7858\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.9201 - mae: 2.9352 - val_loss: 22.4491 - val_mae: 3.6569\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 26s 285ms/step - loss: 12.4479 - mae: 2.8451 - val_loss: 20.3784 - val_mae: 3.4751\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.6281 - mae: 2.9249 - val_loss: 12.9109 - val_mae: 2.8647\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.7525 - mae: 2.9061 - val_loss: 10.9565 - val_mae: 2.6945\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 13.0340 - mae: 2.9440 - val_loss: 10.8842 - val_mae: 2.6930\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.3522 - mae: 2.8854 - val_loss: 16.4747 - val_mae: 3.1250\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.6568 - mae: 2.9107 - val_loss: 29.9961 - val_mae: 4.2647\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.2821 - mae: 2.8492 - val_loss: 13.7152 - val_mae: 2.9253\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 26s 282ms/step - loss: 11.9316 - mae: 2.8193 - val_loss: 13.9833 - val_mae: 2.9200\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 11.9488 - mae: 2.8237 - val_loss: 14.9406 - val_mae: 3.0167\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.4260 - mae: 2.8587 - val_loss: 17.3761 - val_mae: 3.2247\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.9388 - mae: 2.8760 - val_loss: 18.3231 - val_mae: 3.2880\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 12.5001 - mae: 2.8500 - val_loss: 16.4986 - val_mae: 3.1519\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 12.7614 - mae: 2.9312 - val_loss: 10.8392 - val_mae: 2.6967\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 14.4147 - mae: 3.0910 - val_loss: 10.0711 - val_mae: 2.6236\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.6987 - mae: 2.9113 - val_loss: 11.2895 - val_mae: 2.7274\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.6989 - mae: 2.9163 - val_loss: 17.9834 - val_mae: 3.2585\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 11.9435 - mae: 2.8288 - val_loss: 14.9064 - val_mae: 3.0035\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 12.5646 - mae: 2.8990 - val_loss: 12.6132 - val_mae: 2.8389\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 28s 318ms/step - loss: 12.9589 - mae: 2.9336 - val_loss: 15.0008 - val_mae: 3.0153\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.5009 - mae: 2.9027 - val_loss: 14.4034 - val_mae: 2.9727\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 26s 290ms/step - loss: 12.7833 - mae: 2.8972 - val_loss: 14.5424 - val_mae: 2.9783\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 26s 284ms/step - loss: 12.2669 - mae: 2.8473 - val_loss: 10.7421 - val_mae: 2.6982\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.6947 - mae: 2.9010 - val_loss: 11.1223 - val_mae: 2.7155\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.8750 - mae: 2.9330 - val_loss: 13.7842 - val_mae: 2.9083\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 12.7495 - mae: 2.9088 - val_loss: 12.2836 - val_mae: 2.7957\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.7741 - mae: 2.8976 - val_loss: 10.3337 - val_mae: 2.6514\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 12.2193 - mae: 2.8384 - val_loss: 14.6089 - val_mae: 2.9853\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 13.0961 - mae: 2.9465 - val_loss: 14.2879 - val_mae: 2.9605\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.7750 - mae: 2.9292 - val_loss: 11.1509 - val_mae: 2.7309\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.5409 - mae: 3.0010 - val_loss: 11.3429 - val_mae: 2.7423\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.9733 - mae: 2.9455 - val_loss: 11.1080 - val_mae: 2.7131\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 12.5368 - mae: 2.8788 - val_loss: 13.4792 - val_mae: 2.9218\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.7230 - mae: 2.8821 - val_loss: 19.0632 - val_mae: 3.3495\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 13.4757 - mae: 2.9594 - val_loss: 11.0037 - val_mae: 2.7124\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.9190 - mae: 2.9251 - val_loss: 13.7106 - val_mae: 2.9407\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 23s 245ms/step - loss: 13.1731 - mae: 2.9706 - val_loss: 10.7370 - val_mae: 2.6761\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.8204 - mae: 2.9316 - val_loss: 10.9428 - val_mae: 2.7051\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 28s 295ms/step - loss: 12.1504 - mae: 2.8633 - val_loss: 17.7348 - val_mae: 3.2436\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.4514 - mae: 2.8842 - val_loss: 12.4769 - val_mae: 2.8401\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.2218 - mae: 2.9599 - val_loss: 12.4688 - val_mae: 2.8349\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.4531 - mae: 2.8791 - val_loss: 15.6126 - val_mae: 3.0651\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.8484 - mae: 2.9153 - val_loss: 16.6513 - val_mae: 3.1412\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 12.3062 - mae: 2.8623 - val_loss: 11.0614 - val_mae: 2.7033\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 22s 237ms/step - loss: 13.3910 - mae: 2.9695 - val_loss: 11.3410 - val_mae: 2.7467\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 22s 234ms/step - loss: 12.8640 - mae: 2.9215 - val_loss: 14.0235 - val_mae: 2.9385\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 24s 249ms/step - loss: 12.8581 - mae: 2.9188 - val_loss: 10.8615 - val_mae: 2.6888\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.5058 - mae: 2.8950 - val_loss: 19.2883 - val_mae: 3.3678\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 31s 340ms/step - loss: 13.2989 - mae: 2.9447 - val_loss: 16.2411 - val_mae: 3.1279\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.3739 - mae: 2.8730 - val_loss: 12.2547 - val_mae: 2.8349\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.1535 - mae: 2.9561 - val_loss: 11.1567 - val_mae: 2.7138\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 22s 244ms/step - loss: 12.7497 - mae: 2.9032 - val_loss: 13.0892 - val_mae: 2.8997\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.4592 - mae: 2.8726 - val_loss: 13.5663 - val_mae: 2.9406\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.7837 - mae: 2.9046 - val_loss: 17.6330 - val_mae: 3.2247\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 27s 303ms/step - loss: 12.8860 - mae: 2.9013 - val_loss: 15.9012 - val_mae: 3.1032\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.8364 - mae: 2.9089 - val_loss: 18.7849 - val_mae: 3.3377\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.4743 - mae: 2.9692 - val_loss: 10.1209 - val_mae: 2.6214\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 13.4513 - mae: 2.9744 - val_loss: 10.0521 - val_mae: 2.6182\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 12.9775 - mae: 2.9228 - val_loss: 15.5652 - val_mae: 3.0726\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 13.8367 - mae: 2.9767 - val_loss: 11.0534 - val_mae: 2.6972\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 29s 321ms/step - loss: 12.4729 - mae: 2.8815 - val_loss: 20.8748 - val_mae: 3.5070\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.3693 - mae: 2.8558 - val_loss: 16.1359 - val_mae: 3.1367\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 13.2926 - mae: 2.9459 - val_loss: 13.1295 - val_mae: 2.8926\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.5952 - mae: 2.8954 - val_loss: 16.9439 - val_mae: 3.2026\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.4039 - mae: 2.8813 - val_loss: 16.5693 - val_mae: 3.1697\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.4911 - mae: 2.8752 - val_loss: 14.5899 - val_mae: 2.9839\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.9484 - mae: 2.9210 - val_loss: 11.3627 - val_mae: 2.7571\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 12.1404 - mae: 2.8395 - val_loss: 11.2394 - val_mae: 2.7358\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.6857 - mae: 2.9050 - val_loss: 16.3927 - val_mae: 3.1573\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.5363 - mae: 2.9001 - val_loss: 14.6931 - val_mae: 2.9992\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 12.8693 - mae: 2.9058 - val_loss: 13.5738 - val_mae: 2.9273\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 13.8179 - mae: 3.0120 - val_loss: 10.4848 - val_mae: 2.6715\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.5492 - mae: 2.8917 - val_loss: 13.4335 - val_mae: 2.8967\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.8399 - mae: 2.9234 - val_loss: 13.5761 - val_mae: 2.9097\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 13.1443 - mae: 2.9218 - val_loss: 14.7624 - val_mae: 2.9947\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 12.4656 - mae: 2.8562 - val_loss: 18.0316 - val_mae: 3.2494\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 12.9041 - mae: 2.9215 - val_loss: 10.4594 - val_mae: 2.6626\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 12.8924 - mae: 2.9436 - val_loss: 11.0358 - val_mae: 2.7068\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 30s 326ms/step - loss: 13.0611 - mae: 2.9058 - val_loss: 13.2540 - val_mae: 2.8935\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.1698 - mae: 2.9119 - val_loss: 16.9103 - val_mae: 3.1579\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 12.5283 - mae: 2.8868 - val_loss: 14.9416 - val_mae: 3.0095\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 12.9195 - mae: 2.9075 - val_loss: 13.4453 - val_mae: 2.9066\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.6283 - mae: 2.9155 - val_loss: 10.8373 - val_mae: 2.6847\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 12.4907 - mae: 2.8753 - val_loss: 14.4422 - val_mae: 2.9746\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 13.1319 - mae: 2.9262 - val_loss: 12.2115 - val_mae: 2.7931\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 13.0094 - mae: 2.9160 - val_loss: 11.3812 - val_mae: 2.7285\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 12.5868 - mae: 2.8780 - val_loss: 9.9289 - val_mae: 2.6141\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 13.2054 - mae: 2.9516 - val_loss: 10.2988 - val_mae: 2.6376\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 13.7900 - mae: 3.0344 - val_loss: 10.7915 - val_mae: 2.7099\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.1582 - mae: 2.8582 - val_loss: 10.8407 - val_mae: 2.6916\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 12.9656 - mae: 2.9346 - val_loss: 13.3488 - val_mae: 2.8817\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 12.4354 - mae: 2.8676 - val_loss: 13.1314 - val_mae: 2.8589\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 12.1515 - mae: 2.8582 - val_loss: 11.4945 - val_mae: 2.7611\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 12.3163 - mae: 2.8707 - val_loss: 14.0128 - val_mae: 2.9173\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.5489 - mae: 2.8882 - val_loss: 10.7577 - val_mae: 2.6766\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 13.0149 - mae: 2.9375 - val_loss: 13.7088 - val_mae: 2.8907\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 13.0672 - mae: 2.9386 - val_loss: 12.4040 - val_mae: 2.8352\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.3803 - mae: 2.9767 - val_loss: 12.0778 - val_mae: 2.7970\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.8048 - mae: 2.8861 - val_loss: 16.9217 - val_mae: 3.1643\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 13.1529 - mae: 2.9521 - val_loss: 10.3419 - val_mae: 2.6427\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.7655 - mae: 2.8910 - val_loss: 20.0920 - val_mae: 3.4280\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 12.9005 - mae: 2.9163 - val_loss: 11.0459 - val_mae: 2.7141\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 12.2613 - mae: 2.8490 - val_loss: 14.3413 - val_mae: 2.9569\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.5163 - mae: 2.8945 - val_loss: 12.7162 - val_mae: 2.8393\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 26s 289ms/step - loss: 13.4492 - mae: 2.9512 - val_loss: 10.6721 - val_mae: 2.6630\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 27s 292ms/step - loss: 12.8998 - mae: 2.9443 - val_loss: 13.0468 - val_mae: 2.8272\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 12.7890 - mae: 2.9151 - val_loss: 10.4822 - val_mae: 2.6467\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 12.6309 - mae: 2.8863 - val_loss: 11.8056 - val_mae: 2.7629\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.5021 - mae: 2.8784 - val_loss: 13.6482 - val_mae: 2.9022\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 12.6956 - mae: 2.9159 - val_loss: 14.4781 - val_mae: 2.9771\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.6850 - mae: 2.8908 - val_loss: 13.0672 - val_mae: 2.8546\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 12.3344 - mae: 2.8846 - val_loss: 15.4095 - val_mae: 3.0383\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 11.9988 - mae: 2.8386 - val_loss: 20.0296 - val_mae: 3.4353\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.2686 - mae: 2.8598 - val_loss: 11.2044 - val_mae: 2.7184\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 13.0942 - mae: 2.9224 - val_loss: 17.4424 - val_mae: 3.1863\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 21s 233ms/step - loss: 12.6531 - mae: 2.8618 - val_loss: 20.1693 - val_mae: 3.4126\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 28s 296ms/step - loss: 12.7595 - mae: 2.9080 - val_loss: 22.3142 - val_mae: 3.5973\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 28s 304ms/step - loss: 12.9984 - mae: 2.8963 - val_loss: 20.2646 - val_mae: 3.4208\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 27s 293ms/step - loss: 12.8371 - mae: 2.8984 - val_loss: 12.6999 - val_mae: 2.8206\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.8533 - mae: 2.9170 - val_loss: 16.8149 - val_mae: 3.1452\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.6413 - mae: 2.8942 - val_loss: 12.1878 - val_mae: 2.7902\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.8795 - mae: 2.8872 - val_loss: 18.3443 - val_mae: 3.2374\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 13.0671 - mae: 2.9301 - val_loss: 18.4682 - val_mae: 3.2587\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 16.0272 - mae: 3.2200 - val_loss: 15.8466 - val_mae: 3.2808\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 14.4377 - mae: 3.0875 - val_loss: 10.0212 - val_mae: 2.6122\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 28s 310ms/step - loss: 13.0360 - mae: 2.9510 - val_loss: 9.8441 - val_mae: 2.5727\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 29s 315ms/step - loss: 12.4687 - mae: 2.8959 - val_loss: 10.5743 - val_mae: 2.6870\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 29s 313ms/step - loss: 13.6033 - mae: 2.9638 - val_loss: 11.9806 - val_mae: 2.7719\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 29s 314ms/step - loss: 12.5296 - mae: 2.8507 - val_loss: 10.7853 - val_mae: 2.6633\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 29s 316ms/step - loss: 12.8047 - mae: 2.9183 - val_loss: 10.3732 - val_mae: 2.6407\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 12.7250 - mae: 2.8817 - val_loss: 10.3581 - val_mae: 2.5374\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 12.1947 - mae: 2.8145 - val_loss: 10.8067 - val_mae: 2.6297\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 12.3709 - mae: 2.8702 - val_loss: 10.5123 - val_mae: 2.6442\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 12.2921 - mae: 2.8474 - val_loss: 10.2986 - val_mae: 2.6329\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.5380 - mae: 2.8641 - val_loss: 12.3385 - val_mae: 2.7940\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 12.3579 - mae: 2.8744 - val_loss: 11.3885 - val_mae: 2.7380\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 21s 231ms/step - loss: 13.0545 - mae: 2.9263 - val_loss: 10.2446 - val_mae: 2.6196\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 13.1092 - mae: 2.9639 - val_loss: 10.5052 - val_mae: 2.5771\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 28s 303ms/step - loss: 12.0309 - mae: 2.8002 - val_loss: 15.5001 - val_mae: 2.9882\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 11.4602 - mae: 2.7319 - val_loss: 19.7953 - val_mae: 3.3645\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 23s 247ms/step - loss: 12.4129 - mae: 2.8460 - val_loss: 9.5971 - val_mae: 2.4773\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 28s 301ms/step - loss: 12.6514 - mae: 2.8422 - val_loss: 9.9863 - val_mae: 2.5464\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 28s 294ms/step - loss: 12.6622 - mae: 2.8402 - val_loss: 9.7994 - val_mae: 2.5340\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 27s 289ms/step - loss: 12.1294 - mae: 2.8255 - val_loss: 14.5616 - val_mae: 2.9506\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 28s 300ms/step - loss: 12.6072 - mae: 2.8807 - val_loss: 17.7625 - val_mae: 3.2628\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 27s 291ms/step - loss: 11.9373 - mae: 2.7607 - val_loss: 12.8814 - val_mae: 2.7806\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 10.9874 - mae: 2.6824 - val_loss: 12.4970 - val_mae: 2.7176\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 11.3823 - mae: 2.7065 - val_loss: 18.0003 - val_mae: 3.2620\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 28s 313ms/step - loss: 11.4403 - mae: 2.7222 - val_loss: 13.9898 - val_mae: 2.8610\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 28s 313ms/step - loss: 11.5200 - mae: 2.7489 - val_loss: 11.5913 - val_mae: 2.6468\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 29s 317ms/step - loss: 11.3413 - mae: 2.7330 - val_loss: 16.0487 - val_mae: 3.0705\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 12.3934 - mae: 2.7867 - val_loss: 10.9319 - val_mae: 2.6255\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 28s 311ms/step - loss: 11.4420 - mae: 2.7240 - val_loss: 17.8892 - val_mae: 3.1975\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 12.0804 - mae: 2.7785 - val_loss: 17.4505 - val_mae: 3.1648\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 11.7832 - mae: 2.7446 - val_loss: 18.1181 - val_mae: 3.2116\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 11.3673 - mae: 2.6921 - val_loss: 16.9049 - val_mae: 3.1012\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 11.2110 - mae: 2.6737 - val_loss: 16.2123 - val_mae: 3.0448\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 27s 295ms/step - loss: 11.2548 - mae: 2.6451 - val_loss: 20.4536 - val_mae: 3.4096\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 11.0090 - mae: 2.6509 - val_loss: 12.3605 - val_mae: 2.7375\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 11.1627 - mae: 2.6715 - val_loss: 20.4721 - val_mae: 3.3850\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 26s 291ms/step - loss: 11.0100 - mae: 2.6306 - val_loss: 13.3389 - val_mae: 2.8216\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 26s 293ms/step - loss: 11.1722 - mae: 2.6808 - val_loss: 18.1574 - val_mae: 3.2167\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 11.2326 - mae: 2.6589 - val_loss: 16.3863 - val_mae: 3.0700\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 10.8908 - mae: 2.6552 - val_loss: 11.0137 - val_mae: 2.5766\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 28s 307ms/step - loss: 11.4884 - mae: 2.7022 - val_loss: 21.1896 - val_mae: 3.4699\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 11.0628 - mae: 2.6369 - val_loss: 17.8913 - val_mae: 3.2028\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 28s 308ms/step - loss: 11.5485 - mae: 2.6625 - val_loss: 12.4202 - val_mae: 2.7455\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 11.1628 - mae: 2.6394 - val_loss: 12.8309 - val_mae: 2.7802\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 27s 294ms/step - loss: 11.3835 - mae: 2.7153 - val_loss: 11.3789 - val_mae: 2.6384\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 26s 287ms/step - loss: 10.8061 - mae: 2.6443 - val_loss: 14.9762 - val_mae: 2.9732\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 29s 319ms/step - loss: 10.7755 - mae: 2.6183 - val_loss: 17.8208 - val_mae: 3.2045\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 29s 320ms/step - loss: 10.6841 - mae: 2.6249 - val_loss: 16.5611 - val_mae: 3.0947\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 27s 299ms/step - loss: 11.0621 - mae: 2.6642 - val_loss: 15.3627 - val_mae: 2.9843\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 23s 252ms/step - loss: 10.1043 - mae: 2.5543 - val_loss: 12.3855 - val_mae: 2.7144\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 10.4481 - mae: 2.5952 - val_loss: 17.6566 - val_mae: 3.1873\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 28s 309ms/step - loss: 10.5173 - mae: 2.5705 - val_loss: 12.4879 - val_mae: 2.7281\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 11.1748 - mae: 2.6319 - val_loss: 11.8210 - val_mae: 2.6534\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 27s 297ms/step - loss: 10.7881 - mae: 2.5956 - val_loss: 12.7324 - val_mae: 2.7643\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 27s 290ms/step - loss: 12.2000 - mae: 2.7844 - val_loss: 14.0790 - val_mae: 2.8765\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 28s 305ms/step - loss: 11.0309 - mae: 2.6194 - val_loss: 10.7227 - val_mae: 2.5834\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 28s 302ms/step - loss: 10.7869 - mae: 2.6102 - val_loss: 12.2685 - val_mae: 2.7103\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 28s 306ms/step - loss: 11.1094 - mae: 2.6561 - val_loss: 15.8079 - val_mae: 3.0129\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 27s 300ms/step - loss: 10.5334 - mae: 2.5578 - val_loss: 11.9488 - val_mae: 2.6570\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 27s 302ms/step - loss: 11.7875 - mae: 2.6943 - val_loss: 12.9069 - val_mae: 2.7667\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 22s 236ms/step - loss: 10.4916 - mae: 2.5708 - val_loss: 9.6860 - val_mae: 2.4443\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 28s 312ms/step - loss: 10.6903 - mae: 2.5895 - val_loss: 11.1876 - val_mae: 2.6130\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 27s 298ms/step - loss: 10.5266 - mae: 2.5848 - val_loss: 14.0371 - val_mae: 2.8766\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 26s 286ms/step - loss: 10.5172 - mae: 2.5619 - val_loss: 12.0392 - val_mae: 2.7046\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 21s 232ms/step - loss: 10.4574 - mae: 2.5708 - val_loss: 11.9139 - val_mae: 2.6726\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 10.7919 - mae: 2.5916 - val_loss: 12.5728 - val_mae: 2.7317\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 10.7399 - mae: 2.5861 - val_loss: 13.8241 - val_mae: 2.8253\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 22s 243ms/step - loss: 10.8329 - mae: 2.6059 - val_loss: 11.6728 - val_mae: 2.6687\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 27s 296ms/step - loss: 11.8282 - mae: 2.7284 - val_loss: 10.2795 - val_mae: 2.4982\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 27s 301ms/step - loss: 10.5162 - mae: 2.5821 - val_loss: 12.1373 - val_mae: 2.7131\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 23s 250ms/step - loss: 10.8586 - mae: 2.6044 - val_loss: 9.5670 - val_mae: 2.4728\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 28s 294ms/step - loss: 10.5407 - mae: 2.5680 - val_loss: 11.1598 - val_mae: 2.6042\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 34s 375ms/step - loss: 11.1110 - mae: 2.6330 - val_loss: 17.2595 - val_mae: 3.1127\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 34s 369ms/step - loss: 11.3255 - mae: 2.6576 - val_loss: 12.8595 - val_mae: 2.7722\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 34s 371ms/step - loss: 10.1195 - mae: 2.5403 - val_loss: 13.5074 - val_mae: 2.8244\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 34s 371ms/step - loss: 10.5051 - mae: 2.5650 - val_loss: 10.4046 - val_mae: 2.5472\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 34s 370ms/step - loss: 10.2977 - mae: 2.5610 - val_loss: 16.8433 - val_mae: 3.0787\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 34s 374ms/step - loss: 11.0499 - mae: 2.6599 - val_loss: 12.9652 - val_mae: 2.7938\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 34s 359ms/step - loss: 10.4823 - mae: 2.5610 - val_loss: 11.5511 - val_mae: 2.6780\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 34s 359ms/step - loss: 10.5803 - mae: 2.5613 - val_loss: 10.1227 - val_mae: 2.5366\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 34s 371ms/step - loss: 10.5177 - mae: 2.5774 - val_loss: 10.7941 - val_mae: 2.5780\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 34s 373ms/step - loss: 9.9750 - mae: 2.4744 - val_loss: 10.9060 - val_mae: 2.5894\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 34s 373ms/step - loss: 11.2425 - mae: 2.6856 - val_loss: 13.5924 - val_mae: 2.9015\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 34s 368ms/step - loss: 13.2392 - mae: 2.9141 - val_loss: 11.2364 - val_mae: 2.7196\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 34s 369ms/step - loss: 13.2774 - mae: 2.9345 - val_loss: 11.5434 - val_mae: 2.7345\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 34s 362ms/step - loss: 11.1391 - mae: 2.6542 - val_loss: 14.9581 - val_mae: 2.9950\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 34s 365ms/step - loss: 10.5797 - mae: 2.6015 - val_loss: 10.8808 - val_mae: 2.6153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b599363c-ddd0-4169-ea94-cc3cd3103246"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "6f3c8263-9c7f-47e5-e925-267eff0e74a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1_New_MAE_Flimpano_Male18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}