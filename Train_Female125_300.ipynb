{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/Train_Female125_300.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "65240284-1374-4437-f5ad-4d130d17f5a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Female_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "outputId": "a4fea29f-c433-4f47-a35c-1a7a00ceeb32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7   Y7F         V1.jpg   \n",
              "1           2               1          7   Y7F    Flip_V1.jpg   \n",
              "2           3               2          7   Y7F         V2.jpg   \n",
              "3           4               2          7   Y7F    Flip_V2.jpg   \n",
              "4           5               3          7   Y7F         V3.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              65         25  Y25F  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fefa261-7d49-4bed-8e45-15581003bf49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fefa261-7d49-4bed-8e45-15581003bf49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fefa261-7d49-4bed-8e45-15581003bf49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fefa261-7d49-4bed-8e45-15581003bf49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ขาดอายุ 14"
      ],
      "metadata": {
        "id": "UGcz4TH8GSPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Y7F','Y8F','Y9F','Y10F','Y11F','Y12F','Y13F','15F','14F','Y16F','Y17F','Y18F','Y19F','Y20F','Y21F','Y22F','Y23F','Y24F','Y25F']\n",
        "len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRBrW9is1vcq",
        "outputId": "78e6c973-7fc7-4855-8af9-3b12ce191bbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34H1ad-Q2gAN",
        "outputId": "f387c131-99d8-48f3-c446-09ec6cceab3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2375, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(df['Class']))\n",
        "print(set(df['Sex']))\n",
        "print(set(df['Floder']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A29byGc029YW",
        "outputId": "8a31f933-a774-4d3f-bf85-cb99fb2e992b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Y19F', 'Y25F', 'Y22F', 'Y7F', 'Y18F', 'Y24F', 'Y12F', 'Y15F', 'Y13F', 'Y23F', 'Y9F', 'Y21F', 'Y10F', 'Y20F', 'Y17F', 'Y11F', 'Y14F', 'Y8F', 'Y16F'}\n",
            "{'เพศหญิง'}\n",
            "{'Both', 'Rt', 'Lt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 300\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "856bf1e5-bfed-4dfb-f603-6b6cebdd8afc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 413, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 413 (delta 173), reused 157 (delta 130), pack-reused 184\u001b[K\n",
            "Receiving objects: 100% (413/413), 8.07 MiB | 12.37 MiB/s, done.\n",
            "Resolving deltas: 100% (246/246), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "4426e975-f03b-4e0c-f622-ed52372a631e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "215abe76-d7da-4971-9b2d-9e80f30ae37d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##สร้างโฟลเดอร์ Train ของแต่ละอายุและแบ่งเป็นเพศหญิงและเพศชาย"
      ],
      "metadata": {
        "id": "kpJJ-arYLhAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_Y7F_dir = os.path.join(train_dir, 'Y7F')\n",
        "os.makedirs(train_Y7F_dir, exist_ok=True)\n",
        "\n",
        "train_Y8F_dir = os.path.join(train_dir, 'Y8F')\n",
        "os.makedirs(train_Y8F_dir, exist_ok=True)\n",
        "\n",
        "train_Y9F_dir = os.path.join(train_dir, 'Y9F')\n",
        "os.makedirs(train_Y9F_dir, exist_ok=True)\n",
        "\n",
        "train_Y10F_dir = os.path.join(train_dir, 'Y10F')\n",
        "os.makedirs(train_Y10F_dir, exist_ok=True)\n",
        "\n",
        "train_Y11F_dir = os.path.join(train_dir, 'Y11F')\n",
        "os.makedirs(train_Y11F_dir, exist_ok=True)\n",
        "\n",
        "train_Y12F_dir = os.path.join(train_dir, 'Y12F')\n",
        "os.makedirs(train_Y12F_dir, exist_ok=True)\n",
        "\n",
        "train_Y13F_dir = os.path.join(train_dir, 'Y13F')\n",
        "os.makedirs(train_Y13F_dir, exist_ok=True)\n",
        "\n",
        "train_Y14F_dir = os.path.join(train_dir, 'Y14F')\n",
        "os.makedirs(train_Y14F_dir, exist_ok=True)\n",
        "\n",
        "train_Y15F_dir = os.path.join(train_dir, 'Y15F')\n",
        "os.makedirs(train_Y15F_dir, exist_ok=True)\n",
        "\n",
        "train_Y16F_dir = os.path.join(train_dir, 'Y16F')\n",
        "os.makedirs(train_Y16F_dir, exist_ok=True)\n",
        "\n",
        "train_Y17F_dir = os.path.join(train_dir, 'Y17F')\n",
        "os.makedirs(train_Y17F_dir, exist_ok=True)\n",
        "\n",
        "train_Y18F_dir = os.path.join(train_dir, 'Y18F')\n",
        "os.makedirs(train_Y18F_dir, exist_ok=True)\n",
        "\n",
        "train_Y19F_dir = os.path.join(train_dir, 'Y19F')\n",
        "os.makedirs(train_Y19F_dir, exist_ok=True)\n",
        "\n",
        "train_Y20F_dir = os.path.join(train_dir, 'Y20F')\n",
        "os.makedirs(train_Y20F_dir, exist_ok=True)\n",
        "\n",
        "train_Y21F_dir = os.path.join(train_dir, 'Y21F')\n",
        "os.makedirs(train_Y21F_dir, exist_ok=True)\n",
        "\n",
        "train_Y22F_dir = os.path.join(train_dir, 'Y22F')\n",
        "os.makedirs(train_Y22F_dir, exist_ok=True)\n",
        "\n",
        "train_Y23F_dir = os.path.join(train_dir, 'Y23F')\n",
        "os.makedirs(train_Y23F_dir, exist_ok=True)\n",
        "\n",
        "train_Y24F_dir = os.path.join(train_dir, 'Y24F')\n",
        "os.makedirs(train_Y24F_dir, exist_ok=True)\n",
        "\n",
        "train_Y25F_dir = os.path.join(train_dir, 'Y25F')\n",
        "os.makedirs(train_Y25F_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "hdGel6FAGASi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##สร้างโฟลเดอร์ Validation ของแต่ละอายุและแบ่งเป็นเพศหญิงและเพศชาย"
      ],
      "metadata": {
        "id": "e-HMTWc1L5iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_Y7F_dir = os.path.join(validation_dir, 'Y7F')\n",
        "os.makedirs(validation_Y7F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "validation_Y8F_dir = os.path.join(validation_dir, 'Y8F')\n",
        "os.makedirs(validation_Y8F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "validation_Y9F_dir = os.path.join(validation_dir, 'Y9F')\n",
        "os.makedirs(validation_Y9F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "validation_Y10F_dir = os.path.join(validation_dir, 'Y10F')\n",
        "os.makedirs(validation_Y10F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y11F_dir = os.path.join(validation_dir, 'Y11F')\n",
        "os.makedirs(validation_Y11F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y12F_dir = os.path.join(validation_dir, 'Y12F')\n",
        "os.makedirs(validation_Y12F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y13F_dir = os.path.join(validation_dir, 'Y13F')\n",
        "os.makedirs(validation_Y13F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y14F_dir = os.path.join(validation_dir, 'Y14F')\n",
        "os.makedirs(validation_Y14F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y15F_dir = os.path.join(validation_dir, 'Y15F')\n",
        "os.makedirs(validation_Y15F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y16F_dir = os.path.join(validation_dir, 'Y16F')\n",
        "os.makedirs(validation_Y16F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y17F_dir = os.path.join(validation_dir, 'Y17F')\n",
        "os.makedirs(validation_Y17F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y18F_dir = os.path.join(validation_dir, 'Y18F')\n",
        "os.makedirs(validation_Y18F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y19F_dir = os.path.join(validation_dir, 'Y19F')\n",
        "os.makedirs(validation_Y19F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y20F_dir = os.path.join(validation_dir, 'Y20F')\n",
        "os.makedirs(validation_Y20F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y21F_dir = os.path.join(validation_dir, 'Y21F')\n",
        "os.makedirs(validation_Y21F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y22F_dir = os.path.join(validation_dir, 'Y22F')\n",
        "os.makedirs(validation_Y22F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y23F_dir = os.path.join(validation_dir, 'Y23F')\n",
        "os.makedirs(validation_Y23F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y24F_dir = os.path.join(validation_dir, 'Y24F')\n",
        "os.makedirs(validation_Y24F_dir, exist_ok=True)\n",
        "\n",
        "validation_Y25F_dir = os.path.join(validation_dir, 'Y25F')\n",
        "os.makedirs(validation_Y25F_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "pnGZfuzdJ6iW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##สร้างโฟลเดอร์ Test ของแต่ละอายุและแบ่งเป็นเพศหญิงและเพศชาย"
      ],
      "metadata": {
        "id": "8gaG2WaYL9wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_Y7F_dir = os.path.join(test_dir, 'Y7F')\n",
        "os.makedirs(test_Y7F_dir, exist_ok=True)\n",
        "\n",
        "test_Y8F_dir = os.path.join(test_dir, 'Y8F')\n",
        "os.makedirs(test_Y8F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y9F_dir = os.path.join(test_dir, 'Y9F')\n",
        "os.makedirs(test_Y9F_dir, exist_ok=True)\n",
        "\n",
        "test_Y10F_dir = os.path.join(test_dir, 'Y10F')\n",
        "os.makedirs(test_Y10F_dir, exist_ok=True)\n",
        "\n",
        "test_Y11F_dir = os.path.join(test_dir, 'Y11F')\n",
        "os.makedirs(test_Y11F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y12F_dir = os.path.join(test_dir, 'Y12F')\n",
        "os.makedirs(test_Y12F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y13F_dir = os.path.join(test_dir, 'Y13F')\n",
        "os.makedirs(test_Y13F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y14F_dir = os.path.join(test_dir, 'Y14F')\n",
        "os.makedirs(test_Y14F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y15F_dir = os.path.join(test_dir, 'Y15F')\n",
        "os.makedirs(test_Y15F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y16F_dir = os.path.join(test_dir, 'Y16F')\n",
        "os.makedirs(test_Y16F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y17F_dir = os.path.join(test_dir, 'Y17F')\n",
        "os.makedirs(test_Y17F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y18F_dir = os.path.join(test_dir, 'Y18F')\n",
        "os.makedirs(test_Y18F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y19F_dir = os.path.join(test_dir, 'Y19F')\n",
        "os.makedirs(test_Y19F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y20F_dir = os.path.join(test_dir, 'Y20F')\n",
        "os.makedirs(test_Y20F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y21F_dir = os.path.join(test_dir, 'Y21F')\n",
        "os.makedirs(test_Y21F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y22F_dir = os.path.join(test_dir, 'Y22F')\n",
        "os.makedirs(test_Y22F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y23F_dir = os.path.join(test_dir, 'Y23F')\n",
        "os.makedirs(test_Y23F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y24F_dir = os.path.join(test_dir, 'Y24F')\n",
        "os.makedirs(test_Y24F_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "test_Y25F_dir = os.path.join(test_dir, 'Y25F')\n",
        "os.makedirs(test_Y25F_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "FJAX4QxtKyjz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oLVNWv5g4Xwv",
        "outputId": "a9362ee4-6ac8-4e5b-ef46-7cef59ed25f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7   Y7F         V1.jpg   \n",
              "1           2               1          7   Y7F    Flip_V1.jpg   \n",
              "2           3               2          7   Y7F         V2.jpg   \n",
              "3           4               2          7   Y7F    Flip_V2.jpg   \n",
              "4           5               3          7   Y7F         V3.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              65         25  Y25F  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1751bc0-afc0-4556-9a5d-f73880907af0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7F</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1751bc0-afc0-4556-9a5d-f73880907af0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1751bc0-afc0-4556-9a5d-f73880907af0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1751bc0-afc0-4556-9a5d-f73880907af0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = df[df['Fig_Age'].between(76,100)]\n",
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "test = df[df['Fig_Age'].between(101,125)]\n",
        "\n",
        "#Path Train\n",
        "Y7F_train = train[train['Class']=='Y7F' ]\n",
        "Y7F_path_train = Y7F_train['Path_filename'].tolist() \n",
        "\n",
        "Y8F_train = train[train['Class']=='Y8F' ]\n",
        "Y8F_path_train = Y8F_train['Path_filename'].tolist() \n",
        "\n",
        "Y9F_train = train[train['Class']=='Y9F' ]\n",
        "Y9F_path_train = Y9F_train['Path_filename'].tolist()\n",
        "\n",
        "Y10F_train = train[train['Class']=='Y10F' ]\n",
        "Y10F_path_train = Y10F_train['Path_filename'].tolist()\n",
        "\n",
        "Y11F_train = train[train['Class']=='Y11F' ]\n",
        "Y11F_path_train = Y11F_train['Path_filename'].tolist()\n",
        "\n",
        "Y12F_train = train[train['Class']=='Y12F' ]\n",
        "Y12F_path_train = Y12F_train['Path_filename'].tolist()\n",
        "\n",
        "Y13F_train = train[train['Class']=='Y13F' ]\n",
        "Y13F_path_train = Y13F_train['Path_filename'].tolist()\n",
        "\n",
        "Y14F_train = train[train['Class']=='Y14F' ]\n",
        "Y14F_path_train = Y14F_train['Path_filename'].tolist()\n",
        "\n",
        "Y15F_train = train[train['Class']=='Y15F' ]\n",
        "Y15F_path_train = Y15F_train['Path_filename'].tolist()\n",
        "\n",
        "Y16F_train = train[train['Class']=='Y16F' ]\n",
        "Y16F_path_train = Y16F_train['Path_filename'].tolist() \n",
        "\n",
        "Y17F_train = train[train['Class']=='Y17F' ]\n",
        "Y17F_path_train = Y17F_train['Path_filename'].tolist()\n",
        "\n",
        "Y18F_train = train[train['Class']=='Y18F' ]\n",
        "Y18F_path_train = Y18F_train['Path_filename'].tolist()\n",
        "\n",
        "Y19F_train = train[train['Class']=='Y19F' ]\n",
        "Y19F_path_train = Y19F_train['Path_filename'].tolist()\n",
        "\n",
        "Y20F_train = train[train['Class']=='Y20F' ]\n",
        "Y20F_path_train = Y20F_train['Path_filename'].tolist()\n",
        "\n",
        "Y21F_train = train[train['Class']=='Y21F' ]\n",
        "Y21F_path_train = Y21F_train['Path_filename'].tolist()\n",
        "\n",
        "Y22F_train = train[train['Class']=='Y22F' ]\n",
        "Y22F_path_train = Y22F_train['Path_filename'].tolist()\n",
        "\n",
        "Y23F_train = train[train['Class']=='Y23F' ]\n",
        "Y23F_path_train = Y23F_train['Path_filename'].tolist()\n",
        "\n",
        "Y24F_train = train[train['Class']=='Y24F' ]\n",
        "Y24F_path_train = Y24F_train['Path_filename'].tolist()\n",
        "\n",
        "Y25F_train = train[train['Class']=='Y25F' ]\n",
        "Y25F_path_train = Y25F_train['Path_filename'].tolist()\n",
        "\n",
        "#Path Validation\n",
        "Y7F_val = val[val['Class']=='Y7F' ]\n",
        "Y7F_path_val = Y7F_val['Path_filename'].tolist() \n",
        "\n",
        "Y8F_val = val[val['Class']=='Y8F' ]\n",
        "Y8F_path_val = Y8F_val['Path_filename'].tolist() \n",
        "\n",
        "Y9F_val = val[val['Class']=='Y9F' ]\n",
        "Y9F_path_val = Y9F_val['Path_filename'].tolist()\n",
        "\n",
        "Y10F_val = val[val['Class']=='Y10F' ]\n",
        "Y10F_path_val = Y10F_val['Path_filename'].tolist()\n",
        "\n",
        "Y11F_val = val[val['Class']=='Y11F' ]\n",
        "Y11F_path_val = Y11F_val['Path_filename'].tolist()\n",
        "\n",
        "Y12F_val = val[val['Class']=='Y12F' ]\n",
        "Y12F_path_val = Y12F_val['Path_filename'].tolist()\n",
        "\n",
        "Y13F_val = val[val['Class']=='Y13F' ]\n",
        "Y13F_path_val = Y13F_val['Path_filename'].tolist()\n",
        "\n",
        "Y14F_val = val[val['Class']=='Y14F' ]\n",
        "Y14F_path_val = Y14F_val['Path_filename'].tolist()\n",
        "\n",
        "Y15F_val = val[val['Class']=='Y15F' ]\n",
        "Y15F_path_val = Y15F_val['Path_filename'].tolist()\n",
        "\n",
        "Y16F_val = val[val['Class']=='Y16F' ]\n",
        "Y16F_path_val = Y16F_val['Path_filename'].tolist() \n",
        "\n",
        "Y17F_val = val[val['Class']=='Y17F' ]\n",
        "Y17F_path_val = Y17F_val['Path_filename'].tolist()\n",
        "\n",
        "Y18F_val  = val[val ['Class']=='Y18F' ]\n",
        "Y18F_path_val = Y18F_val['Path_filename'].tolist()\n",
        "\n",
        "Y19F_val = val[val['Class']=='Y19F' ]\n",
        "Y19F_path_val = Y19F_val['Path_filename'].tolist()\n",
        "\n",
        "Y20F_val = val[val['Class']=='Y20F' ]\n",
        "Y20F_path_val = Y20F_val['Path_filename'].tolist()\n",
        "\n",
        "Y21F_val = val[val['Class']=='Y21F' ]\n",
        "Y21F_path_val = Y21F_val['Path_filename'].tolist()\n",
        "\n",
        "Y22F_val = val[val['Class']=='Y22F' ]\n",
        "Y22F_path_val = Y22F_val['Path_filename'].tolist()\n",
        "\n",
        "Y23F_val = val[val['Class']=='Y23F' ]\n",
        "Y23F_path_val = Y23F_val['Path_filename'].tolist()\n",
        "\n",
        "Y24F_val = val[val['Class']=='Y24F' ]\n",
        "Y24F_path_val = Y24F_val['Path_filename'].tolist()\n",
        "\n",
        "Y25F_val = val[val['Class']=='Y25F' ]\n",
        "Y25F_path_val = Y25F_val['Path_filename'].tolist()\n",
        "\n",
        "\n",
        "#Path Test\n",
        "Y7F_test = test[test['Class']=='Y7F' ]\n",
        "Y7F_path_test = Y7F_test['Path_filename'].tolist() \n",
        "\n",
        "Y8F_test = test[test['Class']=='Y8F' ]\n",
        "Y8F_path_test = Y8F_test['Path_filename'].tolist() \n",
        "\n",
        "Y9F_test = test[test['Class']=='Y9F' ]\n",
        "Y9F_path_test = Y9F_test['Path_filename'].tolist()\n",
        "\n",
        "Y10F_test = test[test['Class']=='Y10F' ]\n",
        "Y10F_path_test = Y10F_test['Path_filename'].tolist()\n",
        "\n",
        "Y11F_test = test[test['Class']=='Y11F' ]\n",
        "Y11F_path_test = Y11F_test['Path_filename'].tolist()\n",
        "\n",
        "Y12F_test = test[test['Class']=='Y12F' ]\n",
        "Y12F_path_test = Y12F_test['Path_filename'].tolist()\n",
        "\n",
        "Y13F_test = test[test['Class']=='Y13F' ]\n",
        "Y13F_path_test = Y13F_test['Path_filename'].tolist()\n",
        "\n",
        "Y14F_test = test[test['Class']=='Y14F' ]\n",
        "Y14F_path_test = Y14F_test['Path_filename'].tolist()\n",
        "\n",
        "Y15F_test = test[test['Class']=='Y15F' ]\n",
        "Y15F_path_test = Y15F_test['Path_filename'].tolist()\n",
        "\n",
        "Y16F_test = test[test['Class']=='Y16F' ]\n",
        "Y16F_path_test = Y16F_test['Path_filename'].tolist() \n",
        "\n",
        "Y17F_test = test[test['Class']=='Y17F' ]\n",
        "Y17F_path_test = Y17F_test['Path_filename'].tolist()\n",
        "\n",
        "Y18F_test = test[test['Class']=='Y18F' ]\n",
        "Y18F_path_test = Y18F_test['Path_filename'].tolist()\n",
        "\n",
        "Y19F_test = test[test['Class']=='Y19F' ]\n",
        "Y19F_path_test = Y19F_test['Path_filename'].tolist()\n",
        "\n",
        "\n",
        "Y20F_test = test[test['Class']=='Y20F' ]\n",
        "Y20F_path_test = Y20F_test['Path_filename'].tolist()\n",
        "\n",
        "Y21F_test = test[test['Class']=='Y21F' ]\n",
        "Y21F_path_test = Y21F_test['Path_filename'].tolist()\n",
        "\n",
        "Y22F_test = test[test['Class']=='Y22F' ]\n",
        "Y22F_path_test = Y22F_test['Path_filename'].tolist()\n",
        "\n",
        "Y23F_test = test[test['Class']=='Y23F' ]\n",
        "Y23F_path_test = Y23F_test['Path_filename'].tolist()\n",
        "\n",
        "Y24F_test = test[test['Class']=='Y24F' ]\n",
        "Y24F_path_test = Y24F_test['Path_filename'].tolist()\n",
        "\n",
        "Y25F_test = test[test['Class']=='Y25F' ]\n",
        "Y25F_path_test = Y25F_test['Path_filename'].tolist()"
      ],
      "metadata": {
        "id": "cJ0tqr00LCFd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train"
      ],
      "metadata": {
        "id": "lHYSDt6H9j7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = Y7F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y7F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "\n",
        "\n",
        "fnames = Y8F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y8F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y9F_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y9F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = Y10F_path_train \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y10F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y11F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y11F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "\n",
        "fnames = Y12F_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y12F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y13F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y13F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y14F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y14F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y15F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y15F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y16F_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y16F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "  \n",
        "\n",
        "fnames = Y17F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y17F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        " \n",
        "    \n",
        "fnames = Y18F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y18F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y19F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y19F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y20F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y20F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y21F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y21F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y22F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y22F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y23F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y23F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "\n",
        "fnames = Y24F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y24F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y25F_path_train\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y25F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "  "
      ],
      "metadata": {
        "id": "S72g_pKbZX8e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validation\n"
      ],
      "metadata": {
        "id": "BSKa05K59pL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = Y7F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y7F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y8F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y8F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y9F_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y9F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y10F_path_val \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y10F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y11F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y11F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "\n",
        "fnames = Y12F_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y12F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "    \n",
        "fnames = Y13F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y13F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y14F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y14F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    fnames = Y15F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y15F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y16F_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y16F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "\n",
        "    fnames = Y17F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y17F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        " \n",
        "    \n",
        "    fnames = Y18F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y18F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "    fnames = Y19F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y19F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y20F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y20F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y21F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y21F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "   \n",
        "\n",
        "    fnames = Y22F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y22F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "     \n",
        "\n",
        "    fnames = Y23F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y23F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "  \n",
        "\n",
        "    fnames = Y24F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y24F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        " \n",
        "\n",
        "    fnames = Y25F_path_val\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y25F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)"
      ],
      "metadata": {
        "id": "-z1SOXYF-0h_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "gEE-jxb59uiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = Y7F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y7F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y8F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y8F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y9F_path_test  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y9F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "fnames = Y10F_path_test \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y10F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    \n",
        "fnames = Y11F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y11F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "\n",
        "fnames = Y12F_path_test  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y12F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "    \n",
        "fnames = Y13F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y13F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = Y14F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y14F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y15F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y15F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    fnames = Y16F_path_test  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y16F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "\n",
        "    fnames = Y17F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y17F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "    \n",
        "    fnames = Y18F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y18F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y19F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y19F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y20F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y20F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y21F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y21F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y22F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y22F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "\n",
        "    fnames = Y23F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y23F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "   \n",
        "\n",
        "    fnames = Y24F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y24F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "    fnames = Y25F_path_test\n",
        "for fname in fnames:\n",
        "    dst = os.path.join(test_Y25F_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n"
      ],
      "metadata": {
        "id": "9i1M2u2v_kLt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Total Training"
      ],
      "metadata": {
        "id": "n_ebIH0GEWmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training 7years_Female images:', len(os.listdir(train_Y7F_dir))) \n",
        "print('total training 8years_Female images:', len(os.listdir(train_Y8F_dir)))\n",
        "print('total training 9years_Female images:', len(os.listdir(train_Y9F_dir)))\n",
        "print('total training 10years_Female images:', len(os.listdir(train_Y10F_dir))) \n",
        "print('total training 11years_Female images:', len(os.listdir(train_Y11F_dir)))\n",
        "print('total training 12years_Female images:', len(os.listdir(train_Y12F_dir)))\n",
        "print('total training 13years_Female images:', len(os.listdir(train_Y13F_dir))) \n",
        "print('total training 14years _Female images:', len(os.listdir(train_Y14F_dir))) \n",
        "print('total training 15years_Female images:', len(os.listdir(train_Y15F_dir))) \n",
        "print('total training 16years_Female images:', len(os.listdir(train_Y16F_dir)))\n",
        "print('total training 17years_Female images:', len(os.listdir(train_Y17F_dir)))\n",
        "print('total training 18years_Female images:', len(os.listdir(train_Y18F_dir))) \n",
        "print('total training 19years_Female images:', len(os.listdir(train_Y19F_dir))) \n",
        "print('total training 20years_Female images:', len(os.listdir(train_Y20F_dir))) \n",
        "print('total training 21years_Female images:', len(os.listdir(train_Y21F_dir))) \n",
        "print('total training 22years_Female images:', len(os.listdir(train_Y22F_dir))) \n",
        "print('total training 23years_Female images:', len(os.listdir(train_Y23F_dir))) \n",
        "print('total training 24years_Female images:', len(os.listdir(train_Y24F_dir))) \n",
        "print('total training 25years_Female images:', len(os.listdir(train_Y25F_dir)), '\\n')"
      ],
      "metadata": {
        "id": "zJlWrrinDGtc",
        "outputId": "1e4b2ca7-9a55-4946-8062-4df778184a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training 7years_Female images: 75\n",
            "total training 8years_Female images: 75\n",
            "total training 9years_Female images: 75\n",
            "total training 10years_Female images: 75\n",
            "total training 11years_Female images: 75\n",
            "total training 12years_Female images: 75\n",
            "total training 13years_Female images: 75\n",
            "total training 14years _Female images: 75\n",
            "total training 15years_Female images: 75\n",
            "total training 16years_Female images: 75\n",
            "total training 17years_Female images: 75\n",
            "total training 18years_Female images: 75\n",
            "total training 19years_Female images: 75\n",
            "total training 20years_Female images: 75\n",
            "total training 21years_Female images: 75\n",
            "total training 22years_Female images: 75\n",
            "total training 23years_Female images: 75\n",
            "total training 24years_Female images: 75\n",
            "total training 25years_Female images: 75 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Total Validation"
      ],
      "metadata": {
        "id": "c9-pd7I0Eeox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('total validation 7years_Female images:', len(os.listdir(validation_Y7F_dir))) \n",
        "print('total validation 8years_Female images:', len(os.listdir(validation_Y8F_dir)))\n",
        "print('total validation 9years_Female images:', len(os.listdir(validation_Y9F_dir)))\n",
        "print('total validation 10years_Female images:', len(os.listdir(validation_Y10F_dir))) \n",
        "print('total validation 11years_Female images:', len(os.listdir(validation_Y11F_dir)))\n",
        "print('total validation 12years_Female images:', len(os.listdir(validation_Y12F_dir)))\n",
        "print('total validation 13years_Female images:', len(os.listdir(validation_Y13F_dir))) \n",
        "print('total validation 14years _Female images:', len(os.listdir(validation_Y14F_dir))) \n",
        "print('total validation 15years_Female images:', len(os.listdir(validation_Y15F_dir))) \n",
        "print('total validation 16years_Female images:', len(os.listdir(validation_Y16F_dir)))\n",
        "print('total validation 17years_Female images:', len(os.listdir(validation_Y17F_dir)))\n",
        "print('total validation 18years_Female images:', len(os.listdir(validation_Y18F_dir))) \n",
        "print('total validation 19years_Female images:', len(os.listdir(validation_Y19F_dir))) \n",
        "print('total validation 20years_Female images:', len(os.listdir(validation_Y20F_dir))) \n",
        "print('total validation 21years_Female images:', len(os.listdir(validation_Y21F_dir))) \n",
        "print('total validation 22years_Female images:', len(os.listdir(validation_Y22F_dir))) \n",
        "print('total validation 23years_Female images:', len(os.listdir(validation_Y23F_dir))) \n",
        "print('total validation 24years_Female images:', len(os.listdir(validation_Y24F_dir))) \n",
        "print('total validation 25years_Female images:', len(os.listdir(validation_Y25F_dir)), '\\n')"
      ],
      "metadata": {
        "id": "feobw_67ezwu",
        "outputId": "f20352aa-ce18-4599-8d8c-86c51fd838f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total validation 7years_Female images: 25\n",
            "total validation 8years_Female images: 25\n",
            "total validation 9years_Female images: 25\n",
            "total validation 10years_Female images: 25\n",
            "total validation 11years_Female images: 25\n",
            "total validation 12years_Female images: 25\n",
            "total validation 13years_Female images: 25\n",
            "total validation 14years _Female images: 25\n",
            "total validation 15years_Female images: 25\n",
            "total validation 16years_Female images: 25\n",
            "total validation 17years_Female images: 25\n",
            "total validation 18years_Female images: 25\n",
            "total validation 19years_Female images: 25\n",
            "total validation 20years_Female images: 25\n",
            "total validation 21years_Female images: 25\n",
            "total validation 22years_Female images: 25\n",
            "total validation 23years_Female images: 25\n",
            "total validation 24years_Female images: 25\n",
            "total validation 25years_Female images: 25 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Total Test"
      ],
      "metadata": {
        "id": "y76dMTeNFBee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('total test 7years_Female images:', len(os.listdir(test_Y7F_dir))) \n",
        "print('total test 8years_Female images:', len(os.listdir(test_Y8F_dir)))\n",
        "print('total test 9years_Female images:', len(os.listdir(test_Y9F_dir)))\n",
        "print('total test 10years_Female images:', len(os.listdir(test_Y10F_dir))) \n",
        "print('total test 11years_Female images:', len(os.listdir(test_Y11F_dir)))\n",
        "print('total test 12years_Female images:', len(os.listdir(test_Y12F_dir)))\n",
        "print('total test 13years_Female images:', len(os.listdir(test_Y13F_dir))) \n",
        "print('total test 14years _Female images:', len(os.listdir(test_Y14F_dir))) \n",
        "print('total test 15years_Female images:', len(os.listdir(test_Y15F_dir))) \n",
        "print('total test 16years_Female images:', len(os.listdir(test_Y16F_dir)))\n",
        "print('total test 17years_Female images:', len(os.listdir(test_Y17F_dir)))\n",
        "print('total test 18years_Female images:', len(os.listdir(test_Y18F_dir))) \n",
        "print('total test 19years_Female images:', len(os.listdir(test_Y19F_dir))) \n",
        "print('total test 20years_Female images:', len(os.listdir(test_Y20F_dir))) \n",
        "print('total test 21years_Female images:', len(os.listdir(test_Y21F_dir))) \n",
        "print('total test 22years_Female images:', len(os.listdir(test_Y22F_dir))) \n",
        "print('total test 23years_Female images:', len(os.listdir(test_Y23F_dir))) \n",
        "print('total test 24years_Female images:', len(os.listdir(test_Y24F_dir))) \n",
        "print('total test 25years_Female images:', len(os.listdir(test_Y25F_dir)),'\\n')"
      ],
      "metadata": {
        "id": "AqeXPDqFFG11",
        "outputId": "643a06a4-c421-43cb-ae97-b38c3b73460e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total test 7years_Female images: 25\n",
            "total test 8years_Female images: 25\n",
            "total test 9years_Female images: 25\n",
            "total test 10years_Female images: 25\n",
            "total test 11years_Female images: 25\n",
            "total test 12years_Female images: 25\n",
            "total test 13years_Female images: 25\n",
            "total test 14years _Female images: 25\n",
            "total test 15years_Female images: 25\n",
            "total test 16years_Female images: 25\n",
            "total test 17years_Female images: 25\n",
            "total test 18years_Female images: 25\n",
            "total test 19years_Female images: 25\n",
            "total test 20years_Female images: 25\n",
            "total test 21years_Female images: 25\n",
            "total test 22years_Female images: 25\n",
            "total test 23years_Female images: 25\n",
            "total test 24years_Female images: 25\n",
            "total test 25years_Female images: 25 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef23061-1eb0-4d10-ed57-62c413ab48c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadBB12251jh",
        "outputId": "f4214228-c2c6-4ab1-c56e-c98e2688c376"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GepWq3yy53t5",
        "outputId": "38e01ac2-09c0-413e-f1d8-eb12b12a8e01"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6qUmmF856ZE",
        "outputId": "041ce2c5-50a8-4fee-be4f-dcb52be70c2b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-29-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "89/89 [==============================] - 82s 813ms/step - loss: 4.9056 - acc: 0.0483 - val_loss: 4.2584 - val_acc: 0.0496\n",
            "Epoch 2/300\n",
            "89/89 [==============================] - 76s 812ms/step - loss: 4.5064 - acc: 0.0440 - val_loss: 3.9521 - val_acc: 0.0733\n",
            "Epoch 3/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 4.2841 - acc: 0.0476 - val_loss: 3.8157 - val_acc: 0.0733\n",
            "Epoch 4/300\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 4.2408 - acc: 0.0582 - val_loss: 3.6929 - val_acc: 0.0647\n",
            "Epoch 5/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 4.0557 - acc: 0.0518 - val_loss: 3.6757 - val_acc: 0.0603\n",
            "Epoch 6/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 4.0195 - acc: 0.0625 - val_loss: 3.7062 - val_acc: 0.0582\n",
            "Epoch 7/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 4.0159 - acc: 0.0582 - val_loss: 3.6910 - val_acc: 0.0603\n",
            "Epoch 8/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.9828 - acc: 0.0646 - val_loss: 3.6478 - val_acc: 0.0603\n",
            "Epoch 9/300\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 3.9417 - acc: 0.0639 - val_loss: 3.6640 - val_acc: 0.0625\n",
            "Epoch 10/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 3.9564 - acc: 0.0632 - val_loss: 3.6105 - val_acc: 0.0603\n",
            "Epoch 11/300\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 3.8551 - acc: 0.0632 - val_loss: 3.5363 - val_acc: 0.0582\n",
            "Epoch 12/300\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 3.8594 - acc: 0.0632 - val_loss: 3.5280 - val_acc: 0.0647\n",
            "Epoch 13/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.8168 - acc: 0.0660 - val_loss: 3.5088 - val_acc: 0.0582\n",
            "Epoch 14/300\n",
            "89/89 [==============================] - 71s 780ms/step - loss: 3.7184 - acc: 0.0745 - val_loss: 3.4647 - val_acc: 0.0560\n",
            "Epoch 15/300\n",
            "89/89 [==============================] - 71s 779ms/step - loss: 3.7471 - acc: 0.0681 - val_loss: 3.4743 - val_acc: 0.0625\n",
            "Epoch 16/300\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 3.7178 - acc: 0.0873 - val_loss: 3.4469 - val_acc: 0.0625\n",
            "Epoch 17/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.7919 - acc: 0.0703 - val_loss: 3.4311 - val_acc: 0.0625\n",
            "Epoch 18/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.7541 - acc: 0.0582 - val_loss: 3.4189 - val_acc: 0.0647\n",
            "Epoch 19/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 3.6867 - acc: 0.0937 - val_loss: 3.4163 - val_acc: 0.0603\n",
            "Epoch 20/300\n",
            "89/89 [==============================] - 71s 781ms/step - loss: 3.6930 - acc: 0.0802 - val_loss: 3.3669 - val_acc: 0.0690\n",
            "Epoch 21/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 3.6612 - acc: 0.0816 - val_loss: 3.3215 - val_acc: 0.0776\n",
            "Epoch 22/300\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 3.7156 - acc: 0.0788 - val_loss: 3.3035 - val_acc: 0.0797\n",
            "Epoch 23/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.7012 - acc: 0.0816 - val_loss: 3.2646 - val_acc: 0.0819\n",
            "Epoch 24/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.5772 - acc: 0.0880 - val_loss: 3.2787 - val_acc: 0.0776\n",
            "Epoch 25/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 3.6164 - acc: 0.0951 - val_loss: 3.2405 - val_acc: 0.0905\n",
            "Epoch 26/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.5683 - acc: 0.0923 - val_loss: 3.2454 - val_acc: 0.0841\n",
            "Epoch 27/300\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 3.5343 - acc: 0.0923 - val_loss: 3.2153 - val_acc: 0.0819\n",
            "Epoch 28/300\n",
            "89/89 [==============================] - 71s 777ms/step - loss: 3.6028 - acc: 0.0937 - val_loss: 3.2058 - val_acc: 0.0819\n",
            "Epoch 29/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.5488 - acc: 0.0866 - val_loss: 3.2094 - val_acc: 0.0819\n",
            "Epoch 30/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.5328 - acc: 0.0866 - val_loss: 3.1770 - val_acc: 0.0905\n",
            "Epoch 31/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 3.4939 - acc: 0.0866 - val_loss: 3.1873 - val_acc: 0.0841\n",
            "Epoch 32/300\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 3.4939 - acc: 0.0987 - val_loss: 3.1753 - val_acc: 0.0905\n",
            "Epoch 33/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.4964 - acc: 0.0866 - val_loss: 3.1629 - val_acc: 0.0776\n",
            "Epoch 34/300\n",
            "89/89 [==============================] - 72s 784ms/step - loss: 3.4219 - acc: 0.1214 - val_loss: 3.1329 - val_acc: 0.0927\n",
            "Epoch 35/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 3.5188 - acc: 0.0852 - val_loss: 3.1103 - val_acc: 0.0905\n",
            "Epoch 36/300\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 3.4957 - acc: 0.1050 - val_loss: 3.0739 - val_acc: 0.0927\n",
            "Epoch 37/300\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 3.4229 - acc: 0.1072 - val_loss: 3.0836 - val_acc: 0.1013\n",
            "Epoch 38/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 3.4895 - acc: 0.0937 - val_loss: 3.0812 - val_acc: 0.0991\n",
            "Epoch 39/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 3.4218 - acc: 0.0994 - val_loss: 3.0723 - val_acc: 0.0948\n",
            "Epoch 40/300\n",
            "89/89 [==============================] - 71s 777ms/step - loss: 3.4120 - acc: 0.1043 - val_loss: 3.0540 - val_acc: 0.1034\n",
            "Epoch 41/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.3572 - acc: 0.1065 - val_loss: 3.0609 - val_acc: 0.1013\n",
            "Epoch 42/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 3.4364 - acc: 0.1015 - val_loss: 3.0420 - val_acc: 0.1164\n",
            "Epoch 43/300\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 3.4379 - acc: 0.1093 - val_loss: 3.0277 - val_acc: 0.1056\n",
            "Epoch 44/300\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 3.3221 - acc: 0.1221 - val_loss: 3.0178 - val_acc: 0.1013\n",
            "Epoch 45/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 3.3349 - acc: 0.1143 - val_loss: 3.0192 - val_acc: 0.1056\n",
            "Epoch 46/300\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.3863 - acc: 0.1043 - val_loss: 3.0115 - val_acc: 0.1099\n",
            "Epoch 47/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.3595 - acc: 0.1107 - val_loss: 3.0023 - val_acc: 0.1078\n",
            "Epoch 48/300\n",
            "89/89 [==============================] - 73s 790ms/step - loss: 3.2912 - acc: 0.1214 - val_loss: 2.9988 - val_acc: 0.1034\n",
            "Epoch 49/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 3.2977 - acc: 0.1079 - val_loss: 2.9994 - val_acc: 0.1099\n",
            "Epoch 50/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 3.3379 - acc: 0.1192 - val_loss: 2.9667 - val_acc: 0.1078\n",
            "Epoch 51/300\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 3.3922 - acc: 0.1100 - val_loss: 2.9740 - val_acc: 0.1099\n",
            "Epoch 52/300\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 3.2320 - acc: 0.1199 - val_loss: 2.9570 - val_acc: 0.1142\n",
            "Epoch 53/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.1742 - acc: 0.1384 - val_loss: 2.9625 - val_acc: 0.1142\n",
            "Epoch 54/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 3.2795 - acc: 0.1178 - val_loss: 2.9543 - val_acc: 0.1164\n",
            "Epoch 55/300\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.2726 - acc: 0.1278 - val_loss: 2.9287 - val_acc: 0.1121\n",
            "Epoch 56/300\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 3.2737 - acc: 0.1093 - val_loss: 2.9376 - val_acc: 0.1142\n",
            "Epoch 57/300\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.2738 - acc: 0.1114 - val_loss: 2.9413 - val_acc: 0.1142\n",
            "Epoch 58/300\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 3.2684 - acc: 0.1214 - val_loss: 2.9338 - val_acc: 0.1142\n",
            "Epoch 59/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 3.2389 - acc: 0.1107 - val_loss: 2.9249 - val_acc: 0.1207\n",
            "Epoch 60/300\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 3.3007 - acc: 0.0972 - val_loss: 2.9293 - val_acc: 0.1099\n",
            "Epoch 61/300\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 3.2593 - acc: 0.1242 - val_loss: 2.9227 - val_acc: 0.1078\n",
            "Epoch 62/300\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 3.2609 - acc: 0.1164 - val_loss: 2.9012 - val_acc: 0.1142\n",
            "Epoch 63/300\n",
            "89/89 [==============================] - 76s 858ms/step - loss: 3.1582 - acc: 0.1306 - val_loss: 2.9063 - val_acc: 0.1185\n",
            "Epoch 64/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 3.1706 - acc: 0.1377 - val_loss: 2.9047 - val_acc: 0.1185\n",
            "Epoch 65/300\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 3.1694 - acc: 0.1341 - val_loss: 2.8897 - val_acc: 0.1164\n",
            "Epoch 66/300\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 3.2144 - acc: 0.1207 - val_loss: 2.8926 - val_acc: 0.1250\n",
            "Epoch 67/300\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 3.2599 - acc: 0.1178 - val_loss: 2.8737 - val_acc: 0.1207\n",
            "Epoch 68/300\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 3.1102 - acc: 0.1334 - val_loss: 2.8974 - val_acc: 0.1164\n",
            "Epoch 69/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 3.1846 - acc: 0.1256 - val_loss: 2.8742 - val_acc: 0.1250\n",
            "Epoch 70/300\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 3.1008 - acc: 0.1320 - val_loss: 2.8770 - val_acc: 0.1228\n",
            "Epoch 71/300\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 3.1325 - acc: 0.1256 - val_loss: 2.8663 - val_acc: 0.1207\n",
            "Epoch 72/300\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 3.1259 - acc: 0.1363 - val_loss: 2.8531 - val_acc: 0.1272\n",
            "Epoch 73/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 3.2092 - acc: 0.1114 - val_loss: 2.8463 - val_acc: 0.1272\n",
            "Epoch 74/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.1580 - acc: 0.1278 - val_loss: 2.8505 - val_acc: 0.1379\n",
            "Epoch 75/300\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.1966 - acc: 0.1207 - val_loss: 2.8434 - val_acc: 0.1336\n",
            "Epoch 76/300\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.1884 - acc: 0.1270 - val_loss: 2.8589 - val_acc: 0.1272\n",
            "Epoch 77/300\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 3.1268 - acc: 0.1270 - val_loss: 2.8485 - val_acc: 0.1207\n",
            "Epoch 78/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.2002 - acc: 0.1256 - val_loss: 2.8309 - val_acc: 0.1250\n",
            "Epoch 79/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.1110 - acc: 0.1306 - val_loss: 2.8548 - val_acc: 0.1315\n",
            "Epoch 80/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.1780 - acc: 0.1313 - val_loss: 2.8485 - val_acc: 0.1315\n",
            "Epoch 81/300\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 3.1391 - acc: 0.1384 - val_loss: 2.8234 - val_acc: 0.1272\n",
            "Epoch 82/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.1140 - acc: 0.1228 - val_loss: 2.8330 - val_acc: 0.1336\n",
            "Epoch 83/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.0899 - acc: 0.1334 - val_loss: 2.8294 - val_acc: 0.1358\n",
            "Epoch 84/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 3.0870 - acc: 0.1235 - val_loss: 2.8173 - val_acc: 0.1293\n",
            "Epoch 85/300\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 3.1367 - acc: 0.1334 - val_loss: 2.8263 - val_acc: 0.1315\n",
            "Epoch 86/300\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 3.1182 - acc: 0.1356 - val_loss: 2.8137 - val_acc: 0.1185\n",
            "Epoch 87/300\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 3.0836 - acc: 0.1270 - val_loss: 2.8091 - val_acc: 0.1228\n",
            "Epoch 88/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 3.0795 - acc: 0.1384 - val_loss: 2.8249 - val_acc: 0.1293\n",
            "Epoch 89/300\n",
            "89/89 [==============================] - 72s 784ms/step - loss: 3.0761 - acc: 0.1214 - val_loss: 2.8187 - val_acc: 0.1228\n",
            "Epoch 90/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 3.1247 - acc: 0.1398 - val_loss: 2.8009 - val_acc: 0.1272\n",
            "Epoch 91/300\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 3.1011 - acc: 0.1299 - val_loss: 2.7930 - val_acc: 0.1293\n",
            "Epoch 92/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.1331 - acc: 0.1292 - val_loss: 2.8193 - val_acc: 0.1293\n",
            "Epoch 93/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0722 - acc: 0.1391 - val_loss: 2.8106 - val_acc: 0.1293\n",
            "Epoch 94/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 3.1085 - acc: 0.1299 - val_loss: 2.8033 - val_acc: 0.1272\n",
            "Epoch 95/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 3.0740 - acc: 0.1363 - val_loss: 2.8185 - val_acc: 0.1272\n",
            "Epoch 96/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.0470 - acc: 0.1341 - val_loss: 2.7821 - val_acc: 0.1293\n",
            "Epoch 97/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 3.0767 - acc: 0.1370 - val_loss: 2.8104 - val_acc: 0.1315\n",
            "Epoch 98/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 3.0069 - acc: 0.1377 - val_loss: 2.7976 - val_acc: 0.1293\n",
            "Epoch 99/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 3.0339 - acc: 0.1533 - val_loss: 2.7891 - val_acc: 0.1315\n",
            "Epoch 100/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.0643 - acc: 0.1505 - val_loss: 2.7779 - val_acc: 0.1315\n",
            "Epoch 101/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.9959 - acc: 0.1554 - val_loss: 2.7820 - val_acc: 0.1315\n",
            "Epoch 102/300\n",
            "89/89 [==============================] - 71s 784ms/step - loss: 3.0255 - acc: 0.1419 - val_loss: 2.7950 - val_acc: 0.1185\n",
            "Epoch 103/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 3.0083 - acc: 0.1462 - val_loss: 2.7914 - val_acc: 0.1358\n",
            "Epoch 104/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 3.0182 - acc: 0.1370 - val_loss: 2.7919 - val_acc: 0.1228\n",
            "Epoch 105/300\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 3.0411 - acc: 0.1469 - val_loss: 2.7858 - val_acc: 0.1358\n",
            "Epoch 106/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.9930 - acc: 0.1398 - val_loss: 2.7776 - val_acc: 0.1293\n",
            "Epoch 107/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.0290 - acc: 0.1391 - val_loss: 2.7785 - val_acc: 0.1272\n",
            "Epoch 108/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 3.0046 - acc: 0.1547 - val_loss: 2.7686 - val_acc: 0.1293\n",
            "Epoch 109/300\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.9528 - acc: 0.1412 - val_loss: 2.7942 - val_acc: 0.1250\n",
            "Epoch 110/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 3.0102 - acc: 0.1434 - val_loss: 2.7753 - val_acc: 0.1272\n",
            "Epoch 111/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0506 - acc: 0.1320 - val_loss: 2.7700 - val_acc: 0.1336\n",
            "Epoch 112/300\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.9902 - acc: 0.1533 - val_loss: 2.7776 - val_acc: 0.1293\n",
            "Epoch 113/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.9872 - acc: 0.1320 - val_loss: 2.7640 - val_acc: 0.1379\n",
            "Epoch 114/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 3.0037 - acc: 0.1441 - val_loss: 2.7771 - val_acc: 0.1379\n",
            "Epoch 115/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.9689 - acc: 0.1434 - val_loss: 2.7648 - val_acc: 0.1422\n",
            "Epoch 116/300\n",
            "89/89 [==============================] - 73s 785ms/step - loss: 2.9928 - acc: 0.1604 - val_loss: 2.7591 - val_acc: 0.1379\n",
            "Epoch 117/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.9664 - acc: 0.1547 - val_loss: 2.7579 - val_acc: 0.1379\n",
            "Epoch 118/300\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 3.0226 - acc: 0.1306 - val_loss: 2.7423 - val_acc: 0.1401\n",
            "Epoch 119/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.0100 - acc: 0.1348 - val_loss: 2.7633 - val_acc: 0.1401\n",
            "Epoch 120/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.9174 - acc: 0.1611 - val_loss: 2.7562 - val_acc: 0.1444\n",
            "Epoch 121/300\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.9657 - acc: 0.1427 - val_loss: 2.7542 - val_acc: 0.1444\n",
            "Epoch 122/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.9632 - acc: 0.1576 - val_loss: 2.7665 - val_acc: 0.1379\n",
            "Epoch 123/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.9950 - acc: 0.1476 - val_loss: 2.7580 - val_acc: 0.1422\n",
            "Epoch 124/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.9946 - acc: 0.1490 - val_loss: 2.7702 - val_acc: 0.1336\n",
            "Epoch 125/300\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.9431 - acc: 0.1561 - val_loss: 2.7528 - val_acc: 0.1379\n",
            "Epoch 126/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 3.0031 - acc: 0.1455 - val_loss: 2.7672 - val_acc: 0.1358\n",
            "Epoch 127/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 3.0027 - acc: 0.1370 - val_loss: 2.7541 - val_acc: 0.1336\n",
            "Epoch 128/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.9340 - acc: 0.1647 - val_loss: 2.7362 - val_acc: 0.1401\n",
            "Epoch 129/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.9453 - acc: 0.1512 - val_loss: 2.7456 - val_acc: 0.1466\n",
            "Epoch 130/300\n",
            "89/89 [==============================] - 71s 784ms/step - loss: 2.9615 - acc: 0.1483 - val_loss: 2.7635 - val_acc: 0.1422\n",
            "Epoch 131/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.9124 - acc: 0.1639 - val_loss: 2.7439 - val_acc: 0.1444\n",
            "Epoch 132/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.9482 - acc: 0.1441 - val_loss: 2.7550 - val_acc: 0.1422\n",
            "Epoch 133/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.8924 - acc: 0.1519 - val_loss: 2.7386 - val_acc: 0.1444\n",
            "Epoch 134/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.9559 - acc: 0.1540 - val_loss: 2.7536 - val_acc: 0.1422\n",
            "Epoch 135/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.8648 - acc: 0.1547 - val_loss: 2.7476 - val_acc: 0.1379\n",
            "Epoch 136/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.9217 - acc: 0.1632 - val_loss: 2.7580 - val_acc: 0.1422\n",
            "Epoch 137/300\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 2.9091 - acc: 0.1576 - val_loss: 2.7549 - val_acc: 0.1379\n",
            "Epoch 138/300\n",
            "89/89 [==============================] - 72s 797ms/step - loss: 2.9073 - acc: 0.1675 - val_loss: 2.7446 - val_acc: 0.1401\n",
            "Epoch 139/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.9861 - acc: 0.1462 - val_loss: 2.7619 - val_acc: 0.1401\n",
            "Epoch 140/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.9318 - acc: 0.1576 - val_loss: 2.7655 - val_acc: 0.1379\n",
            "Epoch 141/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.9009 - acc: 0.1483 - val_loss: 2.7353 - val_acc: 0.1401\n",
            "Epoch 142/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.8814 - acc: 0.1590 - val_loss: 2.7359 - val_acc: 0.1444\n",
            "Epoch 143/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.9281 - acc: 0.1632 - val_loss: 2.7170 - val_acc: 0.1422\n",
            "Epoch 144/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.8639 - acc: 0.1632 - val_loss: 2.7321 - val_acc: 0.1336\n",
            "Epoch 145/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.8847 - acc: 0.1696 - val_loss: 2.7359 - val_acc: 0.1422\n",
            "Epoch 146/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.8952 - acc: 0.1675 - val_loss: 2.7440 - val_acc: 0.1487\n",
            "Epoch 147/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.8372 - acc: 0.1554 - val_loss: 2.7329 - val_acc: 0.1487\n",
            "Epoch 148/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.8518 - acc: 0.1540 - val_loss: 2.7343 - val_acc: 0.1358\n",
            "Epoch 149/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.8711 - acc: 0.1618 - val_loss: 2.7557 - val_acc: 0.1444\n",
            "Epoch 150/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.9336 - acc: 0.1583 - val_loss: 2.7503 - val_acc: 0.1379\n",
            "Epoch 151/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.8914 - acc: 0.1568 - val_loss: 2.7409 - val_acc: 0.1444\n",
            "Epoch 152/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.8500 - acc: 0.1753 - val_loss: 2.7525 - val_acc: 0.1315\n",
            "Epoch 153/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.8695 - acc: 0.1654 - val_loss: 2.7148 - val_acc: 0.1509\n",
            "Epoch 154/300\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 2.7954 - acc: 0.1590 - val_loss: 2.7332 - val_acc: 0.1444\n",
            "Epoch 155/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.8494 - acc: 0.1696 - val_loss: 2.7247 - val_acc: 0.1466\n",
            "Epoch 156/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.8796 - acc: 0.1533 - val_loss: 2.7481 - val_acc: 0.1466\n",
            "Epoch 157/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.8537 - acc: 0.1604 - val_loss: 2.7463 - val_acc: 0.1444\n",
            "Epoch 158/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.8744 - acc: 0.1611 - val_loss: 2.7535 - val_acc: 0.1379\n",
            "Epoch 159/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.8306 - acc: 0.1668 - val_loss: 2.7370 - val_acc: 0.1444\n",
            "Epoch 160/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.8816 - acc: 0.1611 - val_loss: 2.7422 - val_acc: 0.1444\n",
            "Epoch 161/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.8110 - acc: 0.1611 - val_loss: 2.7317 - val_acc: 0.1466\n",
            "Epoch 162/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.8382 - acc: 0.1533 - val_loss: 2.7424 - val_acc: 0.1379\n",
            "Epoch 163/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.8483 - acc: 0.1547 - val_loss: 2.6963 - val_acc: 0.1422\n",
            "Epoch 164/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.9370 - acc: 0.1547 - val_loss: 2.7204 - val_acc: 0.1487\n",
            "Epoch 165/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.8051 - acc: 0.1654 - val_loss: 2.7262 - val_acc: 0.1466\n",
            "Epoch 166/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.8057 - acc: 0.1611 - val_loss: 2.7342 - val_acc: 0.1487\n",
            "Epoch 167/300\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 2.8986 - acc: 0.1505 - val_loss: 2.7361 - val_acc: 0.1401\n",
            "Epoch 168/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.8562 - acc: 0.1718 - val_loss: 2.7211 - val_acc: 0.1466\n",
            "Epoch 169/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.8311 - acc: 0.1639 - val_loss: 2.6980 - val_acc: 0.1466\n",
            "Epoch 170/300\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.8542 - acc: 0.1611 - val_loss: 2.7156 - val_acc: 0.1444\n",
            "Epoch 171/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.8536 - acc: 0.1483 - val_loss: 2.7043 - val_acc: 0.1530\n",
            "Epoch 172/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.8543 - acc: 0.1597 - val_loss: 2.7077 - val_acc: 0.1509\n",
            "Epoch 173/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.8001 - acc: 0.1725 - val_loss: 2.7106 - val_acc: 0.1530\n",
            "Epoch 174/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.8535 - acc: 0.1732 - val_loss: 2.7129 - val_acc: 0.1487\n",
            "Epoch 175/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.8685 - acc: 0.1647 - val_loss: 2.7240 - val_acc: 0.1509\n",
            "Epoch 176/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.8352 - acc: 0.1668 - val_loss: 2.7133 - val_acc: 0.1616\n",
            "Epoch 177/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7847 - acc: 0.1838 - val_loss: 2.7145 - val_acc: 0.1552\n",
            "Epoch 178/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.7986 - acc: 0.1682 - val_loss: 2.7005 - val_acc: 0.1573\n",
            "Epoch 179/300\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.8376 - acc: 0.1668 - val_loss: 2.6983 - val_acc: 0.1552\n",
            "Epoch 180/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.7859 - acc: 0.1611 - val_loss: 2.7134 - val_acc: 0.1530\n",
            "Epoch 181/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.8356 - acc: 0.1568 - val_loss: 2.7092 - val_acc: 0.1530\n",
            "Epoch 182/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.8173 - acc: 0.1639 - val_loss: 2.7116 - val_acc: 0.1573\n",
            "Epoch 183/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.8148 - acc: 0.1597 - val_loss: 2.7105 - val_acc: 0.1616\n",
            "Epoch 184/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.7522 - acc: 0.1675 - val_loss: 2.7090 - val_acc: 0.1595\n",
            "Epoch 185/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.8281 - acc: 0.1725 - val_loss: 2.6996 - val_acc: 0.1509\n",
            "Epoch 186/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.7526 - acc: 0.1781 - val_loss: 2.6969 - val_acc: 0.1573\n",
            "Epoch 187/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.8233 - acc: 0.1611 - val_loss: 2.7205 - val_acc: 0.1466\n",
            "Epoch 188/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.8558 - acc: 0.1583 - val_loss: 2.7059 - val_acc: 0.1552\n",
            "Epoch 189/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.8110 - acc: 0.1753 - val_loss: 2.7033 - val_acc: 0.1422\n",
            "Epoch 190/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.8492 - acc: 0.1753 - val_loss: 2.6981 - val_acc: 0.1444\n",
            "Epoch 191/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.8074 - acc: 0.1718 - val_loss: 2.7066 - val_acc: 0.1444\n",
            "Epoch 192/300\n",
            "89/89 [==============================] - 72s 797ms/step - loss: 2.7817 - acc: 0.1625 - val_loss: 2.6960 - val_acc: 0.1444\n",
            "Epoch 193/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.7729 - acc: 0.1512 - val_loss: 2.6861 - val_acc: 0.1401\n",
            "Epoch 194/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7795 - acc: 0.1682 - val_loss: 2.7010 - val_acc: 0.1444\n",
            "Epoch 195/300\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 2.7922 - acc: 0.1739 - val_loss: 2.6938 - val_acc: 0.1638\n",
            "Epoch 196/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.7157 - acc: 0.1833 - val_loss: 2.7102 - val_acc: 0.1444\n",
            "Epoch 197/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.7663 - acc: 0.1668 - val_loss: 2.7207 - val_acc: 0.1401\n",
            "Epoch 198/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.7407 - acc: 0.1739 - val_loss: 2.7090 - val_acc: 0.1530\n",
            "Epoch 199/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.7291 - acc: 0.1760 - val_loss: 2.7395 - val_acc: 0.1509\n",
            "Epoch 200/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7125 - acc: 0.1796 - val_loss: 2.7379 - val_acc: 0.1336\n",
            "Epoch 201/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.7718 - acc: 0.1639 - val_loss: 2.7322 - val_acc: 0.1358\n",
            "Epoch 202/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7313 - acc: 0.1625 - val_loss: 2.6991 - val_acc: 0.1466\n",
            "Epoch 203/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.7843 - acc: 0.1739 - val_loss: 2.6914 - val_acc: 0.1509\n",
            "Epoch 204/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7733 - acc: 0.1668 - val_loss: 2.6965 - val_acc: 0.1466\n",
            "Epoch 205/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.7218 - acc: 0.1909 - val_loss: 2.6844 - val_acc: 0.1530\n",
            "Epoch 206/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.7117 - acc: 0.1774 - val_loss: 2.6944 - val_acc: 0.1509\n",
            "Epoch 207/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.7631 - acc: 0.1760 - val_loss: 2.7088 - val_acc: 0.1509\n",
            "Epoch 208/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.7473 - acc: 0.1710 - val_loss: 2.6765 - val_acc: 0.1466\n",
            "Epoch 209/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.7235 - acc: 0.1753 - val_loss: 2.6818 - val_acc: 0.1466\n",
            "Epoch 210/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.7776 - acc: 0.1732 - val_loss: 2.6979 - val_acc: 0.1444\n",
            "Epoch 211/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.7572 - acc: 0.1654 - val_loss: 2.6897 - val_acc: 0.1466\n",
            "Epoch 212/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.7208 - acc: 0.1796 - val_loss: 2.6837 - val_acc: 0.1444\n",
            "Epoch 213/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.7291 - acc: 0.1689 - val_loss: 2.6754 - val_acc: 0.1552\n",
            "Epoch 214/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.7516 - acc: 0.1796 - val_loss: 2.6887 - val_acc: 0.1509\n",
            "Epoch 215/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.7679 - acc: 0.1696 - val_loss: 2.6895 - val_acc: 0.1552\n",
            "Epoch 216/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7600 - acc: 0.1767 - val_loss: 2.6801 - val_acc: 0.1487\n",
            "Epoch 217/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.7103 - acc: 0.1803 - val_loss: 2.6859 - val_acc: 0.1573\n",
            "Epoch 218/300\n",
            "89/89 [==============================] - 71s 781ms/step - loss: 2.6731 - acc: 0.1909 - val_loss: 2.6798 - val_acc: 0.1444\n",
            "Epoch 219/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7174 - acc: 0.1746 - val_loss: 2.6759 - val_acc: 0.1552\n",
            "Epoch 220/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.7261 - acc: 0.1803 - val_loss: 2.7010 - val_acc: 0.1444\n",
            "Epoch 221/300\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.8052 - acc: 0.1561 - val_loss: 2.6728 - val_acc: 0.1509\n",
            "Epoch 222/300\n",
            "89/89 [==============================] - 76s 813ms/step - loss: 2.6971 - acc: 0.2016 - val_loss: 2.6639 - val_acc: 0.1530\n",
            "Epoch 223/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.7031 - acc: 0.1796 - val_loss: 2.6588 - val_acc: 0.1530\n",
            "Epoch 224/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.6883 - acc: 0.1824 - val_loss: 2.6629 - val_acc: 0.1487\n",
            "Epoch 225/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.6758 - acc: 0.1703 - val_loss: 2.6725 - val_acc: 0.1552\n",
            "Epoch 226/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.7076 - acc: 0.1696 - val_loss: 2.6788 - val_acc: 0.1466\n",
            "Epoch 227/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.6756 - acc: 0.1739 - val_loss: 2.6695 - val_acc: 0.1509\n",
            "Epoch 228/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7658 - acc: 0.1703 - val_loss: 2.6986 - val_acc: 0.1444\n",
            "Epoch 229/300\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.6697 - acc: 0.1973 - val_loss: 2.6730 - val_acc: 0.1595\n",
            "Epoch 230/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.6665 - acc: 0.1774 - val_loss: 2.6767 - val_acc: 0.1509\n",
            "Epoch 231/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.6810 - acc: 0.1675 - val_loss: 2.6764 - val_acc: 0.1573\n",
            "Epoch 232/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.7274 - acc: 0.1763 - val_loss: 2.6779 - val_acc: 0.1552\n",
            "Epoch 233/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.7147 - acc: 0.1746 - val_loss: 2.6664 - val_acc: 0.1444\n",
            "Epoch 234/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7238 - acc: 0.1760 - val_loss: 2.6558 - val_acc: 0.1487\n",
            "Epoch 235/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.7097 - acc: 0.1675 - val_loss: 2.6690 - val_acc: 0.1509\n",
            "Epoch 236/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.6530 - acc: 0.1881 - val_loss: 2.6686 - val_acc: 0.1552\n",
            "Epoch 237/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6943 - acc: 0.1760 - val_loss: 2.6476 - val_acc: 0.1573\n",
            "Epoch 238/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.7016 - acc: 0.1774 - val_loss: 2.6581 - val_acc: 0.1638\n",
            "Epoch 239/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.6758 - acc: 0.1718 - val_loss: 2.6766 - val_acc: 0.1595\n",
            "Epoch 240/300\n",
            "89/89 [==============================] - 71s 785ms/step - loss: 2.6724 - acc: 0.1888 - val_loss: 2.6475 - val_acc: 0.1595\n",
            "Epoch 241/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.6625 - acc: 0.1810 - val_loss: 2.6693 - val_acc: 0.1552\n",
            "Epoch 242/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.6456 - acc: 0.1789 - val_loss: 2.6634 - val_acc: 0.1466\n",
            "Epoch 243/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.6566 - acc: 0.1980 - val_loss: 2.6532 - val_acc: 0.1530\n",
            "Epoch 244/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.7056 - acc: 0.1710 - val_loss: 2.6629 - val_acc: 0.1509\n",
            "Epoch 245/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.6676 - acc: 0.1945 - val_loss: 2.6624 - val_acc: 0.1466\n",
            "Epoch 246/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.6520 - acc: 0.1859 - val_loss: 2.6562 - val_acc: 0.1595\n",
            "Epoch 247/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.7097 - acc: 0.1739 - val_loss: 2.6607 - val_acc: 0.1552\n",
            "Epoch 248/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.6717 - acc: 0.1760 - val_loss: 2.6553 - val_acc: 0.1530\n",
            "Epoch 249/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.6895 - acc: 0.1760 - val_loss: 2.6661 - val_acc: 0.1681\n",
            "Epoch 250/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.6771 - acc: 0.1703 - val_loss: 2.6688 - val_acc: 0.1638\n",
            "Epoch 251/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.6704 - acc: 0.1845 - val_loss: 2.6706 - val_acc: 0.1509\n",
            "Epoch 252/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.6483 - acc: 0.1881 - val_loss: 2.6627 - val_acc: 0.1595\n",
            "Epoch 253/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.6713 - acc: 0.1916 - val_loss: 2.6908 - val_acc: 0.1444\n",
            "Epoch 254/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6855 - acc: 0.1810 - val_loss: 2.6525 - val_acc: 0.1530\n",
            "Epoch 255/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.6186 - acc: 0.1881 - val_loss: 2.6656 - val_acc: 0.1509\n",
            "Epoch 256/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.6058 - acc: 0.1817 - val_loss: 2.6618 - val_acc: 0.1595\n",
            "Epoch 257/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.6745 - acc: 0.1789 - val_loss: 2.6505 - val_acc: 0.1595\n",
            "Epoch 258/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.6175 - acc: 0.1952 - val_loss: 2.6605 - val_acc: 0.1530\n",
            "Epoch 259/300\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.6495 - acc: 0.1781 - val_loss: 2.6592 - val_acc: 0.1552\n",
            "Epoch 260/300\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.6278 - acc: 0.1980 - val_loss: 2.6529 - val_acc: 0.1659\n",
            "Epoch 261/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.6161 - acc: 0.2087 - val_loss: 2.6618 - val_acc: 0.1638\n",
            "Epoch 262/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7025 - acc: 0.1675 - val_loss: 2.6683 - val_acc: 0.1530\n",
            "Epoch 263/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.6455 - acc: 0.1767 - val_loss: 2.6536 - val_acc: 0.1573\n",
            "Epoch 264/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.5835 - acc: 0.1888 - val_loss: 2.6754 - val_acc: 0.1638\n",
            "Epoch 265/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6520 - acc: 0.2030 - val_loss: 2.6670 - val_acc: 0.1552\n",
            "Epoch 266/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.6278 - acc: 0.1831 - val_loss: 2.6793 - val_acc: 0.1530\n",
            "Epoch 267/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.5717 - acc: 0.1945 - val_loss: 2.6682 - val_acc: 0.1573\n",
            "Epoch 268/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7051 - acc: 0.1881 - val_loss: 2.6604 - val_acc: 0.1573\n",
            "Epoch 269/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.6411 - acc: 0.1902 - val_loss: 2.6627 - val_acc: 0.1616\n",
            "Epoch 270/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.6016 - acc: 0.1980 - val_loss: 2.6741 - val_acc: 0.1509\n",
            "Epoch 271/300\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.5906 - acc: 0.2001 - val_loss: 2.6852 - val_acc: 0.1573\n",
            "Epoch 272/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.5923 - acc: 0.1895 - val_loss: 2.6798 - val_acc: 0.1681\n",
            "Epoch 273/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.6731 - acc: 0.1668 - val_loss: 2.6861 - val_acc: 0.1616\n",
            "Epoch 274/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.6618 - acc: 0.2023 - val_loss: 2.6680 - val_acc: 0.1530\n",
            "Epoch 275/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.6075 - acc: 0.2037 - val_loss: 2.6751 - val_acc: 0.1616\n",
            "Epoch 276/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.5948 - acc: 0.2044 - val_loss: 2.6710 - val_acc: 0.1595\n",
            "Epoch 277/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.6377 - acc: 0.1859 - val_loss: 2.6613 - val_acc: 0.1616\n",
            "Epoch 278/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.6419 - acc: 0.1881 - val_loss: 2.6742 - val_acc: 0.1703\n",
            "Epoch 279/300\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.6078 - acc: 0.1938 - val_loss: 2.6774 - val_acc: 0.1638\n",
            "Epoch 280/300\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 2.5902 - acc: 0.2037 - val_loss: 2.6592 - val_acc: 0.1659\n",
            "Epoch 281/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.6091 - acc: 0.1881 - val_loss: 2.6618 - val_acc: 0.1638\n",
            "Epoch 282/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.6096 - acc: 0.1973 - val_loss: 2.6730 - val_acc: 0.1616\n",
            "Epoch 283/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.6103 - acc: 0.2023 - val_loss: 2.6646 - val_acc: 0.1616\n",
            "Epoch 284/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.6314 - acc: 0.1824 - val_loss: 2.6809 - val_acc: 0.1530\n",
            "Epoch 285/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.6162 - acc: 0.1888 - val_loss: 2.6713 - val_acc: 0.1616\n",
            "Epoch 286/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.6338 - acc: 0.2108 - val_loss: 2.6931 - val_acc: 0.1638\n",
            "Epoch 287/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6560 - acc: 0.1803 - val_loss: 2.6641 - val_acc: 0.1638\n",
            "Epoch 288/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.5944 - acc: 0.2087 - val_loss: 2.6710 - val_acc: 0.1595\n",
            "Epoch 289/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.6560 - acc: 0.1824 - val_loss: 2.6428 - val_acc: 0.1659\n",
            "Epoch 290/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.5933 - acc: 0.1930 - val_loss: 2.6487 - val_acc: 0.1659\n",
            "Epoch 291/300\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 2.6308 - acc: 0.1952 - val_loss: 2.6542 - val_acc: 0.1703\n",
            "Epoch 292/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.6179 - acc: 0.1718 - val_loss: 2.6433 - val_acc: 0.1681\n",
            "Epoch 293/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.6333 - acc: 0.2044 - val_loss: 2.6460 - val_acc: 0.1659\n",
            "Epoch 294/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.5802 - acc: 0.1867 - val_loss: 2.6568 - val_acc: 0.1595\n",
            "Epoch 295/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.6378 - acc: 0.1973 - val_loss: 2.6574 - val_acc: 0.1681\n",
            "Epoch 296/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6099 - acc: 0.1831 - val_loss: 2.6563 - val_acc: 0.1638\n",
            "Epoch 297/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.6252 - acc: 0.1852 - val_loss: 2.6481 - val_acc: 0.1638\n",
            "Epoch 298/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.6422 - acc: 0.1916 - val_loss: 2.6588 - val_acc: 0.1573\n",
            "Epoch 299/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.6823 - acc: 0.1966 - val_loss: 2.6561 - val_acc: 0.1573\n",
            "Epoch 300/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.5872 - acc: 0.1867 - val_loss: 2.6662 - val_acc: 0.1616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "outputId": "9f21737b-1d27-43c4-a6e5-ab22d0ff5270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine tuning last several layers."
      ],
      "metadata": {
        "id": "VeqQzlVtGxJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "metadata": {
        "id": "d8KiN4WQGpvn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "fhiWBST6G0qp",
        "outputId": "d8cfa789-13f8-4ef4-f0d9-fceb083e5552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-4287107a2cee>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "89/89 [==============================] - 80s 807ms/step - loss: 2.5743 - acc: 0.2044 - val_loss: 2.6911 - val_acc: 0.1659\n",
            "Epoch 2/300\n",
            "89/89 [==============================] - 71s 776ms/step - loss: 2.6123 - acc: 0.2030 - val_loss: 2.6513 - val_acc: 0.1746\n",
            "Epoch 3/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.5962 - acc: 0.1966 - val_loss: 2.6634 - val_acc: 0.1659\n",
            "Epoch 4/300\n",
            "89/89 [==============================] - 71s 784ms/step - loss: 2.6063 - acc: 0.1895 - val_loss: 2.6666 - val_acc: 0.1681\n",
            "Epoch 5/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.6404 - acc: 0.1774 - val_loss: 2.6737 - val_acc: 0.1659\n",
            "Epoch 6/300\n",
            "89/89 [==============================] - 71s 784ms/step - loss: 2.6104 - acc: 0.1774 - val_loss: 2.6678 - val_acc: 0.1681\n",
            "Epoch 7/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.6057 - acc: 0.1909 - val_loss: 2.6755 - val_acc: 0.1703\n",
            "Epoch 8/300\n",
            "89/89 [==============================] - 71s 778ms/step - loss: 2.5090 - acc: 0.2150 - val_loss: 2.6606 - val_acc: 0.1659\n",
            "Epoch 9/300\n",
            "89/89 [==============================] - 72s 784ms/step - loss: 2.5883 - acc: 0.1987 - val_loss: 2.6948 - val_acc: 0.1767\n",
            "Epoch 10/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.5568 - acc: 0.2044 - val_loss: 2.6664 - val_acc: 0.1767\n",
            "Epoch 11/300\n",
            "89/89 [==============================] - 71s 780ms/step - loss: 2.5839 - acc: 0.2108 - val_loss: 2.6707 - val_acc: 0.1724\n",
            "Epoch 12/300\n",
            "89/89 [==============================] - 71s 774ms/step - loss: 2.5877 - acc: 0.1902 - val_loss: 2.6725 - val_acc: 0.1703\n",
            "Epoch 13/300\n",
            "89/89 [==============================] - 71s 780ms/step - loss: 2.5941 - acc: 0.1923 - val_loss: 2.6612 - val_acc: 0.1681\n",
            "Epoch 14/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.5442 - acc: 0.2023 - val_loss: 2.6644 - val_acc: 0.1746\n",
            "Epoch 15/300\n",
            "89/89 [==============================] - 72s 783ms/step - loss: 2.5689 - acc: 0.1881 - val_loss: 2.6731 - val_acc: 0.1767\n",
            "Epoch 16/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.6046 - acc: 0.1959 - val_loss: 2.6728 - val_acc: 0.1638\n",
            "Epoch 17/300\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 2.5303 - acc: 0.2129 - val_loss: 2.6615 - val_acc: 0.1681\n",
            "Epoch 18/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.6052 - acc: 0.1881 - val_loss: 2.6698 - val_acc: 0.1595\n",
            "Epoch 19/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.5535 - acc: 0.1902 - val_loss: 2.6641 - val_acc: 0.1681\n",
            "Epoch 20/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.6119 - acc: 0.1867 - val_loss: 2.6566 - val_acc: 0.1724\n",
            "Epoch 21/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.5455 - acc: 0.1973 - val_loss: 2.6527 - val_acc: 0.1616\n",
            "Epoch 22/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.5876 - acc: 0.2009 - val_loss: 2.6410 - val_acc: 0.1659\n",
            "Epoch 23/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.5774 - acc: 0.1923 - val_loss: 2.6664 - val_acc: 0.1638\n",
            "Epoch 24/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.6279 - acc: 0.1774 - val_loss: 2.6545 - val_acc: 0.1659\n",
            "Epoch 25/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.6195 - acc: 0.1909 - val_loss: 2.6622 - val_acc: 0.1724\n",
            "Epoch 26/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.5644 - acc: 0.2001 - val_loss: 2.6440 - val_acc: 0.1789\n",
            "Epoch 27/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.5297 - acc: 0.1980 - val_loss: 2.6589 - val_acc: 0.1681\n",
            "Epoch 28/300\n",
            "89/89 [==============================] - 71s 782ms/step - loss: 2.5640 - acc: 0.1973 - val_loss: 2.6774 - val_acc: 0.1595\n",
            "Epoch 29/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.5631 - acc: 0.2030 - val_loss: 2.6586 - val_acc: 0.1659\n",
            "Epoch 30/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.5205 - acc: 0.2044 - val_loss: 2.6499 - val_acc: 0.1746\n",
            "Epoch 31/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.5467 - acc: 0.2037 - val_loss: 2.6543 - val_acc: 0.1681\n",
            "Epoch 32/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.5483 - acc: 0.2058 - val_loss: 2.6569 - val_acc: 0.1659\n",
            "Epoch 33/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.5643 - acc: 0.1966 - val_loss: 2.6434 - val_acc: 0.1724\n",
            "Epoch 34/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.5568 - acc: 0.2079 - val_loss: 2.6526 - val_acc: 0.1724\n",
            "Epoch 35/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.5618 - acc: 0.2051 - val_loss: 2.6402 - val_acc: 0.1810\n",
            "Epoch 36/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.6235 - acc: 0.2030 - val_loss: 2.6388 - val_acc: 0.1746\n",
            "Epoch 37/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.5372 - acc: 0.2030 - val_loss: 2.6431 - val_acc: 0.1832\n",
            "Epoch 38/300\n",
            "89/89 [==============================] - 71s 783ms/step - loss: 2.5622 - acc: 0.1938 - val_loss: 2.6427 - val_acc: 0.1746\n",
            "Epoch 39/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.5567 - acc: 0.1916 - val_loss: 2.6602 - val_acc: 0.1789\n",
            "Epoch 40/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.5479 - acc: 0.1959 - val_loss: 2.6399 - val_acc: 0.1638\n",
            "Epoch 41/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.5415 - acc: 0.1980 - val_loss: 2.6521 - val_acc: 0.1703\n",
            "Epoch 42/300\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 2.5889 - acc: 0.1959 - val_loss: 2.6417 - val_acc: 0.1767\n",
            "Epoch 43/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.5306 - acc: 0.2115 - val_loss: 2.6544 - val_acc: 0.1724\n",
            "Epoch 44/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.5707 - acc: 0.1909 - val_loss: 2.6615 - val_acc: 0.1681\n",
            "Epoch 45/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.5790 - acc: 0.1945 - val_loss: 2.6468 - val_acc: 0.1746\n",
            "Epoch 46/300\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.5359 - acc: 0.2165 - val_loss: 2.6457 - val_acc: 0.1746\n",
            "Epoch 47/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.5718 - acc: 0.2044 - val_loss: 2.6275 - val_acc: 0.1724\n",
            "Epoch 48/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.5571 - acc: 0.2016 - val_loss: 2.6533 - val_acc: 0.1724\n",
            "Epoch 49/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.5455 - acc: 0.2001 - val_loss: 2.6319 - val_acc: 0.1810\n",
            "Epoch 50/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.5489 - acc: 0.1966 - val_loss: 2.6217 - val_acc: 0.1703\n",
            "Epoch 51/300\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.4765 - acc: 0.2214 - val_loss: 2.6303 - val_acc: 0.1681\n",
            "Epoch 52/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.5496 - acc: 0.2009 - val_loss: 2.6429 - val_acc: 0.1746\n",
            "Epoch 53/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.5224 - acc: 0.2094 - val_loss: 2.6435 - val_acc: 0.1746\n",
            "Epoch 54/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.5517 - acc: 0.1945 - val_loss: 2.6442 - val_acc: 0.1789\n",
            "Epoch 55/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.4544 - acc: 0.2179 - val_loss: 2.6322 - val_acc: 0.1746\n",
            "Epoch 56/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.5006 - acc: 0.2200 - val_loss: 2.6414 - val_acc: 0.1746\n",
            "Epoch 57/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.5387 - acc: 0.1916 - val_loss: 2.6386 - val_acc: 0.1810\n",
            "Epoch 58/300\n",
            "89/89 [==============================] - 75s 816ms/step - loss: 2.4840 - acc: 0.2087 - val_loss: 2.6307 - val_acc: 0.1810\n",
            "Epoch 59/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.5344 - acc: 0.2122 - val_loss: 2.6411 - val_acc: 0.1767\n",
            "Epoch 60/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.6094 - acc: 0.2023 - val_loss: 2.6379 - val_acc: 0.1746\n",
            "Epoch 61/300\n",
            "89/89 [==============================] - 73s 823ms/step - loss: 2.4870 - acc: 0.2150 - val_loss: 2.6231 - val_acc: 0.1789\n",
            "Epoch 62/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.5274 - acc: 0.2108 - val_loss: 2.6210 - val_acc: 0.1746\n",
            "Epoch 63/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.4796 - acc: 0.2094 - val_loss: 2.6479 - val_acc: 0.1703\n",
            "Epoch 64/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.4903 - acc: 0.2009 - val_loss: 2.6374 - val_acc: 0.1703\n",
            "Epoch 65/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.5680 - acc: 0.2094 - val_loss: 2.6293 - val_acc: 0.1746\n",
            "Epoch 66/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.5295 - acc: 0.2193 - val_loss: 2.6316 - val_acc: 0.1724\n",
            "Epoch 67/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.5351 - acc: 0.2016 - val_loss: 2.6552 - val_acc: 0.1724\n",
            "Epoch 68/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.4632 - acc: 0.2165 - val_loss: 2.6381 - val_acc: 0.1767\n",
            "Epoch 69/300\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.4141 - acc: 0.2257 - val_loss: 2.6411 - val_acc: 0.1767\n",
            "Epoch 70/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.5471 - acc: 0.2115 - val_loss: 2.6350 - val_acc: 0.1767\n",
            "Epoch 71/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.5182 - acc: 0.1959 - val_loss: 2.6328 - val_acc: 0.1767\n",
            "Epoch 72/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.5238 - acc: 0.2009 - val_loss: 2.6286 - val_acc: 0.1724\n",
            "Epoch 73/300\n",
            "89/89 [==============================] - 72s 818ms/step - loss: 2.4713 - acc: 0.2030 - val_loss: 2.6205 - val_acc: 0.1789\n",
            "Epoch 74/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.4540 - acc: 0.2165 - val_loss: 2.6407 - val_acc: 0.1789\n",
            "Epoch 75/300\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.5066 - acc: 0.2044 - val_loss: 2.6482 - val_acc: 0.1810\n",
            "Epoch 76/300\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.4942 - acc: 0.2016 - val_loss: 2.6287 - val_acc: 0.1789\n",
            "Epoch 77/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.4965 - acc: 0.1938 - val_loss: 2.6454 - val_acc: 0.1810\n",
            "Epoch 78/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.5340 - acc: 0.1930 - val_loss: 2.6548 - val_acc: 0.1724\n",
            "Epoch 79/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.4801 - acc: 0.2143 - val_loss: 2.6343 - val_acc: 0.1810\n",
            "Epoch 80/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.5612 - acc: 0.2030 - val_loss: 2.6586 - val_acc: 0.1746\n",
            "Epoch 81/300\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.4978 - acc: 0.2179 - val_loss: 2.6235 - val_acc: 0.1724\n",
            "Epoch 82/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.4943 - acc: 0.2016 - val_loss: 2.6374 - val_acc: 0.1810\n",
            "Epoch 83/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.5033 - acc: 0.2023 - val_loss: 2.6385 - val_acc: 0.1746\n",
            "Epoch 84/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.5071 - acc: 0.2058 - val_loss: 2.6463 - val_acc: 0.1724\n",
            "Epoch 85/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.5020 - acc: 0.2158 - val_loss: 2.6671 - val_acc: 0.1724\n",
            "Epoch 86/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.5174 - acc: 0.2009 - val_loss: 2.6675 - val_acc: 0.1724\n",
            "Epoch 87/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.5070 - acc: 0.2058 - val_loss: 2.6463 - val_acc: 0.1832\n",
            "Epoch 88/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.4575 - acc: 0.2058 - val_loss: 2.6568 - val_acc: 0.1789\n",
            "Epoch 89/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.4736 - acc: 0.2108 - val_loss: 2.6518 - val_acc: 0.1810\n",
            "Epoch 90/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.4814 - acc: 0.2037 - val_loss: 2.6355 - val_acc: 0.1767\n",
            "Epoch 91/300\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.4839 - acc: 0.2207 - val_loss: 2.6437 - val_acc: 0.1767\n",
            "Epoch 92/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.5225 - acc: 0.1959 - val_loss: 2.6340 - val_acc: 0.1853\n",
            "Epoch 93/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.4848 - acc: 0.2122 - val_loss: 2.6310 - val_acc: 0.1789\n",
            "Epoch 94/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.5246 - acc: 0.2065 - val_loss: 2.6436 - val_acc: 0.1746\n",
            "Epoch 95/300\n",
            "89/89 [==============================] - 75s 796ms/step - loss: 2.4876 - acc: 0.2243 - val_loss: 2.6513 - val_acc: 0.1746\n",
            "Epoch 96/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.5119 - acc: 0.1909 - val_loss: 2.6263 - val_acc: 0.1810\n",
            "Epoch 97/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.4808 - acc: 0.2001 - val_loss: 2.6445 - val_acc: 0.1832\n",
            "Epoch 98/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.4624 - acc: 0.2179 - val_loss: 2.6548 - val_acc: 0.1853\n",
            "Epoch 99/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.4821 - acc: 0.2172 - val_loss: 2.6147 - val_acc: 0.1875\n",
            "Epoch 100/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.5331 - acc: 0.2037 - val_loss: 2.6616 - val_acc: 0.1789\n",
            "Epoch 101/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.4997 - acc: 0.2101 - val_loss: 2.6417 - val_acc: 0.1832\n",
            "Epoch 102/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4366 - acc: 0.2058 - val_loss: 2.6407 - val_acc: 0.1767\n",
            "Epoch 103/300\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.5225 - acc: 0.2016 - val_loss: 2.6479 - val_acc: 0.1853\n",
            "Epoch 104/300\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.4971 - acc: 0.2079 - val_loss: 2.6441 - val_acc: 0.1789\n",
            "Epoch 105/300\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.5121 - acc: 0.1973 - val_loss: 2.6553 - val_acc: 0.1746\n",
            "Epoch 106/300\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.4680 - acc: 0.2129 - val_loss: 2.6440 - val_acc: 0.1810\n",
            "Epoch 107/300\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.4614 - acc: 0.1994 - val_loss: 2.6459 - val_acc: 0.1810\n",
            "Epoch 108/300\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.4719 - acc: 0.2023 - val_loss: 2.6496 - val_acc: 0.1746\n",
            "Epoch 109/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.4542 - acc: 0.2150 - val_loss: 2.6384 - val_acc: 0.1746\n",
            "Epoch 110/300\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.4855 - acc: 0.2122 - val_loss: 2.6572 - val_acc: 0.1746\n",
            "Epoch 111/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.4979 - acc: 0.2207 - val_loss: 2.6591 - val_acc: 0.1789\n",
            "Epoch 112/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.4804 - acc: 0.2079 - val_loss: 2.6675 - val_acc: 0.1832\n",
            "Epoch 113/300\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.4638 - acc: 0.2129 - val_loss: 2.6554 - val_acc: 0.1897\n",
            "Epoch 114/300\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.4834 - acc: 0.2150 - val_loss: 2.6483 - val_acc: 0.1832\n",
            "Epoch 115/300\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.4561 - acc: 0.2229 - val_loss: 2.6559 - val_acc: 0.1832\n",
            "Epoch 116/300\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.4622 - acc: 0.2023 - val_loss: 2.6510 - val_acc: 0.1746\n",
            "Epoch 117/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.4933 - acc: 0.2030 - val_loss: 2.6570 - val_acc: 0.1853\n",
            "Epoch 118/300\n",
            "89/89 [==============================] - 74s 819ms/step - loss: 2.4443 - acc: 0.2136 - val_loss: 2.6539 - val_acc: 0.1832\n",
            "Epoch 119/300\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.4452 - acc: 0.2221 - val_loss: 2.6445 - val_acc: 0.1767\n",
            "Epoch 120/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.4824 - acc: 0.2108 - val_loss: 2.6462 - val_acc: 0.1767\n",
            "Epoch 121/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.4453 - acc: 0.2058 - val_loss: 2.6599 - val_acc: 0.1767\n",
            "Epoch 122/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.4764 - acc: 0.2009 - val_loss: 2.6654 - val_acc: 0.1703\n",
            "Epoch 123/300\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.4618 - acc: 0.2221 - val_loss: 2.6612 - val_acc: 0.1810\n",
            "Epoch 124/300\n",
            "89/89 [==============================] - 75s 829ms/step - loss: 2.4546 - acc: 0.2023 - val_loss: 2.6481 - val_acc: 0.1832\n",
            "Epoch 125/300\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.4887 - acc: 0.2001 - val_loss: 2.6606 - val_acc: 0.1810\n",
            "Epoch 126/300\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.4410 - acc: 0.2229 - val_loss: 2.6631 - val_acc: 0.1853\n",
            "Epoch 127/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.4482 - acc: 0.2250 - val_loss: 2.6613 - val_acc: 0.1810\n",
            "Epoch 128/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.4739 - acc: 0.2115 - val_loss: 2.6612 - val_acc: 0.1746\n",
            "Epoch 129/300\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.4188 - acc: 0.2335 - val_loss: 2.6740 - val_acc: 0.1703\n",
            "Epoch 130/300\n",
            "89/89 [==============================] - 72s 798ms/step - loss: 2.4298 - acc: 0.2200 - val_loss: 2.6542 - val_acc: 0.1810\n",
            "Epoch 131/300\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.4779 - acc: 0.2158 - val_loss: 2.6595 - val_acc: 0.1767\n",
            "Epoch 132/300\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.4443 - acc: 0.2321 - val_loss: 2.6611 - val_acc: 0.1810\n",
            "Epoch 133/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.4463 - acc: 0.2207 - val_loss: 2.6694 - val_acc: 0.1789\n",
            "Epoch 134/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.4192 - acc: 0.2229 - val_loss: 2.6946 - val_acc: 0.1767\n",
            "Epoch 135/300\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.4128 - acc: 0.2207 - val_loss: 2.6618 - val_acc: 0.1832\n",
            "Epoch 136/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.5340 - acc: 0.2030 - val_loss: 2.6590 - val_acc: 0.1746\n",
            "Epoch 137/300\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 2.4248 - acc: 0.2214 - val_loss: 2.6690 - val_acc: 0.1810\n",
            "Epoch 138/300\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.4800 - acc: 0.2172 - val_loss: 2.6442 - val_acc: 0.1853\n",
            "Epoch 139/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.4635 - acc: 0.1966 - val_loss: 2.6719 - val_acc: 0.1875\n",
            "Epoch 140/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.4638 - acc: 0.2221 - val_loss: 2.6489 - val_acc: 0.1832\n",
            "Epoch 141/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.4657 - acc: 0.2392 - val_loss: 2.6725 - val_acc: 0.1789\n",
            "Epoch 142/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.4797 - acc: 0.2122 - val_loss: 2.6763 - val_acc: 0.1789\n",
            "Epoch 143/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.4136 - acc: 0.2243 - val_loss: 2.6775 - val_acc: 0.1853\n",
            "Epoch 144/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.4343 - acc: 0.2065 - val_loss: 2.6795 - val_acc: 0.1767\n",
            "Epoch 145/300\n",
            "89/89 [==============================] - 73s 786ms/step - loss: 2.4525 - acc: 0.2250 - val_loss: 2.6676 - val_acc: 0.1746\n",
            "Epoch 146/300\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.4373 - acc: 0.2122 - val_loss: 2.6674 - val_acc: 0.1789\n",
            "Epoch 147/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.4180 - acc: 0.2150 - val_loss: 2.6573 - val_acc: 0.1810\n",
            "Epoch 148/300\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.4482 - acc: 0.2271 - val_loss: 2.6810 - val_acc: 0.1746\n",
            "Epoch 149/300\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.4273 - acc: 0.2214 - val_loss: 2.6735 - val_acc: 0.1724\n",
            "Epoch 150/300\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.4080 - acc: 0.2165 - val_loss: 2.6516 - val_acc: 0.1789\n",
            "Epoch 151/300\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.3976 - acc: 0.2385 - val_loss: 2.6594 - val_acc: 0.1724\n",
            "Epoch 152/300\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.4364 - acc: 0.2257 - val_loss: 2.6729 - val_acc: 0.1789\n",
            "Epoch 153/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.4609 - acc: 0.2087 - val_loss: 2.6790 - val_acc: 0.1767\n",
            "Epoch 154/300\n",
            "89/89 [==============================] - 75s 809ms/step - loss: 2.4492 - acc: 0.2165 - val_loss: 2.6713 - val_acc: 0.1810\n",
            "Epoch 155/300\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.4704 - acc: 0.2292 - val_loss: 2.6624 - val_acc: 0.1767\n",
            "Epoch 156/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.4343 - acc: 0.2129 - val_loss: 2.6672 - val_acc: 0.1853\n",
            "Epoch 157/300\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.4287 - acc: 0.2229 - val_loss: 2.6953 - val_acc: 0.1789\n",
            "Epoch 158/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4297 - acc: 0.2236 - val_loss: 2.6868 - val_acc: 0.1703\n",
            "Epoch 159/300\n",
            "89/89 [==============================] - 72s 784ms/step - loss: 2.4157 - acc: 0.2278 - val_loss: 2.6830 - val_acc: 0.1789\n",
            "Epoch 160/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.3847 - acc: 0.2321 - val_loss: 2.6687 - val_acc: 0.1767\n",
            "Epoch 161/300\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 2.4525 - acc: 0.2101 - val_loss: 2.6741 - val_acc: 0.1875\n",
            "Epoch 162/300\n",
            "89/89 [==============================] - 71s 780ms/step - loss: 2.4258 - acc: 0.2200 - val_loss: 2.6725 - val_acc: 0.1767\n",
            "Epoch 163/300\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.4033 - acc: 0.2300 - val_loss: 2.6593 - val_acc: 0.1810\n",
            "Epoch 164/300\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.4231 - acc: 0.2172 - val_loss: 2.6720 - val_acc: 0.1810\n",
            "Epoch 165/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.4242 - acc: 0.2250 - val_loss: 2.6980 - val_acc: 0.1681\n",
            "Epoch 166/300\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.4225 - acc: 0.2250 - val_loss: 2.6837 - val_acc: 0.1810\n",
            "Epoch 167/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.4362 - acc: 0.2236 - val_loss: 2.6509 - val_acc: 0.1897\n",
            "Epoch 168/300\n",
            "89/89 [==============================] - 71s 784ms/step - loss: 2.4288 - acc: 0.2129 - val_loss: 2.6854 - val_acc: 0.1789\n",
            "Epoch 169/300\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.4297 - acc: 0.2314 - val_loss: 2.6665 - val_acc: 0.1767\n",
            "Epoch 170/300\n",
            "89/89 [==============================] - 71s 781ms/step - loss: 2.4150 - acc: 0.2314 - val_loss: 2.6932 - val_acc: 0.1832\n",
            "Epoch 171/300\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.4086 - acc: 0.2193 - val_loss: 2.6935 - val_acc: 0.1832\n",
            "Epoch 172/300\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.4388 - acc: 0.2261 - val_loss: 2.6871 - val_acc: 0.1832\n",
            "Epoch 173/300\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 2.3916 - acc: 0.2257 - val_loss: 2.6543 - val_acc: 0.1789\n",
            "Epoch 174/300\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.4421 - acc: 0.2108 - val_loss: 2.6831 - val_acc: 0.1616\n",
            "Epoch 175/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4288 - acc: 0.2200 - val_loss: 2.6729 - val_acc: 0.1767\n",
            "Epoch 176/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.3844 - acc: 0.2264 - val_loss: 2.6661 - val_acc: 0.1897\n",
            "Epoch 177/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4082 - acc: 0.2072 - val_loss: 2.6563 - val_acc: 0.1789\n",
            "Epoch 178/300\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.4417 - acc: 0.1930 - val_loss: 2.6659 - val_acc: 0.1832\n",
            "Epoch 179/300\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.3982 - acc: 0.2328 - val_loss: 2.6695 - val_acc: 0.1767\n",
            "Epoch 180/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4594 - acc: 0.2292 - val_loss: 2.6712 - val_acc: 0.1810\n",
            "Epoch 181/300\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4485 - acc: 0.2136 - val_loss: 2.6764 - val_acc: 0.1767\n",
            "Epoch 182/300\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.3808 - acc: 0.2321 - val_loss: 2.6767 - val_acc: 0.1875\n",
            "Epoch 183/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.4653 - acc: 0.2193 - val_loss: 2.6660 - val_acc: 0.1897\n",
            "Epoch 184/300\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.4289 - acc: 0.2158 - val_loss: 2.6581 - val_acc: 0.1810\n",
            "Epoch 185/300\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.4306 - acc: 0.2115 - val_loss: 2.6737 - val_acc: 0.1767\n",
            "Epoch 186/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.3981 - acc: 0.2406 - val_loss: 2.6758 - val_acc: 0.1832\n",
            "Epoch 187/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.4278 - acc: 0.2200 - val_loss: 2.6722 - val_acc: 0.1810\n",
            "Epoch 188/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.4199 - acc: 0.2079 - val_loss: 2.7019 - val_acc: 0.1767\n",
            "Epoch 189/300\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.4380 - acc: 0.2278 - val_loss: 2.6807 - val_acc: 0.1853\n",
            "Epoch 190/300\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.4443 - acc: 0.2172 - val_loss: 2.6799 - val_acc: 0.1810\n",
            "Epoch 191/300\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.3790 - acc: 0.2250 - val_loss: 2.6929 - val_acc: 0.1724\n",
            "Epoch 192/300\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.4069 - acc: 0.2264 - val_loss: 2.6706 - val_acc: 0.1724\n",
            "Epoch 193/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.4000 - acc: 0.2143 - val_loss: 2.6753 - val_acc: 0.1746\n",
            "Epoch 194/300\n",
            "89/89 [==============================] - 72s 797ms/step - loss: 2.3743 - acc: 0.2229 - val_loss: 2.6722 - val_acc: 0.1746\n",
            "Epoch 195/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.4138 - acc: 0.2158 - val_loss: 2.6637 - val_acc: 0.1810\n",
            "Epoch 196/300\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.3883 - acc: 0.2300 - val_loss: 2.6734 - val_acc: 0.1703\n",
            "Epoch 197/300\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.4491 - acc: 0.2044 - val_loss: 2.6883 - val_acc: 0.1659\n",
            "Epoch 198/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.4351 - acc: 0.2051 - val_loss: 2.6650 - val_acc: 0.1767\n",
            "Epoch 199/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.4148 - acc: 0.2229 - val_loss: 2.6715 - val_acc: 0.1810\n",
            "Epoch 200/300\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.4207 - acc: 0.2207 - val_loss: 2.6759 - val_acc: 0.1703\n",
            "Epoch 201/300\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.3826 - acc: 0.2356 - val_loss: 2.6676 - val_acc: 0.1746\n",
            "Epoch 202/300\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.4139 - acc: 0.2129 - val_loss: 2.6492 - val_acc: 0.1703\n",
            "Epoch 203/300\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.3935 - acc: 0.2335 - val_loss: 2.6709 - val_acc: 0.1724\n",
            "Epoch 204/300\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.3439 - acc: 0.2292 - val_loss: 2.6799 - val_acc: 0.1832\n",
            "Epoch 205/300\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.3824 - acc: 0.2087 - val_loss: 2.6884 - val_acc: 0.1810\n",
            "Epoch 206/300\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.3928 - acc: 0.2250 - val_loss: 2.6893 - val_acc: 0.1789\n",
            "Epoch 207/300\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.3427 - acc: 0.2392 - val_loss: 2.6830 - val_acc: 0.1832\n",
            "Epoch 208/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.3955 - acc: 0.2292 - val_loss: 2.6738 - val_acc: 0.1789\n",
            "Epoch 209/300\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.3719 - acc: 0.2328 - val_loss: 2.6521 - val_acc: 0.1897\n",
            "Epoch 210/300\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.4300 - acc: 0.2136 - val_loss: 2.6543 - val_acc: 0.1853\n",
            "Epoch 211/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.3707 - acc: 0.2278 - val_loss: 2.6688 - val_acc: 0.1940\n",
            "Epoch 212/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.4064 - acc: 0.2179 - val_loss: 2.6642 - val_acc: 0.1789\n",
            "Epoch 213/300\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.3541 - acc: 0.2527 - val_loss: 2.6817 - val_acc: 0.1767\n",
            "Epoch 214/300\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.3771 - acc: 0.2349 - val_loss: 2.6579 - val_acc: 0.1810\n",
            "Epoch 215/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.4034 - acc: 0.2179 - val_loss: 2.6565 - val_acc: 0.1810\n",
            "Epoch 216/300\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 2.3756 - acc: 0.2186 - val_loss: 2.6598 - val_acc: 0.1789\n",
            "Epoch 217/300\n",
            "89/89 [==============================] - 74s 790ms/step - loss: 2.3417 - acc: 0.2243 - val_loss: 2.6930 - val_acc: 0.1746\n",
            "Epoch 218/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.3975 - acc: 0.2264 - val_loss: 2.6467 - val_acc: 0.1746\n",
            "Epoch 219/300\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.3652 - acc: 0.2314 - val_loss: 2.6391 - val_acc: 0.1810\n",
            "Epoch 220/300\n",
            "89/89 [==============================] - 72s 784ms/step - loss: 2.4146 - acc: 0.2101 - val_loss: 2.6532 - val_acc: 0.1832\n",
            "Epoch 221/300\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.3474 - acc: 0.2335 - val_loss: 2.6689 - val_acc: 0.1789\n",
            "Epoch 222/300\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.3943 - acc: 0.2044 - val_loss: 2.6806 - val_acc: 0.1789\n",
            "Epoch 223/300\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.3911 - acc: 0.2314 - val_loss: 2.6755 - val_acc: 0.1767\n",
            "Epoch 224/300\n",
            " 1/89 [..............................] - ETA: 3:46 - loss: 2.0921 - acc: 0.3750"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Mx-si2lQQWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/Flimpano_Female125_300.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('./content/drive/My Drive/cut_panoramic/Flimpano_Female_100.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyNRKoopf9WE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}