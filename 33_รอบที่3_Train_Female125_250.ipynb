{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/33_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%883_Train_Female125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "3ef988ec-433c-4455-99a1-7ac0ea66c841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EG3WyBRiPM0P",
        "outputId": "d866d92b-1dc1-460f-9ac7-47cc1b06744a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07F         V1.jpg   \n",
              "1           2               1          7  Y07F    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         V2.jpg   \n",
              "3           4               2          7  Y07F    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         V3.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              65         25  Y25F  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9946dacc-141c-4936-abe0-d63b270dfaa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9946dacc-141c-4936-abe0-d63b270dfaa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9946dacc-141c-4936-abe0-d63b270dfaa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9946dacc-141c-4936-abe0-d63b270dfaa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Female_125.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 473\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "2998b4c3-d6bb-48ff-b113-177b3614a321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 545, done.\u001b[K\n",
            "remote: Counting objects: 100% (361/361), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 545 (delta 257), reused 266 (delta 199), pack-reused 184\u001b[K\n",
            "Receiving objects: 100% (545/545), 10.21 MiB | 24.27 MiB/s, done.\n",
            "Resolving deltas: 100% (330/330), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "outputs": [],
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SxQTV4IKPb5h",
        "outputId": "7deec0fe-1a1d-46ed-981b-979ec7bbf6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVGeF9M7PchT",
        "outputId": "560b8d88-505f-44b4-aef0-7eefef30529f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary() #ดู Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od-ZSNm5PoGy"
      },
      "source": [
        "#load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/22_รอบที่2_Flimpano_Female125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "outputs": [],
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/22_รอบที่2_Flimpano_Female125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "bdf1ebda-a40b-4dc4-c048-d5369c61f27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od14yWT7Pka1",
        "outputId": "906aedc7-7b32-4fc6-e2f7-301d79380a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "21168b45-82b9-49a6-dd79-9aa40a205052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-15-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 111s 1s/step - loss: 2.3653 - acc: 0.2285 - val_loss: 2.7100 - val_acc: 0.1832\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.4369 - acc: 0.2143 - val_loss: 2.7146 - val_acc: 0.1767\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.4633 - acc: 0.2094 - val_loss: 2.7115 - val_acc: 0.1875\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.4222 - acc: 0.2122 - val_loss: 2.7119 - val_acc: 0.1875\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 79s 875ms/step - loss: 2.3634 - acc: 0.2158 - val_loss: 2.7549 - val_acc: 0.1789\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.3757 - acc: 0.2406 - val_loss: 2.7155 - val_acc: 0.1940\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 79s 868ms/step - loss: 2.3660 - acc: 0.2434 - val_loss: 2.7049 - val_acc: 0.1810\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.3354 - acc: 0.2278 - val_loss: 2.7282 - val_acc: 0.1853\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.3962 - acc: 0.2179 - val_loss: 2.7116 - val_acc: 0.1897\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.3973 - acc: 0.2165 - val_loss: 2.6931 - val_acc: 0.1832\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.3514 - acc: 0.2200 - val_loss: 2.7093 - val_acc: 0.1853\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.3927 - acc: 0.2200 - val_loss: 2.7292 - val_acc: 0.1767\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.4667 - acc: 0.2186 - val_loss: 2.7050 - val_acc: 0.1789\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 74s 797ms/step - loss: 2.4076 - acc: 0.2243 - val_loss: 2.7376 - val_acc: 0.1810\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.3845 - acc: 0.2229 - val_loss: 2.6957 - val_acc: 0.1853\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.3641 - acc: 0.2214 - val_loss: 2.7203 - val_acc: 0.1875\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.3925 - acc: 0.2214 - val_loss: 2.6889 - val_acc: 0.1897\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.4316 - acc: 0.2065 - val_loss: 2.7613 - val_acc: 0.1853\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 77s 826ms/step - loss: 2.3943 - acc: 0.2292 - val_loss: 2.7595 - val_acc: 0.1810\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.4073 - acc: 0.2165 - val_loss: 2.7509 - val_acc: 0.1853\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 81s 885ms/step - loss: 2.4001 - acc: 0.2200 - val_loss: 2.7594 - val_acc: 0.1789\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 75s 816ms/step - loss: 2.3287 - acc: 0.2477 - val_loss: 2.7324 - val_acc: 0.1789\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.3368 - acc: 0.2356 - val_loss: 2.7469 - val_acc: 0.1875\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.4075 - acc: 0.2122 - val_loss: 2.7307 - val_acc: 0.1832\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.3757 - acc: 0.2285 - val_loss: 2.7389 - val_acc: 0.1767\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.3493 - acc: 0.2378 - val_loss: 2.7065 - val_acc: 0.1789\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4071 - acc: 0.2221 - val_loss: 2.7230 - val_acc: 0.1853\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.3672 - acc: 0.2285 - val_loss: 2.7227 - val_acc: 0.1810\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.3888 - acc: 0.2236 - val_loss: 2.7141 - val_acc: 0.1832\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 81s 890ms/step - loss: 2.3273 - acc: 0.2363 - val_loss: 2.7282 - val_acc: 0.1875\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.3919 - acc: 0.2186 - val_loss: 2.7085 - val_acc: 0.1853\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.3797 - acc: 0.2221 - val_loss: 2.7399 - val_acc: 0.1853\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 80s 886ms/step - loss: 2.3972 - acc: 0.2250 - val_loss: 2.7318 - val_acc: 0.1767\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.3761 - acc: 0.2257 - val_loss: 2.7204 - val_acc: 0.1703\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.4092 - acc: 0.2221 - val_loss: 2.7230 - val_acc: 0.1853\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.3960 - acc: 0.2079 - val_loss: 2.7249 - val_acc: 0.1832\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.3481 - acc: 0.2250 - val_loss: 2.7107 - val_acc: 0.1810\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.3824 - acc: 0.2214 - val_loss: 2.7453 - val_acc: 0.1918\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.3526 - acc: 0.2278 - val_loss: 2.7355 - val_acc: 0.1832\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 79s 865ms/step - loss: 2.3724 - acc: 0.2307 - val_loss: 2.7074 - val_acc: 0.1853\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.4318 - acc: 0.2072 - val_loss: 2.7166 - val_acc: 0.1897\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.3746 - acc: 0.2243 - val_loss: 2.7181 - val_acc: 0.1832\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.3764 - acc: 0.2221 - val_loss: 2.7098 - val_acc: 0.1832\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.3748 - acc: 0.2250 - val_loss: 2.7227 - val_acc: 0.1853\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.3657 - acc: 0.2342 - val_loss: 2.7311 - val_acc: 0.1897\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 78s 857ms/step - loss: 2.3390 - acc: 0.2300 - val_loss: 2.7276 - val_acc: 0.1810\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.3483 - acc: 0.2250 - val_loss: 2.7324 - val_acc: 0.1853\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 2.3575 - acc: 0.2406 - val_loss: 2.7266 - val_acc: 0.1832\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 79s 868ms/step - loss: 2.3838 - acc: 0.2221 - val_loss: 2.7226 - val_acc: 0.1918\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.3678 - acc: 0.2441 - val_loss: 2.7360 - val_acc: 0.1832\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.3194 - acc: 0.2434 - val_loss: 2.7371 - val_acc: 0.1875\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.3954 - acc: 0.2243 - val_loss: 2.7501 - val_acc: 0.1832\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.3738 - acc: 0.2420 - val_loss: 2.7192 - val_acc: 0.1853\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.3966 - acc: 0.2179 - val_loss: 2.7240 - val_acc: 0.1832\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 80s 874ms/step - loss: 2.3210 - acc: 0.2392 - val_loss: 2.7158 - val_acc: 0.1853\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.3280 - acc: 0.2427 - val_loss: 2.7069 - val_acc: 0.1875\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.3547 - acc: 0.2356 - val_loss: 2.7456 - val_acc: 0.1810\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 79s 868ms/step - loss: 2.3680 - acc: 0.2420 - val_loss: 2.7476 - val_acc: 0.1810\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.3602 - acc: 0.2335 - val_loss: 2.7412 - val_acc: 0.1810\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.3275 - acc: 0.2328 - val_loss: 2.7462 - val_acc: 0.1746\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 79s 870ms/step - loss: 2.3527 - acc: 0.2285 - val_loss: 2.7430 - val_acc: 0.1789\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.3596 - acc: 0.2250 - val_loss: 2.7158 - val_acc: 0.1853\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.3536 - acc: 0.2367 - val_loss: 2.7330 - val_acc: 0.1875\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 78s 863ms/step - loss: 2.3637 - acc: 0.2292 - val_loss: 2.7319 - val_acc: 0.1897\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.3914 - acc: 0.2221 - val_loss: 2.7481 - val_acc: 0.1832\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.3721 - acc: 0.2257 - val_loss: 2.7559 - val_acc: 0.1853\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.3548 - acc: 0.2179 - val_loss: 2.7287 - val_acc: 0.1832\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.3609 - acc: 0.2314 - val_loss: 2.7276 - val_acc: 0.1789\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.3821 - acc: 0.2243 - val_loss: 2.7527 - val_acc: 0.1789\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 79s 863ms/step - loss: 2.3587 - acc: 0.2250 - val_loss: 2.7518 - val_acc: 0.1746\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.3234 - acc: 0.2434 - val_loss: 2.7389 - val_acc: 0.1832\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.3922 - acc: 0.2328 - val_loss: 2.7459 - val_acc: 0.1810\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 78s 887ms/step - loss: 2.3371 - acc: 0.2385 - val_loss: 2.7418 - val_acc: 0.1810\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.3361 - acc: 0.2441 - val_loss: 2.7147 - val_acc: 0.1832\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.3652 - acc: 0.2406 - val_loss: 2.7223 - val_acc: 0.1853\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 79s 868ms/step - loss: 2.3197 - acc: 0.2349 - val_loss: 2.7107 - val_acc: 0.1875\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.3587 - acc: 0.2427 - val_loss: 2.7102 - val_acc: 0.1832\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.3483 - acc: 0.2335 - val_loss: 2.7427 - val_acc: 0.1724\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 77s 826ms/step - loss: 2.3877 - acc: 0.2314 - val_loss: 2.7131 - val_acc: 0.1832\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.3309 - acc: 0.2437 - val_loss: 2.7130 - val_acc: 0.1810\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.3142 - acc: 0.2321 - val_loss: 2.7499 - val_acc: 0.1724\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.3644 - acc: 0.2221 - val_loss: 2.7284 - val_acc: 0.1746\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.3422 - acc: 0.2392 - val_loss: 2.7075 - val_acc: 0.1897\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 81s 891ms/step - loss: 2.3396 - acc: 0.2207 - val_loss: 2.7199 - val_acc: 0.1918\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.3420 - acc: 0.2335 - val_loss: 2.7286 - val_acc: 0.1853\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.3471 - acc: 0.2342 - val_loss: 2.7206 - val_acc: 0.1810\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 79s 872ms/step - loss: 2.3059 - acc: 0.2555 - val_loss: 2.7346 - val_acc: 0.1853\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.3215 - acc: 0.2434 - val_loss: 2.7371 - val_acc: 0.1810\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.3671 - acc: 0.2378 - val_loss: 2.7554 - val_acc: 0.1789\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 78s 857ms/step - loss: 2.3391 - acc: 0.2520 - val_loss: 2.7431 - val_acc: 0.1853\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.3855 - acc: 0.2307 - val_loss: 2.7317 - val_acc: 0.1853\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.3093 - acc: 0.2370 - val_loss: 2.7333 - val_acc: 0.1875\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 80s 872ms/step - loss: 2.3232 - acc: 0.2370 - val_loss: 2.7326 - val_acc: 0.1789\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.3324 - acc: 0.2576 - val_loss: 2.7338 - val_acc: 0.1810\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.3585 - acc: 0.2186 - val_loss: 2.7413 - val_acc: 0.1767\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.3545 - acc: 0.2363 - val_loss: 2.7275 - val_acc: 0.1832\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.2762 - acc: 0.2612 - val_loss: 2.7304 - val_acc: 0.1789\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.3450 - acc: 0.2385 - val_loss: 2.7280 - val_acc: 0.1853\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2739 - acc: 0.2427 - val_loss: 2.7105 - val_acc: 0.1767\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.3092 - acc: 0.2335 - val_loss: 2.7160 - val_acc: 0.1832\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.3473 - acc: 0.2328 - val_loss: 2.6965 - val_acc: 0.1853\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 80s 876ms/step - loss: 2.3400 - acc: 0.2392 - val_loss: 2.6909 - val_acc: 0.1810\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.3040 - acc: 0.2399 - val_loss: 2.7289 - val_acc: 0.1810\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.3148 - acc: 0.2477 - val_loss: 2.7274 - val_acc: 0.1810\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.3139 - acc: 0.2548 - val_loss: 2.6964 - val_acc: 0.1789\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.2690 - acc: 0.2470 - val_loss: 2.7288 - val_acc: 0.1767\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.3216 - acc: 0.2349 - val_loss: 2.7099 - val_acc: 0.1810\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 79s 846ms/step - loss: 2.3396 - acc: 0.2434 - val_loss: 2.7374 - val_acc: 0.1832\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.3047 - acc: 0.2477 - val_loss: 2.6942 - val_acc: 0.1810\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.3666 - acc: 0.2229 - val_loss: 2.7036 - val_acc: 0.1832\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.3592 - acc: 0.2342 - val_loss: 2.6935 - val_acc: 0.1853\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.3593 - acc: 0.2413 - val_loss: 2.7241 - val_acc: 0.1789\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 81s 886ms/step - loss: 2.3498 - acc: 0.2456 - val_loss: 2.7230 - val_acc: 0.1746\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.2745 - acc: 0.2512 - val_loss: 2.7046 - val_acc: 0.1789\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 2.2954 - acc: 0.2484 - val_loss: 2.7261 - val_acc: 0.1746\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 80s 876ms/step - loss: 2.3109 - acc: 0.2321 - val_loss: 2.7056 - val_acc: 0.1767\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.3180 - acc: 0.2583 - val_loss: 2.7183 - val_acc: 0.1789\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 80s 873ms/step - loss: 2.3054 - acc: 0.2406 - val_loss: 2.7398 - val_acc: 0.1789\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.3356 - acc: 0.2328 - val_loss: 2.7159 - val_acc: 0.1810\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.3158 - acc: 0.2314 - val_loss: 2.7133 - val_acc: 0.1832\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 81s 891ms/step - loss: 2.3577 - acc: 0.2392 - val_loss: 2.7376 - val_acc: 0.1832\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.3458 - acc: 0.2449 - val_loss: 2.7456 - val_acc: 0.1810\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.3601 - acc: 0.2243 - val_loss: 2.7469 - val_acc: 0.1789\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 78s 857ms/step - loss: 2.3286 - acc: 0.2378 - val_loss: 2.7214 - val_acc: 0.1789\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.3167 - acc: 0.2441 - val_loss: 2.7192 - val_acc: 0.1853\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.2980 - acc: 0.2420 - val_loss: 2.7150 - val_acc: 0.1875\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.3382 - acc: 0.2342 - val_loss: 2.7314 - val_acc: 0.1810\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2887 - acc: 0.2541 - val_loss: 2.7279 - val_acc: 0.1724\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.2830 - acc: 0.2449 - val_loss: 2.7135 - val_acc: 0.1767\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.3112 - acc: 0.2477 - val_loss: 2.6991 - val_acc: 0.1853\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.3534 - acc: 0.2413 - val_loss: 2.7132 - val_acc: 0.1746\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.3315 - acc: 0.2292 - val_loss: 2.7345 - val_acc: 0.1767\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2839 - acc: 0.2363 - val_loss: 2.7164 - val_acc: 0.1875\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.3141 - acc: 0.2463 - val_loss: 2.7066 - val_acc: 0.1875\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 77s 825ms/step - loss: 2.3189 - acc: 0.2434 - val_loss: 2.7082 - val_acc: 0.1832\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 79s 870ms/step - loss: 2.2879 - acc: 0.2484 - val_loss: 2.7315 - val_acc: 0.1810\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.2692 - acc: 0.2498 - val_loss: 2.7194 - val_acc: 0.1832\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.3345 - acc: 0.2392 - val_loss: 2.7008 - val_acc: 0.1810\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.3127 - acc: 0.2434 - val_loss: 2.7100 - val_acc: 0.1853\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.3155 - acc: 0.2484 - val_loss: 2.7061 - val_acc: 0.1810\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.3321 - acc: 0.2406 - val_loss: 2.7191 - val_acc: 0.1810\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 77s 852ms/step - loss: 2.3178 - acc: 0.2335 - val_loss: 2.7100 - val_acc: 0.1767\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.2665 - acc: 0.2640 - val_loss: 2.7267 - val_acc: 0.1767\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.3248 - acc: 0.2229 - val_loss: 2.7019 - val_acc: 0.1832\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.3336 - acc: 0.2406 - val_loss: 2.7178 - val_acc: 0.1810\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.3292 - acc: 0.2200 - val_loss: 2.7166 - val_acc: 0.1746\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.3423 - acc: 0.2378 - val_loss: 2.7261 - val_acc: 0.1767\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.3301 - acc: 0.2392 - val_loss: 2.6968 - val_acc: 0.1789\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2796 - acc: 0.2583 - val_loss: 2.6926 - val_acc: 0.1767\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.3174 - acc: 0.2356 - val_loss: 2.7185 - val_acc: 0.1789\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 79s 851ms/step - loss: 2.2953 - acc: 0.2491 - val_loss: 2.7011 - val_acc: 0.1767\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.2997 - acc: 0.2328 - val_loss: 2.7410 - val_acc: 0.1810\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.3261 - acc: 0.2307 - val_loss: 2.7501 - val_acc: 0.1724\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.2949 - acc: 0.2335 - val_loss: 2.7191 - val_acc: 0.1767\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.2993 - acc: 0.2392 - val_loss: 2.7294 - val_acc: 0.1746\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 78s 858ms/step - loss: 2.2760 - acc: 0.2562 - val_loss: 2.7300 - val_acc: 0.1789\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 80s 877ms/step - loss: 2.3237 - acc: 0.2484 - val_loss: 2.7298 - val_acc: 0.1746\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 78s 857ms/step - loss: 2.3382 - acc: 0.2420 - val_loss: 2.7044 - val_acc: 0.1810\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.3087 - acc: 0.2434 - val_loss: 2.7247 - val_acc: 0.1746\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.2978 - acc: 0.2370 - val_loss: 2.7232 - val_acc: 0.1810\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 78s 843ms/step - loss: 2.2949 - acc: 0.2413 - val_loss: 2.7338 - val_acc: 0.1789\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.3306 - acc: 0.2463 - val_loss: 2.7232 - val_acc: 0.1767\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.3301 - acc: 0.2385 - val_loss: 2.7232 - val_acc: 0.1810\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.3428 - acc: 0.2328 - val_loss: 2.7061 - val_acc: 0.1875\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.2696 - acc: 0.2449 - val_loss: 2.7004 - val_acc: 0.1789\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2969 - acc: 0.2527 - val_loss: 2.7074 - val_acc: 0.1789\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.3008 - acc: 0.2427 - val_loss: 2.6893 - val_acc: 0.1767\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.2955 - acc: 0.2420 - val_loss: 2.7145 - val_acc: 0.1746\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.2968 - acc: 0.2512 - val_loss: 2.6983 - val_acc: 0.1789\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.3083 - acc: 0.2321 - val_loss: 2.7049 - val_acc: 0.1789\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2610 - acc: 0.2612 - val_loss: 2.7109 - val_acc: 0.1767\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2876 - acc: 0.2527 - val_loss: 2.7009 - val_acc: 0.1767\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.3005 - acc: 0.2427 - val_loss: 2.7080 - val_acc: 0.1789\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 76s 841ms/step - loss: 2.3382 - acc: 0.2342 - val_loss: 2.7193 - val_acc: 0.1810\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2870 - acc: 0.2456 - val_loss: 2.7093 - val_acc: 0.1789\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 79s 863ms/step - loss: 2.2855 - acc: 0.2477 - val_loss: 2.7063 - val_acc: 0.1724\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2639 - acc: 0.2619 - val_loss: 2.7410 - val_acc: 0.1810\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.3287 - acc: 0.2392 - val_loss: 2.7319 - val_acc: 0.1810\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2841 - acc: 0.2456 - val_loss: 2.7155 - val_acc: 0.1767\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.3094 - acc: 0.2427 - val_loss: 2.7166 - val_acc: 0.1703\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2895 - acc: 0.2463 - val_loss: 2.7376 - val_acc: 0.1853\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 76s 839ms/step - loss: 2.2934 - acc: 0.2484 - val_loss: 2.7052 - val_acc: 0.1767\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 77s 870ms/step - loss: 2.2970 - acc: 0.2427 - val_loss: 2.6959 - val_acc: 0.1724\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.3045 - acc: 0.2427 - val_loss: 2.7010 - val_acc: 0.1832\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2850 - acc: 0.2449 - val_loss: 2.7171 - val_acc: 0.1832\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.3278 - acc: 0.2527 - val_loss: 2.7240 - val_acc: 0.1853\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.3155 - acc: 0.2406 - val_loss: 2.7055 - val_acc: 0.1875\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.2710 - acc: 0.2619 - val_loss: 2.6946 - val_acc: 0.1789\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.2951 - acc: 0.2484 - val_loss: 2.7004 - val_acc: 0.1875\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2432 - acc: 0.2605 - val_loss: 2.7133 - val_acc: 0.1810\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2887 - acc: 0.2562 - val_loss: 2.7008 - val_acc: 0.1832\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.2404 - acc: 0.2683 - val_loss: 2.7257 - val_acc: 0.1724\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 78s 850ms/step - loss: 2.2950 - acc: 0.2505 - val_loss: 2.7125 - val_acc: 0.1746\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2509 - acc: 0.2548 - val_loss: 2.7285 - val_acc: 0.1746\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 80s 856ms/step - loss: 2.3119 - acc: 0.2434 - val_loss: 2.7049 - val_acc: 0.1832\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 2.2953 - acc: 0.2370 - val_loss: 2.7214 - val_acc: 0.1746\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.2749 - acc: 0.2434 - val_loss: 2.6849 - val_acc: 0.1832\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 79s 865ms/step - loss: 2.2880 - acc: 0.2399 - val_loss: 2.6978 - val_acc: 0.1810\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2661 - acc: 0.2683 - val_loss: 2.6998 - val_acc: 0.1832\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 78s 865ms/step - loss: 2.3024 - acc: 0.2292 - val_loss: 2.7021 - val_acc: 0.1918\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.2906 - acc: 0.2441 - val_loss: 2.7059 - val_acc: 0.1832\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2646 - acc: 0.2583 - val_loss: 2.7171 - val_acc: 0.1853\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.2716 - acc: 0.2541 - val_loss: 2.6994 - val_acc: 0.1853\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.2651 - acc: 0.2512 - val_loss: 2.7067 - val_acc: 0.1789\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.2783 - acc: 0.2534 - val_loss: 2.7017 - val_acc: 0.1875\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.2830 - acc: 0.2576 - val_loss: 2.6735 - val_acc: 0.1918\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2757 - acc: 0.2470 - val_loss: 2.7247 - val_acc: 0.1832\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2696 - acc: 0.2612 - val_loss: 2.7293 - val_acc: 0.1832\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 80s 884ms/step - loss: 2.2973 - acc: 0.2335 - val_loss: 2.7301 - val_acc: 0.1918\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.2578 - acc: 0.2456 - val_loss: 2.7015 - val_acc: 0.1918\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2651 - acc: 0.2505 - val_loss: 2.7070 - val_acc: 0.1789\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 79s 870ms/step - loss: 2.2664 - acc: 0.2598 - val_loss: 2.6880 - val_acc: 0.1832\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2668 - acc: 0.2370 - val_loss: 2.7123 - val_acc: 0.1724\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2972 - acc: 0.2385 - val_loss: 2.7030 - val_acc: 0.1767\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.2761 - acc: 0.2470 - val_loss: 2.7175 - val_acc: 0.1789\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 77s 839ms/step - loss: 2.3001 - acc: 0.2449 - val_loss: 2.7210 - val_acc: 0.1810\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.2605 - acc: 0.2583 - val_loss: 2.7484 - val_acc: 0.1789\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2886 - acc: 0.2441 - val_loss: 2.7144 - val_acc: 0.1832\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.2778 - acc: 0.2619 - val_loss: 2.7211 - val_acc: 0.1767\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 80s 879ms/step - loss: 2.2450 - acc: 0.2548 - val_loss: 2.7044 - val_acc: 0.1767\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.2900 - acc: 0.2434 - val_loss: 2.6970 - val_acc: 0.1832\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 77s 871ms/step - loss: 2.2967 - acc: 0.2449 - val_loss: 2.7026 - val_acc: 0.1853\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2579 - acc: 0.2541 - val_loss: 2.7200 - val_acc: 0.1918\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.2424 - acc: 0.2647 - val_loss: 2.7137 - val_acc: 0.1810\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.2554 - acc: 0.2732 - val_loss: 2.7104 - val_acc: 0.1875\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.2613 - acc: 0.2576 - val_loss: 2.7014 - val_acc: 0.1875\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.2834 - acc: 0.2434 - val_loss: 2.7294 - val_acc: 0.1810\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 79s 874ms/step - loss: 2.2865 - acc: 0.2576 - val_loss: 2.7218 - val_acc: 0.1875\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 79s 862ms/step - loss: 2.2969 - acc: 0.2342 - val_loss: 2.7177 - val_acc: 0.1810\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 78s 858ms/step - loss: 2.2821 - acc: 0.2491 - val_loss: 2.7567 - val_acc: 0.1724\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2907 - acc: 0.2548 - val_loss: 2.7211 - val_acc: 0.1832\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 79s 872ms/step - loss: 2.2730 - acc: 0.2328 - val_loss: 2.7218 - val_acc: 0.1853\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 78s 850ms/step - loss: 2.2676 - acc: 0.2505 - val_loss: 2.7299 - val_acc: 0.1746\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.2371 - acc: 0.2505 - val_loss: 2.7118 - val_acc: 0.1853\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.3144 - acc: 0.2470 - val_loss: 2.7485 - val_acc: 0.1789\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 79s 846ms/step - loss: 2.2710 - acc: 0.2463 - val_loss: 2.7307 - val_acc: 0.1724\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.2230 - acc: 0.2775 - val_loss: 2.7243 - val_acc: 0.1789\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.2626 - acc: 0.2548 - val_loss: 2.7114 - val_acc: 0.1832\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 82s 903ms/step - loss: 2.3133 - acc: 0.2512 - val_loss: 2.7085 - val_acc: 0.1810\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2888 - acc: 0.2491 - val_loss: 2.7088 - val_acc: 0.1767\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 2.2862 - acc: 0.2576 - val_loss: 2.7305 - val_acc: 0.1897\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 78s 858ms/step - loss: 2.2915 - acc: 0.2470 - val_loss: 2.7215 - val_acc: 0.1832\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 80s 881ms/step - loss: 2.2633 - acc: 0.2463 - val_loss: 2.7418 - val_acc: 0.1832\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2761 - acc: 0.2477 - val_loss: 2.7330 - val_acc: 0.1853\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2693 - acc: 0.2583 - val_loss: 2.7417 - val_acc: 0.1810\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 81s 890ms/step - loss: 2.2557 - acc: 0.2505 - val_loss: 2.7392 - val_acc: 0.1746\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 80s 871ms/step - loss: 2.2376 - acc: 0.2633 - val_loss: 2.7441 - val_acc: 0.1789\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.2274 - acc: 0.2612 - val_loss: 2.7527 - val_acc: 0.1789\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2643 - acc: 0.2562 - val_loss: 2.7417 - val_acc: 0.1767\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 79s 861ms/step - loss: 2.2905 - acc: 0.2505 - val_loss: 2.7274 - val_acc: 0.1724\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kwylTJpTP5XI",
        "outputId": "9443e863-d40a-4180-a022-f004603a051e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD-vKaoHQAFd"
      },
      "source": [
        "#Download the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Female125_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qcPW-brHQDpc",
        "outputId": "c044c016-f7e8-42c4-b407-b61696eaf280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8874b3e7-5a42-4ddc-b883-2fe893d504a6\", \"33_\\u0e23\\u0e2d\\u0e1a\\u0e17\\u0e35\\u0e483_Flimpano_Female125_250.h5\", 16780032)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/My Drive/cut_panoramic/Model/33_รอบที่3_Flimpano_Female125_250.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}