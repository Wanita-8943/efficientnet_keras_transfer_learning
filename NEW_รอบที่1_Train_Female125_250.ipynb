{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/NEW_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%881_Train_Female125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "c90d2fd1-0436-4d12-fb44-ccb78e33ac47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Female_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "7383134e-e140-4fdf-e3f0-e2edebe3927a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07F         V1.jpg   \n",
              "1           2               1          7  Y07F    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         V2.jpg   \n",
              "3           4               2          7  Y07F    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         V3.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              65         25  Y25F  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-254ab3dc-62af-4822-b4ea-5fe1479c1f39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-254ab3dc-62af-4822-b4ea-5fe1479c1f39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-254ab3dc-62af-4822-b4ea-5fe1479c1f39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-254ab3dc-62af-4822-b4ea-5fe1479c1f39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "82c2e62f-e8d0-40eb-872a-22e917a23486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "uhCmH24AKmQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "IIWHby0gKpEq",
        "outputId": "a54a08ed-eaf7-4732-9f04-2217b4ac34db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 75, 75, 32)   864         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 75, 75, 32)  128         ['conv2d_130[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_98 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_32 (Depthwise  (None, 75, 75, 32)  288         ['swish_98[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_32[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_99 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_32 (Lambda)             (None, 1, 1, 32)     0           ['swish_99[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 1, 1, 8)      264         ['lambda_32[0][0]']              \n",
            "                                                                                                  \n",
            " swish_100 (Swish)              (None, 1, 1, 8)      0           ['conv2d_131[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 1, 1, 32)     288         ['swish_100[0][0]']              \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 1, 1, 32)     0           ['conv2d_132[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_32 (Multiply)         (None, 75, 75, 32)   0           ['activation_32[0][0]',          \n",
            "                                                                  'swish_99[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 75, 75, 16)   512         ['multiply_32[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 75, 75, 16)  64          ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 75, 75, 96)   1536        ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 75, 75, 96)  384         ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_101 (Swish)              (None, 75, 75, 96)   0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_33 (Depthwise  (None, 38, 38, 96)  864         ['swish_101[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 38, 38, 96)  384         ['depthwise_conv2d_33[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_102 (Swish)              (None, 38, 38, 96)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " lambda_33 (Lambda)             (None, 1, 1, 96)     0           ['swish_102[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 1, 1, 4)      388         ['lambda_33[0][0]']              \n",
            "                                                                                                  \n",
            " swish_103 (Swish)              (None, 1, 1, 4)      0           ['conv2d_135[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 1, 1, 96)     480         ['swish_103[0][0]']              \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 1, 1, 96)     0           ['conv2d_136[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_33 (Multiply)         (None, 38, 38, 96)   0           ['activation_33[0][0]',          \n",
            "                                                                  'swish_102[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 38, 38, 24)   2304        ['multiply_33[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 38, 38, 24)  96          ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 38, 38, 144)  3456        ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 38, 38, 144)  576        ['conv2d_138[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_104 (Swish)              (None, 38, 38, 144)  0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_34 (Depthwise  (None, 38, 38, 144)  1296       ['swish_104[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 38, 38, 144)  576        ['depthwise_conv2d_34[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_105 (Swish)              (None, 38, 38, 144)  0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " lambda_34 (Lambda)             (None, 1, 1, 144)    0           ['swish_105[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 1, 1, 6)      870         ['lambda_34[0][0]']              \n",
            "                                                                                                  \n",
            " swish_106 (Swish)              (None, 1, 1, 6)      0           ['conv2d_139[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 1, 1, 144)    1008        ['swish_106[0][0]']              \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 1, 1, 144)    0           ['conv2d_140[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_34 (Multiply)         (None, 38, 38, 144)  0           ['activation_34[0][0]',          \n",
            "                                                                  'swish_105[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 38, 38, 24)   3456        ['multiply_34[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 38, 38, 24)  96          ['conv2d_141[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_18 (DropConnect)  (None, 38, 38, 24)   0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 38, 38, 24)   0           ['drop_connect_18[0][0]',        \n",
            "                                                                  'batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 38, 38, 144)  3456        ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 38, 38, 144)  576        ['conv2d_142[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_107 (Swish)              (None, 38, 38, 144)  0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_35 (Depthwise  (None, 19, 19, 144)  3600       ['swish_107[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 19, 19, 144)  576        ['depthwise_conv2d_35[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_108 (Swish)              (None, 19, 19, 144)  0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " lambda_35 (Lambda)             (None, 1, 1, 144)    0           ['swish_108[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 1, 1, 6)      870         ['lambda_35[0][0]']              \n",
            "                                                                                                  \n",
            " swish_109 (Swish)              (None, 1, 1, 6)      0           ['conv2d_143[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 1, 1, 144)    1008        ['swish_109[0][0]']              \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 1, 1, 144)    0           ['conv2d_144[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_35 (Multiply)         (None, 19, 19, 144)  0           ['activation_35[0][0]',          \n",
            "                                                                  'swish_108[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 19, 19, 40)   5760        ['multiply_35[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 19, 19, 40)  160         ['conv2d_145[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 19, 19, 240)  9600        ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 19, 19, 240)  960        ['conv2d_146[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_110 (Swish)              (None, 19, 19, 240)  0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_36 (Depthwise  (None, 19, 19, 240)  6000       ['swish_110[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 19, 19, 240)  960        ['depthwise_conv2d_36[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_111 (Swish)              (None, 19, 19, 240)  0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " lambda_36 (Lambda)             (None, 1, 1, 240)    0           ['swish_111[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 1, 1, 10)     2410        ['lambda_36[0][0]']              \n",
            "                                                                                                  \n",
            " swish_112 (Swish)              (None, 1, 1, 10)     0           ['conv2d_147[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 1, 1, 240)    2640        ['swish_112[0][0]']              \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 1, 1, 240)    0           ['conv2d_148[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_36 (Multiply)         (None, 19, 19, 240)  0           ['activation_36[0][0]',          \n",
            "                                                                  'swish_111[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 19, 19, 40)   9600        ['multiply_36[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 19, 19, 40)  160         ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_19 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_19[0][0]',        \n",
            "                                                                  'batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 19, 19, 240)  9600        ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 19, 19, 240)  960        ['conv2d_150[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_113 (Swish)              (None, 19, 19, 240)  0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_37 (Depthwise  (None, 10, 10, 240)  2160       ['swish_113[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 10, 10, 240)  960        ['depthwise_conv2d_37[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_114 (Swish)              (None, 10, 10, 240)  0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " lambda_37 (Lambda)             (None, 1, 1, 240)    0           ['swish_114[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 1, 1, 10)     2410        ['lambda_37[0][0]']              \n",
            "                                                                                                  \n",
            " swish_115 (Swish)              (None, 1, 1, 10)     0           ['conv2d_151[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 1, 1, 240)    2640        ['swish_115[0][0]']              \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 1, 1, 240)    0           ['conv2d_152[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_37 (Multiply)         (None, 10, 10, 240)  0           ['activation_37[0][0]',          \n",
            "                                                                  'swish_114[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 10, 10, 80)   19200       ['multiply_37[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 10, 10, 80)  320         ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 10, 10, 480)  38400       ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 10, 10, 480)  1920       ['conv2d_154[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_116 (Swish)              (None, 10, 10, 480)  0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_38 (Depthwise  (None, 10, 10, 480)  4320       ['swish_116[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 10, 10, 480)  1920       ['depthwise_conv2d_38[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_117 (Swish)              (None, 10, 10, 480)  0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " lambda_38 (Lambda)             (None, 1, 1, 480)    0           ['swish_117[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 1, 1, 20)     9620        ['lambda_38[0][0]']              \n",
            "                                                                                                  \n",
            " swish_118 (Swish)              (None, 1, 1, 20)     0           ['conv2d_155[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 1, 1, 480)    10080       ['swish_118[0][0]']              \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 1, 1, 480)    0           ['conv2d_156[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_38 (Multiply)         (None, 10, 10, 480)  0           ['activation_38[0][0]',          \n",
            "                                                                  'swish_117[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 10, 10, 80)   38400       ['multiply_38[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 10, 10, 80)  320         ['conv2d_157[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_20 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_20[0][0]',        \n",
            "                                                                  'batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 10, 10, 480)  38400       ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 10, 10, 480)  1920       ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_119 (Swish)              (None, 10, 10, 480)  0           ['batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_39 (Depthwise  (None, 10, 10, 480)  4320       ['swish_119[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 10, 10, 480)  1920       ['depthwise_conv2d_39[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_120 (Swish)              (None, 10, 10, 480)  0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " lambda_39 (Lambda)             (None, 1, 1, 480)    0           ['swish_120[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 1, 1, 20)     9620        ['lambda_39[0][0]']              \n",
            "                                                                                                  \n",
            " swish_121 (Swish)              (None, 1, 1, 20)     0           ['conv2d_159[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 1, 1, 480)    10080       ['swish_121[0][0]']              \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 1, 1, 480)    0           ['conv2d_160[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_39 (Multiply)         (None, 10, 10, 480)  0           ['activation_39[0][0]',          \n",
            "                                                                  'swish_120[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 10, 10, 80)   38400       ['multiply_39[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 10, 10, 80)  320         ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_21 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_21[0][0]',        \n",
            "                                                                  'add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 10, 10, 480)  38400       ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 10, 10, 480)  1920       ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_122 (Swish)              (None, 10, 10, 480)  0           ['batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_40 (Depthwise  (None, 10, 10, 480)  12000      ['swish_122[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 10, 10, 480)  1920       ['depthwise_conv2d_40[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_123 (Swish)              (None, 10, 10, 480)  0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " lambda_40 (Lambda)             (None, 1, 1, 480)    0           ['swish_123[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 1, 1, 20)     9620        ['lambda_40[0][0]']              \n",
            "                                                                                                  \n",
            " swish_124 (Swish)              (None, 1, 1, 20)     0           ['conv2d_163[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 1, 1, 480)    10080       ['swish_124[0][0]']              \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 1, 1, 480)    0           ['conv2d_164[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_40 (Multiply)         (None, 10, 10, 480)  0           ['activation_40[0][0]',          \n",
            "                                                                  'swish_123[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_40[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 10, 10, 112)  448        ['conv2d_165[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 10, 10, 672)  2688       ['conv2d_166[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_125 (Swish)              (None, 10, 10, 672)  0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_41 (Depthwise  (None, 10, 10, 672)  16800      ['swish_125[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 10, 10, 672)  2688       ['depthwise_conv2d_41[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_126 (Swish)              (None, 10, 10, 672)  0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " lambda_41 (Lambda)             (None, 1, 1, 672)    0           ['swish_126[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_41[0][0]']              \n",
            "                                                                                                  \n",
            " swish_127 (Swish)              (None, 1, 1, 28)     0           ['conv2d_167[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_127[0][0]']              \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 1, 1, 672)    0           ['conv2d_168[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_41 (Multiply)         (None, 10, 10, 672)  0           ['activation_41[0][0]',          \n",
            "                                                                  'swish_126[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_41[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 10, 10, 112)  448        ['conv2d_169[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_22 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_22[0][0]',        \n",
            "                                                                  'batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 10, 10, 672)  75264       ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 10, 10, 672)  2688       ['conv2d_170[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_128 (Swish)              (None, 10, 10, 672)  0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_42 (Depthwise  (None, 10, 10, 672)  16800      ['swish_128[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 10, 10, 672)  2688       ['depthwise_conv2d_42[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_129 (Swish)              (None, 10, 10, 672)  0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " lambda_42 (Lambda)             (None, 1, 1, 672)    0           ['swish_129[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_42[0][0]']              \n",
            "                                                                                                  \n",
            " swish_130 (Swish)              (None, 1, 1, 28)     0           ['conv2d_171[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_130[0][0]']              \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 1, 1, 672)    0           ['conv2d_172[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_42 (Multiply)         (None, 10, 10, 672)  0           ['activation_42[0][0]',          \n",
            "                                                                  'swish_129[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_42[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 10, 10, 112)  448        ['conv2d_173[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_23 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_23[0][0]',        \n",
            "                                                                  'add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 10, 10, 672)  75264       ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 10, 10, 672)  2688       ['conv2d_174[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_131 (Swish)              (None, 10, 10, 672)  0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_43 (Depthwise  (None, 5, 5, 672)   16800       ['swish_131[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 5, 5, 672)   2688        ['depthwise_conv2d_43[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_132 (Swish)              (None, 5, 5, 672)    0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " lambda_43 (Lambda)             (None, 1, 1, 672)    0           ['swish_132[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_43[0][0]']              \n",
            "                                                                                                  \n",
            " swish_133 (Swish)              (None, 1, 1, 28)     0           ['conv2d_175[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_133[0][0]']              \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 1, 1, 672)    0           ['conv2d_176[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_43 (Multiply)         (None, 5, 5, 672)    0           ['activation_43[0][0]',          \n",
            "                                                                  'swish_132[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_43[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 5, 5, 192)   768         ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 5, 5, 1152)  4608        ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_134 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_44 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_134[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_44[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_135 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " lambda_44 (Lambda)             (None, 1, 1, 1152)   0           ['swish_135[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_44[0][0]']              \n",
            "                                                                                                  \n",
            " swish_136 (Swish)              (None, 1, 1, 48)     0           ['conv2d_179[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_136[0][0]']              \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_180[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_44 (Multiply)         (None, 5, 5, 1152)   0           ['activation_44[0][0]',          \n",
            "                                                                  'swish_135[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_44[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 5, 5, 192)   768         ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_24 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_24[0][0]',        \n",
            "                                                                  'batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 5, 5, 1152)  4608        ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_137 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_45 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_137[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_45[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_138 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " lambda_45 (Lambda)             (None, 1, 1, 1152)   0           ['swish_138[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_45[0][0]']              \n",
            "                                                                                                  \n",
            " swish_139 (Swish)              (None, 1, 1, 48)     0           ['conv2d_183[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_139[0][0]']              \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_184[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_45 (Multiply)         (None, 5, 5, 1152)   0           ['activation_45[0][0]',          \n",
            "                                                                  'swish_138[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_45[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 5, 5, 192)   768         ['conv2d_185[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_25 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_25[0][0]',        \n",
            "                                                                  'add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 5, 5, 1152)  4608        ['conv2d_186[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_140 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_46 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_140[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_46[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_141 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " lambda_46 (Lambda)             (None, 1, 1, 1152)   0           ['swish_141[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_46[0][0]']              \n",
            "                                                                                                  \n",
            " swish_142 (Swish)              (None, 1, 1, 48)     0           ['conv2d_187[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_188 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_142[0][0]']              \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_188[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_46 (Multiply)         (None, 5, 5, 1152)   0           ['activation_46[0][0]',          \n",
            "                                                                  'swish_141[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_189 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_46[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 5, 5, 192)   768         ['conv2d_189[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " drop_connect_26 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_26[0][0]',        \n",
            "                                                                  'add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_190 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 5, 5, 1152)  4608        ['conv2d_190[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_143 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " depthwise_conv2d_47 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_143[0][0]']              \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_47[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_144 (Swish)              (None, 5, 5, 1152)   0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " lambda_47 (Lambda)             (None, 1, 1, 1152)   0           ['swish_144[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_47[0][0]']              \n",
            "                                                                                                  \n",
            " swish_145 (Swish)              (None, 1, 1, 48)     0           ['conv2d_191[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_145[0][0]']              \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_192[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_47 (Multiply)         (None, 5, 5, 1152)   0           ['activation_47[0][0]',          \n",
            "                                                                  'swish_144[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_47[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 5, 5, 320)   1280        ['conv2d_193[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 5, 5, 1280)  5120        ['conv2d_194[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " swish_146 (Swish)              (None, 5, 5, 1280)   0           ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "861668d6-39f9-4287-c29a-3c4b3a92e5fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "146fda22-fe37-4a1c-cb6e-2d12c81712eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "52037f2b-9c32-45f4-fa0a-df77aae91fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "2b12437d-038d-4d3c-9179-8cd3285f24fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-45-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 83s 843ms/step - loss: 4.5077 - acc: 0.0504 - val_loss: 4.7665 - val_acc: 0.0453\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 4.2729 - acc: 0.0539 - val_loss: 4.4113 - val_acc: 0.0474\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 4.1707 - acc: 0.0646 - val_loss: 4.2622 - val_acc: 0.0474\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 4.1799 - acc: 0.0518 - val_loss: 4.1316 - val_acc: 0.0539\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 4.0516 - acc: 0.0525 - val_loss: 4.0646 - val_acc: 0.0517\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 4.0539 - acc: 0.0554 - val_loss: 3.9872 - val_acc: 0.0560\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 4.0718 - acc: 0.0532 - val_loss: 3.9545 - val_acc: 0.0582\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 79s 875ms/step - loss: 3.9265 - acc: 0.0625 - val_loss: 3.8867 - val_acc: 0.0582\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 3.9692 - acc: 0.0568 - val_loss: 3.8487 - val_acc: 0.0690\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 3.9315 - acc: 0.0617 - val_loss: 3.8045 - val_acc: 0.0733\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 3.8490 - acc: 0.0646 - val_loss: 3.7742 - val_acc: 0.0711\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 75s 801ms/step - loss: 3.8222 - acc: 0.0681 - val_loss: 3.7688 - val_acc: 0.0754\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 3.7909 - acc: 0.0752 - val_loss: 3.6994 - val_acc: 0.0819\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 3.7098 - acc: 0.0830 - val_loss: 3.6881 - val_acc: 0.0797\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.7459 - acc: 0.0802 - val_loss: 3.6538 - val_acc: 0.0884\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.7442 - acc: 0.0809 - val_loss: 3.5988 - val_acc: 0.0970\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 3.7233 - acc: 0.0809 - val_loss: 3.5986 - val_acc: 0.0948\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 3.6911 - acc: 0.0866 - val_loss: 3.5142 - val_acc: 0.0948\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 76s 827ms/step - loss: 3.7339 - acc: 0.0667 - val_loss: 3.4728 - val_acc: 0.1034\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.7103 - acc: 0.0795 - val_loss: 3.4818 - val_acc: 0.1013\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.6936 - acc: 0.0830 - val_loss: 3.4645 - val_acc: 0.1099\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 3.6566 - acc: 0.0738 - val_loss: 3.4347 - val_acc: 0.1078\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.5794 - acc: 0.0830 - val_loss: 3.3924 - val_acc: 0.1185\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 79s 870ms/step - loss: 3.6307 - acc: 0.0908 - val_loss: 3.3624 - val_acc: 0.1078\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 3.6217 - acc: 0.0880 - val_loss: 3.3554 - val_acc: 0.1099\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 79s 864ms/step - loss: 3.5498 - acc: 0.0894 - val_loss: 3.3180 - val_acc: 0.1164\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.5504 - acc: 0.0937 - val_loss: 3.2654 - val_acc: 0.1185\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 3.4725 - acc: 0.1050 - val_loss: 3.3048 - val_acc: 0.1121\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.5260 - acc: 0.1001 - val_loss: 3.2831 - val_acc: 0.1099\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.5167 - acc: 0.1001 - val_loss: 3.2227 - val_acc: 0.1121\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.4251 - acc: 0.1072 - val_loss: 3.2645 - val_acc: 0.1228\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.5398 - acc: 0.0965 - val_loss: 3.2185 - val_acc: 0.1228\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 78s 858ms/step - loss: 3.5435 - acc: 0.0908 - val_loss: 3.2136 - val_acc: 0.1250\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 3.4344 - acc: 0.1086 - val_loss: 3.1936 - val_acc: 0.1336\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 3.4159 - acc: 0.1114 - val_loss: 3.1898 - val_acc: 0.1250\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.4201 - acc: 0.0979 - val_loss: 3.1751 - val_acc: 0.1336\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 3.3760 - acc: 0.1100 - val_loss: 3.1243 - val_acc: 0.1401\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 77s 838ms/step - loss: 3.4135 - acc: 0.1143 - val_loss: 3.0922 - val_acc: 0.1379\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 76s 840ms/step - loss: 3.4229 - acc: 0.1043 - val_loss: 3.1105 - val_acc: 0.1315\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.4051 - acc: 0.1008 - val_loss: 3.0699 - val_acc: 0.1444\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 3.3447 - acc: 0.1235 - val_loss: 3.0769 - val_acc: 0.1379\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 3.3340 - acc: 0.1114 - val_loss: 3.0658 - val_acc: 0.1401\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 3.4346 - acc: 0.0951 - val_loss: 3.0724 - val_acc: 0.1379\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 3.4338 - acc: 0.0972 - val_loss: 3.0623 - val_acc: 0.1422\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 77s 830ms/step - loss: 3.3726 - acc: 0.1185 - val_loss: 3.0512 - val_acc: 0.1444\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.2980 - acc: 0.1199 - val_loss: 3.0259 - val_acc: 0.1422\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 3.3470 - acc: 0.1114 - val_loss: 3.0108 - val_acc: 0.1466\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 3.2938 - acc: 0.1235 - val_loss: 3.0153 - val_acc: 0.1487\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 3.2874 - acc: 0.1050 - val_loss: 3.0108 - val_acc: 0.1487\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.3498 - acc: 0.1043 - val_loss: 3.0352 - val_acc: 0.1336\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 3.3634 - acc: 0.1036 - val_loss: 2.9972 - val_acc: 0.1444\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.3002 - acc: 0.1143 - val_loss: 3.0097 - val_acc: 0.1466\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 3.2703 - acc: 0.1093 - val_loss: 3.0123 - val_acc: 0.1487\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 3.2368 - acc: 0.1313 - val_loss: 2.9897 - val_acc: 0.1530\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 3.2710 - acc: 0.1121 - val_loss: 2.9703 - val_acc: 0.1552\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 75s 817ms/step - loss: 3.2459 - acc: 0.1185 - val_loss: 2.9774 - val_acc: 0.1509\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 3.2966 - acc: 0.1093 - val_loss: 2.9505 - val_acc: 0.1552\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 3.1997 - acc: 0.1278 - val_loss: 2.9588 - val_acc: 0.1530\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 87s 955ms/step - loss: 3.2672 - acc: 0.1121 - val_loss: 2.9449 - val_acc: 0.1487\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 81s 889ms/step - loss: 3.2570 - acc: 0.1199 - val_loss: 2.9447 - val_acc: 0.1487\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 81s 888ms/step - loss: 3.2126 - acc: 0.1320 - val_loss: 2.9401 - val_acc: 0.1530\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 3.2581 - acc: 0.1235 - val_loss: 2.9513 - val_acc: 0.1530\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 3.1495 - acc: 0.1306 - val_loss: 2.9291 - val_acc: 0.1530\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.3076 - acc: 0.1107 - val_loss: 2.9411 - val_acc: 0.1552\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 3.2394 - acc: 0.1235 - val_loss: 2.9324 - val_acc: 0.1552\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 3.2467 - acc: 0.1178 - val_loss: 2.9390 - val_acc: 0.1638\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 3.1939 - acc: 0.1292 - val_loss: 2.9094 - val_acc: 0.1552\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.2073 - acc: 0.1348 - val_loss: 2.9061 - val_acc: 0.1573\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 3.1949 - acc: 0.1320 - val_loss: 2.9185 - val_acc: 0.1595\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 3.1869 - acc: 0.1334 - val_loss: 2.8913 - val_acc: 0.1573\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 3.2220 - acc: 0.1171 - val_loss: 2.8860 - val_acc: 0.1595\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 3.1529 - acc: 0.1348 - val_loss: 2.8938 - val_acc: 0.1616\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.1459 - acc: 0.1249 - val_loss: 2.8755 - val_acc: 0.1552\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.1488 - acc: 0.1320 - val_loss: 2.8805 - val_acc: 0.1659\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 3.1016 - acc: 0.1583 - val_loss: 2.8977 - val_acc: 0.1552\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 3.1483 - acc: 0.1299 - val_loss: 2.8816 - val_acc: 0.1681\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 3.0914 - acc: 0.1292 - val_loss: 2.8743 - val_acc: 0.1616\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.1493 - acc: 0.1207 - val_loss: 2.8557 - val_acc: 0.1616\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 3.1414 - acc: 0.1263 - val_loss: 2.8509 - val_acc: 0.1681\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 75s 806ms/step - loss: 3.0707 - acc: 0.1490 - val_loss: 2.8348 - val_acc: 0.1638\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 3.0600 - acc: 0.1341 - val_loss: 2.8369 - val_acc: 0.1573\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 3.1608 - acc: 0.1256 - val_loss: 2.8177 - val_acc: 0.1616\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 3.1090 - acc: 0.1320 - val_loss: 2.8618 - val_acc: 0.1573\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 3.1297 - acc: 0.1143 - val_loss: 2.8327 - val_acc: 0.1616\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 3.1106 - acc: 0.1348 - val_loss: 2.8251 - val_acc: 0.1767\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 3.1346 - acc: 0.1377 - val_loss: 2.8422 - val_acc: 0.1595\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.0765 - acc: 0.1214 - val_loss: 2.8369 - val_acc: 0.1703\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.0745 - acc: 0.1334 - val_loss: 2.8177 - val_acc: 0.1595\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 3.0867 - acc: 0.1391 - val_loss: 2.8217 - val_acc: 0.1595\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 3.0160 - acc: 0.1533 - val_loss: 2.8167 - val_acc: 0.1638\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 3.0557 - acc: 0.1419 - val_loss: 2.8261 - val_acc: 0.1573\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 76s 824ms/step - loss: 3.0633 - acc: 0.1391 - val_loss: 2.8043 - val_acc: 0.1638\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.0975 - acc: 0.1341 - val_loss: 2.8234 - val_acc: 0.1573\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 3.0617 - acc: 0.1377 - val_loss: 2.8185 - val_acc: 0.1638\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.0697 - acc: 0.1306 - val_loss: 2.8066 - val_acc: 0.1530\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 3.0558 - acc: 0.1398 - val_loss: 2.7900 - val_acc: 0.1573\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 3.0637 - acc: 0.1285 - val_loss: 2.8087 - val_acc: 0.1616\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.9992 - acc: 0.1512 - val_loss: 2.8076 - val_acc: 0.1573\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.0997 - acc: 0.1391 - val_loss: 2.7951 - val_acc: 0.1616\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 3.0434 - acc: 0.1377 - val_loss: 2.7963 - val_acc: 0.1595\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.9906 - acc: 0.1448 - val_loss: 2.7913 - val_acc: 0.1616\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 3.0157 - acc: 0.1341 - val_loss: 2.7804 - val_acc: 0.1616\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.9918 - acc: 0.1533 - val_loss: 2.7917 - val_acc: 0.1573\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0611 - acc: 0.1278 - val_loss: 2.7884 - val_acc: 0.1573\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0367 - acc: 0.1398 - val_loss: 2.7852 - val_acc: 0.1638\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 3.0034 - acc: 0.1384 - val_loss: 2.7779 - val_acc: 0.1616\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.0394 - acc: 0.1384 - val_loss: 2.7567 - val_acc: 0.1595\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.9549 - acc: 0.1476 - val_loss: 2.7677 - val_acc: 0.1638\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.9606 - acc: 0.1554 - val_loss: 2.7553 - val_acc: 0.1638\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.0386 - acc: 0.1412 - val_loss: 2.7742 - val_acc: 0.1638\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.0158 - acc: 0.1434 - val_loss: 2.7574 - val_acc: 0.1681\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 78s 838ms/step - loss: 3.0441 - acc: 0.1412 - val_loss: 2.7545 - val_acc: 0.1659\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.9970 - acc: 0.1533 - val_loss: 2.7942 - val_acc: 0.1616\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 3.0150 - acc: 0.1519 - val_loss: 2.7806 - val_acc: 0.1530\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.9420 - acc: 0.1576 - val_loss: 2.7617 - val_acc: 0.1659\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.8749 - acc: 0.1604 - val_loss: 2.7830 - val_acc: 0.1638\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 79s 867ms/step - loss: 2.9822 - acc: 0.1561 - val_loss: 2.7519 - val_acc: 0.1681\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.9380 - acc: 0.1469 - val_loss: 2.7500 - val_acc: 0.1616\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.9291 - acc: 0.1725 - val_loss: 2.7504 - val_acc: 0.1509\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 79s 865ms/step - loss: 2.9520 - acc: 0.1512 - val_loss: 2.7235 - val_acc: 0.1703\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 3.0029 - acc: 0.1285 - val_loss: 2.7449 - val_acc: 0.1616\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.9809 - acc: 0.1576 - val_loss: 2.7558 - val_acc: 0.1530\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.9623 - acc: 0.1512 - val_loss: 2.7615 - val_acc: 0.1659\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.9420 - acc: 0.1476 - val_loss: 2.7524 - val_acc: 0.1703\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 79s 872ms/step - loss: 2.9054 - acc: 0.1476 - val_loss: 2.7474 - val_acc: 0.1681\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.9175 - acc: 0.1540 - val_loss: 2.7364 - val_acc: 0.1724\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.8984 - acc: 0.1561 - val_loss: 2.7424 - val_acc: 0.1703\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 76s 840ms/step - loss: 2.9932 - acc: 0.1419 - val_loss: 2.7396 - val_acc: 0.1703\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.9788 - acc: 0.1561 - val_loss: 2.7330 - val_acc: 0.1638\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.9748 - acc: 0.1583 - val_loss: 2.7279 - val_acc: 0.1681\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.8844 - acc: 0.1594 - val_loss: 2.7470 - val_acc: 0.1616\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.9009 - acc: 0.1526 - val_loss: 2.7193 - val_acc: 0.1703\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.9268 - acc: 0.1710 - val_loss: 2.7246 - val_acc: 0.1616\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.8593 - acc: 0.1576 - val_loss: 2.7306 - val_acc: 0.1616\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.9202 - acc: 0.1576 - val_loss: 2.7477 - val_acc: 0.1638\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.8772 - acc: 0.1618 - val_loss: 2.7324 - val_acc: 0.1746\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.9015 - acc: 0.1590 - val_loss: 2.7348 - val_acc: 0.1703\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.9094 - acc: 0.1512 - val_loss: 2.7338 - val_acc: 0.1681\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 75s 806ms/step - loss: 2.9463 - acc: 0.1434 - val_loss: 2.7459 - val_acc: 0.1681\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.9010 - acc: 0.1597 - val_loss: 2.7498 - val_acc: 0.1573\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.8881 - acc: 0.1490 - val_loss: 2.7328 - val_acc: 0.1530\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.8869 - acc: 0.1561 - val_loss: 2.7513 - val_acc: 0.1659\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.8745 - acc: 0.1639 - val_loss: 2.7355 - val_acc: 0.1638\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.9150 - acc: 0.1540 - val_loss: 2.7312 - val_acc: 0.1659\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.8114 - acc: 0.1781 - val_loss: 2.7603 - val_acc: 0.1552\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.8941 - acc: 0.1604 - val_loss: 2.7422 - val_acc: 0.1616\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.8906 - acc: 0.1647 - val_loss: 2.7306 - val_acc: 0.1552\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.8303 - acc: 0.1604 - val_loss: 2.7380 - val_acc: 0.1595\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.8821 - acc: 0.1576 - val_loss: 2.7198 - val_acc: 0.1573\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.8551 - acc: 0.1682 - val_loss: 2.7341 - val_acc: 0.1509\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.9119 - acc: 0.1540 - val_loss: 2.7230 - val_acc: 0.1616\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.8564 - acc: 0.1696 - val_loss: 2.7482 - val_acc: 0.1573\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 2.8445 - acc: 0.1668 - val_loss: 2.7581 - val_acc: 0.1530\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 2.8197 - acc: 0.1639 - val_loss: 2.7429 - val_acc: 0.1552\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.9225 - acc: 0.1568 - val_loss: 2.7480 - val_acc: 0.1530\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.8708 - acc: 0.1512 - val_loss: 2.7384 - val_acc: 0.1573\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.9177 - acc: 0.1412 - val_loss: 2.7187 - val_acc: 0.1659\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.9159 - acc: 0.1597 - val_loss: 2.7493 - val_acc: 0.1659\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.8661 - acc: 0.1448 - val_loss: 2.7281 - val_acc: 0.1573\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.8660 - acc: 0.1661 - val_loss: 2.7607 - val_acc: 0.1509\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.8549 - acc: 0.1632 - val_loss: 2.7401 - val_acc: 0.1573\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 2.8708 - acc: 0.1668 - val_loss: 2.7566 - val_acc: 0.1552\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.8282 - acc: 0.1888 - val_loss: 2.7635 - val_acc: 0.1595\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 78s 859ms/step - loss: 2.8430 - acc: 0.1625 - val_loss: 2.7220 - val_acc: 0.1616\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.8915 - acc: 0.1597 - val_loss: 2.7295 - val_acc: 0.1638\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.8709 - acc: 0.1611 - val_loss: 2.7283 - val_acc: 0.1573\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.8649 - acc: 0.1689 - val_loss: 2.7245 - val_acc: 0.1638\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.8281 - acc: 0.1505 - val_loss: 2.7206 - val_acc: 0.1638\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 2.8373 - acc: 0.1505 - val_loss: 2.7053 - val_acc: 0.1703\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.8288 - acc: 0.1625 - val_loss: 2.7245 - val_acc: 0.1681\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.9453 - acc: 0.1490 - val_loss: 2.7382 - val_acc: 0.1659\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.8318 - acc: 0.1732 - val_loss: 2.7510 - val_acc: 0.1530\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.7942 - acc: 0.1647 - val_loss: 2.7451 - val_acc: 0.1552\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.8297 - acc: 0.1689 - val_loss: 2.7359 - val_acc: 0.1616\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.7681 - acc: 0.1952 - val_loss: 2.7317 - val_acc: 0.1638\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.7808 - acc: 0.1682 - val_loss: 2.7210 - val_acc: 0.1724\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.8452 - acc: 0.1590 - val_loss: 2.7392 - val_acc: 0.1638\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.7699 - acc: 0.1654 - val_loss: 2.7144 - val_acc: 0.1681\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 78s 862ms/step - loss: 2.8432 - acc: 0.1561 - val_loss: 2.7455 - val_acc: 0.1659\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.7838 - acc: 0.1632 - val_loss: 2.7274 - val_acc: 0.1595\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.7584 - acc: 0.1817 - val_loss: 2.7380 - val_acc: 0.1573\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.7962 - acc: 0.1760 - val_loss: 2.7123 - val_acc: 0.1659\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.7781 - acc: 0.1647 - val_loss: 2.7331 - val_acc: 0.1573\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.8248 - acc: 0.1547 - val_loss: 2.7509 - val_acc: 0.1724\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.7735 - acc: 0.1597 - val_loss: 2.7402 - val_acc: 0.1681\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 78s 858ms/step - loss: 2.8041 - acc: 0.1540 - val_loss: 2.7148 - val_acc: 0.1638\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.7714 - acc: 0.1781 - val_loss: 2.7114 - val_acc: 0.1659\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.7939 - acc: 0.1618 - val_loss: 2.7200 - val_acc: 0.1616\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 74s 831ms/step - loss: 2.7547 - acc: 0.1796 - val_loss: 2.7254 - val_acc: 0.1659\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.7532 - acc: 0.1767 - val_loss: 2.7294 - val_acc: 0.1746\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.8187 - acc: 0.1718 - val_loss: 2.7464 - val_acc: 0.1616\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.7583 - acc: 0.1725 - val_loss: 2.7122 - val_acc: 0.1703\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.8104 - acc: 0.1682 - val_loss: 2.7103 - val_acc: 0.1724\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.7826 - acc: 0.1675 - val_loss: 2.7012 - val_acc: 0.1789\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.7727 - acc: 0.1746 - val_loss: 2.7116 - val_acc: 0.1659\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.7115 - acc: 0.1845 - val_loss: 2.7077 - val_acc: 0.1681\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.7371 - acc: 0.1845 - val_loss: 2.7263 - val_acc: 0.1703\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.7666 - acc: 0.1682 - val_loss: 2.7092 - val_acc: 0.1724\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7802 - acc: 0.1753 - val_loss: 2.7016 - val_acc: 0.1703\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.7509 - acc: 0.1668 - val_loss: 2.7123 - val_acc: 0.1681\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.7312 - acc: 0.1742 - val_loss: 2.7312 - val_acc: 0.1724\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.7562 - acc: 0.1696 - val_loss: 2.7232 - val_acc: 0.1573\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 77s 816ms/step - loss: 2.8024 - acc: 0.1526 - val_loss: 2.7480 - val_acc: 0.1595\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.8219 - acc: 0.1725 - val_loss: 2.7110 - val_acc: 0.1638\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.7426 - acc: 0.1796 - val_loss: 2.6930 - val_acc: 0.1681\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.7118 - acc: 0.1774 - val_loss: 2.7150 - val_acc: 0.1767\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.7472 - acc: 0.1824 - val_loss: 2.6888 - val_acc: 0.1681\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.7568 - acc: 0.1618 - val_loss: 2.7034 - val_acc: 0.1659\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.7652 - acc: 0.1654 - val_loss: 2.7323 - val_acc: 0.1724\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.7276 - acc: 0.1774 - val_loss: 2.7121 - val_acc: 0.1746\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.7536 - acc: 0.1639 - val_loss: 2.7209 - val_acc: 0.1767\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.7163 - acc: 0.1781 - val_loss: 2.7241 - val_acc: 0.1767\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.7439 - acc: 0.1732 - val_loss: 2.7167 - val_acc: 0.1810\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 77s 840ms/step - loss: 2.7095 - acc: 0.1781 - val_loss: 2.7415 - val_acc: 0.1681\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.7376 - acc: 0.1810 - val_loss: 2.7356 - val_acc: 0.1659\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 2.7554 - acc: 0.1824 - val_loss: 2.7261 - val_acc: 0.1746\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.7098 - acc: 0.1710 - val_loss: 2.7211 - val_acc: 0.1703\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.7274 - acc: 0.1639 - val_loss: 2.7191 - val_acc: 0.1703\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.7330 - acc: 0.1661 - val_loss: 2.7235 - val_acc: 0.1724\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.7261 - acc: 0.1774 - val_loss: 2.7210 - val_acc: 0.1703\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 76s 839ms/step - loss: 2.6722 - acc: 0.1895 - val_loss: 2.7385 - val_acc: 0.1724\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.7060 - acc: 0.1916 - val_loss: 2.7301 - val_acc: 0.1638\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.7151 - acc: 0.1767 - val_loss: 2.7398 - val_acc: 0.1703\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.7438 - acc: 0.1923 - val_loss: 2.7338 - val_acc: 0.1703\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 2.7172 - acc: 0.1689 - val_loss: 2.7175 - val_acc: 0.1659\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.7663 - acc: 0.1682 - val_loss: 2.7242 - val_acc: 0.1638\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 2.6648 - acc: 0.1994 - val_loss: 2.7335 - val_acc: 0.1724\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 2.7219 - acc: 0.1675 - val_loss: 2.7265 - val_acc: 0.1746\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 77s 839ms/step - loss: 2.7556 - acc: 0.1682 - val_loss: 2.7079 - val_acc: 0.1724\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 2.6904 - acc: 0.1867 - val_loss: 2.7140 - val_acc: 0.1724\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.7078 - acc: 0.1916 - val_loss: 2.7133 - val_acc: 0.1767\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 2.7530 - acc: 0.1682 - val_loss: 2.6948 - val_acc: 0.1789\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.6616 - acc: 0.1689 - val_loss: 2.6763 - val_acc: 0.1724\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.7004 - acc: 0.1781 - val_loss: 2.6944 - val_acc: 0.1810\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 73s 794ms/step - loss: 2.6976 - acc: 0.1945 - val_loss: 2.6956 - val_acc: 0.1746\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.7225 - acc: 0.1767 - val_loss: 2.6871 - val_acc: 0.1789\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6520 - acc: 0.1803 - val_loss: 2.7072 - val_acc: 0.1724\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.6772 - acc: 0.1895 - val_loss: 2.7094 - val_acc: 0.1767\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 77s 847ms/step - loss: 2.6932 - acc: 0.1859 - val_loss: 2.7062 - val_acc: 0.1767\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.6341 - acc: 0.1994 - val_loss: 2.6991 - val_acc: 0.1767\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.6432 - acc: 0.1824 - val_loss: 2.7158 - val_acc: 0.1746\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.6822 - acc: 0.1852 - val_loss: 2.7033 - val_acc: 0.1703\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.6935 - acc: 0.1703 - val_loss: 2.7170 - val_acc: 0.1703\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.6543 - acc: 0.1923 - val_loss: 2.7124 - val_acc: 0.1746\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.6921 - acc: 0.1852 - val_loss: 2.7250 - val_acc: 0.1616\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 2.6900 - acc: 0.1689 - val_loss: 2.7372 - val_acc: 0.1595\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 78s 850ms/step - loss: 2.6510 - acc: 0.1938 - val_loss: 2.7343 - val_acc: 0.1681\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 74s 831ms/step - loss: 2.6228 - acc: 0.2023 - val_loss: 2.7197 - val_acc: 0.1659\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.6253 - acc: 0.1952 - val_loss: 2.7102 - val_acc: 0.1659\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.7009 - acc: 0.1817 - val_loss: 2.7319 - val_acc: 0.1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e0da4ae4-657f-4a53-a8a9-506bfa380646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}