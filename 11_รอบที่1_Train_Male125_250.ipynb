{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/11_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%881_Train_Male125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "6d75a342-c46f-43ad-abda-b1fce67f00cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Male_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "f7b53e88-d76d-48d9-a190-88996c8e7b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07M       VV03.jpg   \n",
              "1           2               1          7  Y07M  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M       VV04.jpg   \n",
              "3           4               2          7  Y07M  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M       VV05.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              77         25  Y25M  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M       J464.jpg   \n",
              "2372      123              78         25  Y25M  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M       J465.jpg   \n",
              "2374      125              79         25  Y25M  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4781ca69-a3d7-4bd4-a735-bbf29491ac12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4781ca69-a3d7-4bd4-a735-bbf29491ac12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4781ca69-a3d7-4bd4-a735-bbf29491ac12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4781ca69-a3d7-4bd4-a735-bbf29491ac12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 473\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "abc1a5d8-0b80-414d-e914-349a83ffb98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "4fd62390-0297-4b1c-9f12-6ff02a2f3db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 75, 75, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 75, 75, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 75, 75, 32)  288         ['swish_49[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 32)     0           ['swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 1, 1, 8)      264         ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 1, 1, 8)      0           ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 32)     288         ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 32)     0           ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 75, 75, 32)   0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 75, 75, 16)   512         ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 75, 75, 16)  64          ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 75, 75, 96)   1536        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 75, 75, 96)  384         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 75, 75, 96)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 38, 38, 96)  864         ['swish_52[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 38, 38, 96)  384         ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 38, 38, 96)   0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 96)     0           ['swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 1, 1, 4)      388         ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 1, 1, 4)      0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 96)     480         ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 96)     0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 38, 38, 96)   0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 38, 38, 24)   2304        ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 38, 38, 24)  96          ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 38, 38, 144)  3456        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 38, 38, 144)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 38, 38, 144)  1296       ['swish_55[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 38, 38, 144)  576        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 144)    0           ['swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 1, 1, 6)      0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 144)    0           ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 38, 38, 144)  0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 38, 38, 24)  96          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 38, 38, 24)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 38, 38, 24)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 38, 38, 144)  3456        ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 38, 38, 144)  576        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 19, 19, 144)  3600       ['swish_58[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 144)    0           ['swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 1, 1, 6)      0           ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 144)    0           ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 19, 19, 144)  0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 19, 19, 40)  160         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 19, 19, 240)  960        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 19, 19, 240)  6000       ['swish_61[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 240)    0           ['swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 1, 1, 10)     0           ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 240)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 19, 19, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 19, 19, 40)  160         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 19, 19, 240)  9600        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 19, 19, 240)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 10, 10, 240)  2160       ['swish_64[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 240)    0           ['swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 1, 1, 10)     0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 240)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 10, 10, 240)  0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 10, 10, 80)  320         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 10, 10, 480)  4320       ['swish_67[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 480)    0           ['swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 1, 1, 20)     0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 480)    0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 10, 10, 480)  0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 10, 10, 80)  320         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 10, 10, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 10, 10, 480)  4320       ['swish_70[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 480)    0           ['swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 1, 1, 20)     0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 480)    0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 10, 10, 480)  0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 10, 10, 80)  320         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 10, 10, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 10, 10, 480)  12000      ['swish_73[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 480)    0           ['swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 1, 1, 20)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 480)    0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 10, 10, 480)  0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 10, 10, 112)  448        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 10, 10, 672)  16800      ['swish_76[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 672)    0           ['swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_78 (Swish)               (None, 1, 1, 28)     0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_78[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 10, 10, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 10, 10, 112)  448        ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 10, 10, 672)  75264       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_79 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 10, 10, 672)  16800      ['swish_79[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_80 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_26 (Lambda)             (None, 1, 1, 672)    0           ['swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_26[0][0]']              \n",
            "                                                                                                  \n",
            " swish_81 (Swish)               (None, 1, 1, 28)     0           ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_81[0][0]']               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 10, 10, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 10, 10, 112)  448        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 10, 10, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_82 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 5, 5, 672)   16800       ['swish_82[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_83 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1, 1, 672)    0           ['swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            " swish_84 (Swish)               (None, 1, 1, 28)     0           ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_84[0][0]']               \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 5, 5, 672)    0           ['activation_27[0][0]',          \n",
            "                                                                  'swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   768         ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_85 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_85[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_86 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1, 1, 1152)   0           ['swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            " swish_87 (Swish)               (None, 1, 1, 48)     0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_87[0][0]']               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 5, 5, 1152)   0           ['activation_28[0][0]',          \n",
            "                                                                  'swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   768         ['conv2d_116[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_88 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_88[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_89 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_29 (Lambda)             (None, 1, 1, 1152)   0           ['swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_29[0][0]']              \n",
            "                                                                                                  \n",
            " swish_90 (Swish)               (None, 1, 1, 48)     0           ['conv2d_118[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_90[0][0]']               \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 5, 5, 1152)   0           ['activation_29[0][0]',          \n",
            "                                                                  'swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 192)   768         ['conv2d_120[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_91 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_91[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_92 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_30 (Lambda)             (None, 1, 1, 1152)   0           ['swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_30[0][0]']              \n",
            "                                                                                                  \n",
            " swish_93 (Swish)               (None, 1, 1, 48)     0           ['conv2d_122[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_93[0][0]']               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_123[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 5, 5, 1152)   0           ['activation_30[0][0]',          \n",
            "                                                                  'swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   768         ['conv2d_124[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_94 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_94[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_95 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_31 (Lambda)             (None, 1, 1, 1152)   0           ['swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_31[0][0]']              \n",
            "                                                                                                  \n",
            " swish_96 (Swish)               (None, 1, 1, 48)     0           ['conv2d_126[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_96[0][0]']               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_127[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 5, 5, 1152)   0           ['activation_31[0][0]',          \n",
            "                                                                  'swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_128[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_97 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "3d9344ec-975c-4975-9ea8-85343c22f29a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 473 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "42a15d68-cde9-45b9-af57-22686420e68b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "4639ff59-4de6-47bf-b858-7903655703fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "35c47409-e056-4115-afa6-8156d2d07216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-36-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 70s 671ms/step - loss: 4.6588 - acc: 0.0504 - val_loss: 4.2420 - val_acc: 0.0323\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 4.2791 - acc: 0.0561 - val_loss: 3.9680 - val_acc: 0.0237\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 56s 613ms/step - loss: 4.1340 - acc: 0.0767 - val_loss: 3.8422 - val_acc: 0.0237\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 58s 628ms/step - loss: 4.1007 - acc: 0.0546 - val_loss: 3.7836 - val_acc: 0.0302\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 57s 627ms/step - loss: 4.0148 - acc: 0.0681 - val_loss: 3.7534 - val_acc: 0.0323\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 57s 622ms/step - loss: 3.9525 - acc: 0.0696 - val_loss: 3.7050 - val_acc: 0.0366\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 61s 667ms/step - loss: 3.9874 - acc: 0.0476 - val_loss: 3.6872 - val_acc: 0.0345\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 3.9228 - acc: 0.0681 - val_loss: 3.6493 - val_acc: 0.0431\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 62s 681ms/step - loss: 3.8828 - acc: 0.0724 - val_loss: 3.5843 - val_acc: 0.0453\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 57s 625ms/step - loss: 3.7850 - acc: 0.0653 - val_loss: 3.5550 - val_acc: 0.0474\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 58s 642ms/step - loss: 3.8716 - acc: 0.0610 - val_loss: 3.5104 - val_acc: 0.0496\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 60s 655ms/step - loss: 3.8396 - acc: 0.0674 - val_loss: 3.5003 - val_acc: 0.0409\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 60s 661ms/step - loss: 3.7601 - acc: 0.0816 - val_loss: 3.4609 - val_acc: 0.0517\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 58s 635ms/step - loss: 3.7196 - acc: 0.0759 - val_loss: 3.4341 - val_acc: 0.0474\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 58s 631ms/step - loss: 3.7330 - acc: 0.0788 - val_loss: 3.4058 - val_acc: 0.0560\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 59s 647ms/step - loss: 3.7724 - acc: 0.0724 - val_loss: 3.3888 - val_acc: 0.0582\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 3.6580 - acc: 0.0816 - val_loss: 3.3813 - val_acc: 0.0539\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 59s 646ms/step - loss: 3.6793 - acc: 0.0703 - val_loss: 3.3341 - val_acc: 0.0539\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 56s 614ms/step - loss: 3.6441 - acc: 0.0724 - val_loss: 3.3104 - val_acc: 0.0668\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 57s 631ms/step - loss: 3.6587 - acc: 0.0823 - val_loss: 3.3122 - val_acc: 0.0625\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 56s 614ms/step - loss: 3.5675 - acc: 0.0859 - val_loss: 3.2815 - val_acc: 0.0668\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 59s 649ms/step - loss: 3.5876 - acc: 0.0781 - val_loss: 3.2817 - val_acc: 0.0754\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 58s 651ms/step - loss: 3.5315 - acc: 0.0901 - val_loss: 3.2534 - val_acc: 0.0797\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 59s 652ms/step - loss: 3.5394 - acc: 0.0859 - val_loss: 3.2354 - val_acc: 0.0797\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 59s 650ms/step - loss: 3.5399 - acc: 0.0887 - val_loss: 3.2215 - val_acc: 0.0733\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 57s 625ms/step - loss: 3.5457 - acc: 0.0894 - val_loss: 3.2051 - val_acc: 0.0797\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 59s 651ms/step - loss: 3.5992 - acc: 0.0845 - val_loss: 3.2100 - val_acc: 0.0819\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 58s 630ms/step - loss: 3.4972 - acc: 0.0930 - val_loss: 3.1704 - val_acc: 0.0905\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 60s 663ms/step - loss: 3.4454 - acc: 0.1086 - val_loss: 3.1508 - val_acc: 0.0970\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 59s 643ms/step - loss: 3.4882 - acc: 0.0923 - val_loss: 3.1249 - val_acc: 0.0970\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 59s 649ms/step - loss: 3.4563 - acc: 0.0994 - val_loss: 3.1270 - val_acc: 0.0927\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 59s 651ms/step - loss: 3.4746 - acc: 0.0951 - val_loss: 3.1342 - val_acc: 0.1013\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 62s 686ms/step - loss: 3.4038 - acc: 0.1029 - val_loss: 3.1088 - val_acc: 0.1034\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 60s 655ms/step - loss: 3.4487 - acc: 0.1029 - val_loss: 3.0932 - val_acc: 0.1056\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 3.4326 - acc: 0.1072 - val_loss: 3.0719 - val_acc: 0.1099\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 58s 641ms/step - loss: 3.3981 - acc: 0.0916 - val_loss: 3.0613 - val_acc: 0.1078\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 58s 641ms/step - loss: 3.4452 - acc: 0.0979 - val_loss: 3.0565 - val_acc: 0.1099\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 58s 635ms/step - loss: 3.3742 - acc: 0.1029 - val_loss: 3.0340 - val_acc: 0.1121\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 56s 620ms/step - loss: 3.4137 - acc: 0.1036 - val_loss: 3.0261 - val_acc: 0.1121\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 61s 671ms/step - loss: 3.3585 - acc: 0.1157 - val_loss: 3.0207 - val_acc: 0.1121\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 58s 632ms/step - loss: 3.3671 - acc: 0.1043 - val_loss: 3.0185 - val_acc: 0.1142\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 3.3301 - acc: 0.0901 - val_loss: 3.0181 - val_acc: 0.1099\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 56s 617ms/step - loss: 3.3713 - acc: 0.1043 - val_loss: 3.0078 - val_acc: 0.1228\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 58s 638ms/step - loss: 3.2850 - acc: 0.1036 - val_loss: 2.9831 - val_acc: 0.1250\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 58s 638ms/step - loss: 3.2862 - acc: 0.1079 - val_loss: 2.9728 - val_acc: 0.1207\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 60s 655ms/step - loss: 3.3557 - acc: 0.1072 - val_loss: 2.9736 - val_acc: 0.1228\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 62s 679ms/step - loss: 3.3398 - acc: 0.1072 - val_loss: 2.9641 - val_acc: 0.1336\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 66s 719ms/step - loss: 3.2737 - acc: 0.0979 - val_loss: 2.9676 - val_acc: 0.1293\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 66s 722ms/step - loss: 3.2750 - acc: 0.0880 - val_loss: 2.9524 - val_acc: 0.1336\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 61s 671ms/step - loss: 3.2719 - acc: 0.1107 - val_loss: 2.9490 - val_acc: 0.1315\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 61s 673ms/step - loss: 3.3137 - acc: 0.1065 - val_loss: 2.9448 - val_acc: 0.1293\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 60s 660ms/step - loss: 3.2904 - acc: 0.1093 - val_loss: 2.9358 - val_acc: 0.1401\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 61s 671ms/step - loss: 3.2187 - acc: 0.1221 - val_loss: 2.9255 - val_acc: 0.1358\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 59s 639ms/step - loss: 3.1771 - acc: 0.1207 - val_loss: 2.9234 - val_acc: 0.1401\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 60s 664ms/step - loss: 3.2090 - acc: 0.1171 - val_loss: 2.9072 - val_acc: 0.1466\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 61s 671ms/step - loss: 3.2393 - acc: 0.1029 - val_loss: 2.9063 - val_acc: 0.1444\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 59s 648ms/step - loss: 3.2295 - acc: 0.1114 - val_loss: 2.9102 - val_acc: 0.1422\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 61s 673ms/step - loss: 3.3009 - acc: 0.1166 - val_loss: 2.8945 - val_acc: 0.1358\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 58s 636ms/step - loss: 3.1886 - acc: 0.1086 - val_loss: 2.8844 - val_acc: 0.1358\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 63s 691ms/step - loss: 3.1049 - acc: 0.1207 - val_loss: 2.8950 - val_acc: 0.1401\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 57s 624ms/step - loss: 3.2993 - acc: 0.1057 - val_loss: 2.9022 - val_acc: 0.1293\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 61s 666ms/step - loss: 3.2140 - acc: 0.1242 - val_loss: 2.8605 - val_acc: 0.1379\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 58s 636ms/step - loss: 3.1564 - acc: 0.1171 - val_loss: 2.8476 - val_acc: 0.1401\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 61s 676ms/step - loss: 3.0849 - acc: 0.1178 - val_loss: 2.8712 - val_acc: 0.1315\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 58s 636ms/step - loss: 3.1211 - acc: 0.1278 - val_loss: 2.8634 - val_acc: 0.1358\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 62s 679ms/step - loss: 3.1527 - acc: 0.1249 - val_loss: 2.8714 - val_acc: 0.1358\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 61s 653ms/step - loss: 3.1306 - acc: 0.1370 - val_loss: 2.8454 - val_acc: 0.1422\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 60s 658ms/step - loss: 3.1493 - acc: 0.1136 - val_loss: 2.8155 - val_acc: 0.1509\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 60s 655ms/step - loss: 3.1169 - acc: 0.1313 - val_loss: 2.8266 - val_acc: 0.1444\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 59s 645ms/step - loss: 3.1297 - acc: 0.1143 - val_loss: 2.7998 - val_acc: 0.1530\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 65s 730ms/step - loss: 3.1218 - acc: 0.1327 - val_loss: 2.8165 - val_acc: 0.1509\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 59s 649ms/step - loss: 3.1698 - acc: 0.1221 - val_loss: 2.8208 - val_acc: 0.1530\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 62s 684ms/step - loss: 3.1336 - acc: 0.1263 - val_loss: 2.8258 - val_acc: 0.1466\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 57s 627ms/step - loss: 3.1214 - acc: 0.1384 - val_loss: 2.8110 - val_acc: 0.1422\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 61s 666ms/step - loss: 3.0980 - acc: 0.1214 - val_loss: 2.8120 - val_acc: 0.1422\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 57s 627ms/step - loss: 3.1977 - acc: 0.1256 - val_loss: 2.8049 - val_acc: 0.1552\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 60s 663ms/step - loss: 3.1169 - acc: 0.1256 - val_loss: 2.8118 - val_acc: 0.1487\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 60s 656ms/step - loss: 3.1206 - acc: 0.1136 - val_loss: 2.8000 - val_acc: 0.1487\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 61s 669ms/step - loss: 3.1077 - acc: 0.1334 - val_loss: 2.7764 - val_acc: 0.1487\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 66s 725ms/step - loss: 3.0181 - acc: 0.1256 - val_loss: 2.7905 - val_acc: 0.1466\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 64s 701ms/step - loss: 3.1270 - acc: 0.1199 - val_loss: 2.7899 - val_acc: 0.1530\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 66s 728ms/step - loss: 3.0785 - acc: 0.1285 - val_loss: 2.7877 - val_acc: 0.1487\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 63s 690ms/step - loss: 3.1004 - acc: 0.1278 - val_loss: 2.7830 - val_acc: 0.1573\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 66s 723ms/step - loss: 3.0789 - acc: 0.1299 - val_loss: 2.7702 - val_acc: 0.1552\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 59s 647ms/step - loss: 3.0405 - acc: 0.1278 - val_loss: 2.7752 - val_acc: 0.1487\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 61s 689ms/step - loss: 3.0222 - acc: 0.1405 - val_loss: 2.7785 - val_acc: 0.1509\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 61s 666ms/step - loss: 3.0241 - acc: 0.1228 - val_loss: 2.7725 - val_acc: 0.1530\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 66s 722ms/step - loss: 3.0556 - acc: 0.1185 - val_loss: 2.7772 - val_acc: 0.1509\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 59s 645ms/step - loss: 3.0606 - acc: 0.1526 - val_loss: 2.7785 - val_acc: 0.1466\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 60s 664ms/step - loss: 3.0150 - acc: 0.1299 - val_loss: 2.7737 - val_acc: 0.1466\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 58s 640ms/step - loss: 3.0199 - acc: 0.1348 - val_loss: 2.7799 - val_acc: 0.1530\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 61s 668ms/step - loss: 3.0402 - acc: 0.1377 - val_loss: 2.7674 - val_acc: 0.1444\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 57s 624ms/step - loss: 3.0297 - acc: 0.1412 - val_loss: 2.7845 - val_acc: 0.1444\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 61s 666ms/step - loss: 3.0776 - acc: 0.1306 - val_loss: 2.7818 - val_acc: 0.1422\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 62s 684ms/step - loss: 3.0709 - acc: 0.1249 - val_loss: 2.7463 - val_acc: 0.1595\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 63s 697ms/step - loss: 3.0463 - acc: 0.1263 - val_loss: 2.7430 - val_acc: 0.1573\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 60s 654ms/step - loss: 3.0537 - acc: 0.1505 - val_loss: 2.7483 - val_acc: 0.1552\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 62s 686ms/step - loss: 3.0468 - acc: 0.1320 - val_loss: 2.7342 - val_acc: 0.1573\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 3.0223 - acc: 0.1214 - val_loss: 2.7391 - val_acc: 0.1681\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 60s 654ms/step - loss: 2.9464 - acc: 0.1419 - val_loss: 2.7238 - val_acc: 0.1659\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 63s 680ms/step - loss: 3.0311 - acc: 0.1363 - val_loss: 2.7585 - val_acc: 0.1638\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 58s 639ms/step - loss: 2.9644 - acc: 0.1242 - val_loss: 2.7444 - val_acc: 0.1573\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 63s 688ms/step - loss: 3.0161 - acc: 0.1363 - val_loss: 2.7533 - val_acc: 0.1509\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 56s 619ms/step - loss: 2.9886 - acc: 0.1278 - val_loss: 2.7365 - val_acc: 0.1595\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 57s 630ms/step - loss: 2.9628 - acc: 0.1292 - val_loss: 2.7387 - val_acc: 0.1595\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 62s 676ms/step - loss: 2.9824 - acc: 0.1561 - val_loss: 2.7417 - val_acc: 0.1595\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 60s 657ms/step - loss: 2.9126 - acc: 0.1476 - val_loss: 2.7240 - val_acc: 0.1595\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 2.9217 - acc: 0.1519 - val_loss: 2.7314 - val_acc: 0.1552\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 58s 638ms/step - loss: 2.9408 - acc: 0.1483 - val_loss: 2.7255 - val_acc: 0.1703\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 59s 646ms/step - loss: 2.9890 - acc: 0.1363 - val_loss: 2.7003 - val_acc: 0.1724\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 59s 651ms/step - loss: 2.9449 - acc: 0.1270 - val_loss: 2.7167 - val_acc: 0.1616\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 62s 684ms/step - loss: 2.9653 - acc: 0.1519 - val_loss: 2.7231 - val_acc: 0.1638\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 59s 648ms/step - loss: 2.9343 - acc: 0.1498 - val_loss: 2.7157 - val_acc: 0.1595\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 59s 650ms/step - loss: 2.8870 - acc: 0.1654 - val_loss: 2.7359 - val_acc: 0.1638\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 63s 689ms/step - loss: 2.9837 - acc: 0.1214 - val_loss: 2.7142 - val_acc: 0.1616\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 60s 658ms/step - loss: 2.9221 - acc: 0.1270 - val_loss: 2.7133 - val_acc: 0.1552\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 59s 647ms/step - loss: 2.9090 - acc: 0.1462 - val_loss: 2.6945 - val_acc: 0.1595\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 2.9220 - acc: 0.1377 - val_loss: 2.7153 - val_acc: 0.1466\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 62s 673ms/step - loss: 3.0085 - acc: 0.1419 - val_loss: 2.7117 - val_acc: 0.1530\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 66s 732ms/step - loss: 2.9172 - acc: 0.1434 - val_loss: 2.6931 - val_acc: 0.1595\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 60s 654ms/step - loss: 2.9751 - acc: 0.1370 - val_loss: 2.7002 - val_acc: 0.1573\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 58s 640ms/step - loss: 2.8494 - acc: 0.1654 - val_loss: 2.7165 - val_acc: 0.1573\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 63s 700ms/step - loss: 2.9119 - acc: 0.1469 - val_loss: 2.7041 - val_acc: 0.1616\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 60s 655ms/step - loss: 2.9348 - acc: 0.1469 - val_loss: 2.6879 - val_acc: 0.1573\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 60s 656ms/step - loss: 2.9061 - acc: 0.1483 - val_loss: 2.6935 - val_acc: 0.1552\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 59s 650ms/step - loss: 2.8576 - acc: 0.1618 - val_loss: 2.6869 - val_acc: 0.1552\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 67s 739ms/step - loss: 2.8797 - acc: 0.1533 - val_loss: 2.6833 - val_acc: 0.1573\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 60s 658ms/step - loss: 2.9368 - acc: 0.1356 - val_loss: 2.6712 - val_acc: 0.1552\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 2.8738 - acc: 0.1519 - val_loss: 2.6992 - val_acc: 0.1530\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 63s 688ms/step - loss: 2.8645 - acc: 0.1391 - val_loss: 2.6914 - val_acc: 0.1681\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 57s 623ms/step - loss: 2.9350 - acc: 0.1427 - val_loss: 2.6951 - val_acc: 0.1573\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 2.8801 - acc: 0.1540 - val_loss: 2.6717 - val_acc: 0.1595\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 62s 683ms/step - loss: 2.8933 - acc: 0.1505 - val_loss: 2.6990 - val_acc: 0.1595\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 57s 623ms/step - loss: 2.8856 - acc: 0.1519 - val_loss: 2.6910 - val_acc: 0.1616\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 58s 638ms/step - loss: 2.8026 - acc: 0.1632 - val_loss: 2.6913 - val_acc: 0.1595\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 64s 701ms/step - loss: 2.8499 - acc: 0.1524 - val_loss: 2.6849 - val_acc: 0.1552\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 58s 640ms/step - loss: 2.9082 - acc: 0.1519 - val_loss: 2.6923 - val_acc: 0.1509\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 57s 622ms/step - loss: 2.8194 - acc: 0.1689 - val_loss: 2.6818 - val_acc: 0.1573\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 58s 636ms/step - loss: 2.9081 - acc: 0.1455 - val_loss: 2.6684 - val_acc: 0.1595\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 2.8329 - acc: 0.1576 - val_loss: 2.6913 - val_acc: 0.1595\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 62s 682ms/step - loss: 2.8324 - acc: 0.1540 - val_loss: 2.7029 - val_acc: 0.1530\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 59s 645ms/step - loss: 2.8738 - acc: 0.1476 - val_loss: 2.6818 - val_acc: 0.1530\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 62s 678ms/step - loss: 2.8664 - acc: 0.1434 - val_loss: 2.6876 - val_acc: 0.1530\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 61s 676ms/step - loss: 2.8819 - acc: 0.1682 - val_loss: 2.6906 - val_acc: 0.1530\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 58s 635ms/step - loss: 2.9117 - acc: 0.1576 - val_loss: 2.6615 - val_acc: 0.1530\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 58s 640ms/step - loss: 2.8582 - acc: 0.1412 - val_loss: 2.6661 - val_acc: 0.1573\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 59s 639ms/step - loss: 2.8596 - acc: 0.1583 - val_loss: 2.6687 - val_acc: 0.1703\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 57s 623ms/step - loss: 2.7997 - acc: 0.1526 - val_loss: 2.6818 - val_acc: 0.1530\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 60s 657ms/step - loss: 2.8481 - acc: 0.1412 - val_loss: 2.6830 - val_acc: 0.1595\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 57s 622ms/step - loss: 2.8516 - acc: 0.1448 - val_loss: 2.6742 - val_acc: 0.1552\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 58s 633ms/step - loss: 2.8494 - acc: 0.1441 - val_loss: 2.6573 - val_acc: 0.1552\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 59s 645ms/step - loss: 2.8416 - acc: 0.1313 - val_loss: 2.6589 - val_acc: 0.1573\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 55s 601ms/step - loss: 2.8380 - acc: 0.1590 - val_loss: 2.6406 - val_acc: 0.1595\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 55s 608ms/step - loss: 2.7911 - acc: 0.1647 - val_loss: 2.6635 - val_acc: 0.1595\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 61s 673ms/step - loss: 2.8045 - acc: 0.1483 - val_loss: 2.6515 - val_acc: 0.1638\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 56s 615ms/step - loss: 2.7912 - acc: 0.1490 - val_loss: 2.6652 - val_acc: 0.1616\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 56s 610ms/step - loss: 2.8431 - acc: 0.1576 - val_loss: 2.6392 - val_acc: 0.1703\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 61s 671ms/step - loss: 2.8261 - acc: 0.1505 - val_loss: 2.6516 - val_acc: 0.1638\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 57s 629ms/step - loss: 2.8496 - acc: 0.1554 - val_loss: 2.6594 - val_acc: 0.1573\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 58s 633ms/step - loss: 2.8861 - acc: 0.1412 - val_loss: 2.6502 - val_acc: 0.1530\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 57s 629ms/step - loss: 2.8255 - acc: 0.1611 - val_loss: 2.6339 - val_acc: 0.1638\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 59s 642ms/step - loss: 2.7983 - acc: 0.1554 - val_loss: 2.6465 - val_acc: 0.1638\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 60s 658ms/step - loss: 2.8958 - acc: 0.1498 - val_loss: 2.6408 - val_acc: 0.1659\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 57s 625ms/step - loss: 2.8330 - acc: 0.1604 - val_loss: 2.6580 - val_acc: 0.1573\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 57s 622ms/step - loss: 2.8218 - acc: 0.1505 - val_loss: 2.6590 - val_acc: 0.1573\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 62s 675ms/step - loss: 2.7918 - acc: 0.1611 - val_loss: 2.6636 - val_acc: 0.1616\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 58s 629ms/step - loss: 2.7812 - acc: 0.1625 - val_loss: 2.6367 - val_acc: 0.1659\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 61s 666ms/step - loss: 2.7953 - acc: 0.1490 - val_loss: 2.6250 - val_acc: 0.1573\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 57s 629ms/step - loss: 2.7916 - acc: 0.1576 - val_loss: 2.6347 - val_acc: 0.1616\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 56s 612ms/step - loss: 2.7779 - acc: 0.1632 - val_loss: 2.6534 - val_acc: 0.1638\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 56s 611ms/step - loss: 2.8135 - acc: 0.1519 - val_loss: 2.6423 - val_acc: 0.1595\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 58s 633ms/step - loss: 2.8502 - acc: 0.1554 - val_loss: 2.6399 - val_acc: 0.1573\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 58s 638ms/step - loss: 2.7652 - acc: 0.1760 - val_loss: 2.6355 - val_acc: 0.1487\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 61s 654ms/step - loss: 2.7910 - acc: 0.1576 - val_loss: 2.6358 - val_acc: 0.1681\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 57s 624ms/step - loss: 2.7915 - acc: 0.1561 - val_loss: 2.6206 - val_acc: 0.1638\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 60s 662ms/step - loss: 2.7593 - acc: 0.1576 - val_loss: 2.6339 - val_acc: 0.1573\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 56s 613ms/step - loss: 2.7754 - acc: 0.1540 - val_loss: 2.6461 - val_acc: 0.1530\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 57s 625ms/step - loss: 2.7803 - acc: 0.1533 - val_loss: 2.6478 - val_acc: 0.1595\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 58s 622ms/step - loss: 2.7801 - acc: 0.1668 - val_loss: 2.6375 - val_acc: 0.1616\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 57s 627ms/step - loss: 2.7997 - acc: 0.1568 - val_loss: 2.6283 - val_acc: 0.1659\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 62s 679ms/step - loss: 2.7449 - acc: 0.1710 - val_loss: 2.6303 - val_acc: 0.1616\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 58s 642ms/step - loss: 2.7997 - acc: 0.1483 - val_loss: 2.6408 - val_acc: 0.1595\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 57s 626ms/step - loss: 2.7089 - acc: 0.1725 - val_loss: 2.6390 - val_acc: 0.1573\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 61s 668ms/step - loss: 2.7446 - acc: 0.1689 - val_loss: 2.6369 - val_acc: 0.1573\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 59s 649ms/step - loss: 2.7374 - acc: 0.1625 - val_loss: 2.6347 - val_acc: 0.1703\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 61s 668ms/step - loss: 2.7992 - acc: 0.1604 - val_loss: 2.6249 - val_acc: 0.1573\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 57s 626ms/step - loss: 2.7633 - acc: 0.1611 - val_loss: 2.6230 - val_acc: 0.1595\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 57s 628ms/step - loss: 2.7923 - acc: 0.1519 - val_loss: 2.6394 - val_acc: 0.1616\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 2.8186 - acc: 0.1561 - val_loss: 2.6319 - val_acc: 0.1595\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 57s 621ms/step - loss: 2.7183 - acc: 0.1739 - val_loss: 2.6439 - val_acc: 0.1595\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 60s 660ms/step - loss: 2.6690 - acc: 0.1774 - val_loss: 2.6455 - val_acc: 0.1530\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 57s 629ms/step - loss: 2.7042 - acc: 0.1739 - val_loss: 2.6319 - val_acc: 0.1616\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 62s 678ms/step - loss: 2.6721 - acc: 0.1895 - val_loss: 2.6462 - val_acc: 0.1659\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 60s 641ms/step - loss: 2.7297 - acc: 0.1725 - val_loss: 2.6433 - val_acc: 0.1616\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 58s 634ms/step - loss: 2.6842 - acc: 0.1803 - val_loss: 2.6394 - val_acc: 0.1573\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 62s 685ms/step - loss: 2.7800 - acc: 0.1632 - val_loss: 2.6295 - val_acc: 0.1595\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 59s 651ms/step - loss: 2.7524 - acc: 0.1767 - val_loss: 2.6296 - val_acc: 0.1530\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 57s 630ms/step - loss: 2.7081 - acc: 0.1583 - val_loss: 2.6292 - val_acc: 0.1573\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 57s 621ms/step - loss: 2.7169 - acc: 0.1618 - val_loss: 2.6113 - val_acc: 0.1552\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 59s 647ms/step - loss: 2.7366 - acc: 0.1682 - val_loss: 2.6239 - val_acc: 0.1595\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 63s 687ms/step - loss: 2.7024 - acc: 0.1746 - val_loss: 2.6423 - val_acc: 0.1466\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 56s 615ms/step - loss: 2.7992 - acc: 0.1547 - val_loss: 2.6202 - val_acc: 0.1573\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 56s 613ms/step - loss: 2.7572 - acc: 0.1597 - val_loss: 2.6355 - val_acc: 0.1659\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 57s 627ms/step - loss: 2.7440 - acc: 0.1568 - val_loss: 2.6353 - val_acc: 0.1552\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 59s 649ms/step - loss: 2.6990 - acc: 0.1732 - val_loss: 2.6279 - val_acc: 0.1638\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 62s 682ms/step - loss: 2.7126 - acc: 0.1739 - val_loss: 2.6082 - val_acc: 0.1681\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 57s 623ms/step - loss: 2.6968 - acc: 0.1831 - val_loss: 2.6249 - val_acc: 0.1573\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 62s 681ms/step - loss: 2.7214 - acc: 0.1767 - val_loss: 2.6296 - val_acc: 0.1616\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 56s 618ms/step - loss: 2.7528 - acc: 0.1703 - val_loss: 2.6284 - val_acc: 0.1595\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 55s 604ms/step - loss: 2.6767 - acc: 0.1789 - val_loss: 2.6378 - val_acc: 0.1573\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 55s 606ms/step - loss: 2.7038 - acc: 0.1675 - val_loss: 2.6361 - val_acc: 0.1659\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 56s 616ms/step - loss: 2.6812 - acc: 0.1583 - val_loss: 2.6237 - val_acc: 0.1638\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 2.7112 - acc: 0.1696 - val_loss: 2.6141 - val_acc: 0.1681\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 56s 609ms/step - loss: 2.6532 - acc: 0.1838 - val_loss: 2.6151 - val_acc: 0.1681\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 56s 613ms/step - loss: 2.6613 - acc: 0.1888 - val_loss: 2.6166 - val_acc: 0.1616\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 61s 667ms/step - loss: 2.6648 - acc: 0.1817 - val_loss: 2.6188 - val_acc: 0.1638\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 55s 608ms/step - loss: 2.7123 - acc: 0.1668 - val_loss: 2.6211 - val_acc: 0.1616\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 56s 612ms/step - loss: 2.6389 - acc: 0.1845 - val_loss: 2.6146 - val_acc: 0.1552\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 55s 604ms/step - loss: 2.7265 - acc: 0.1718 - val_loss: 2.6190 - val_acc: 0.1638\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 58s 632ms/step - loss: 2.7403 - acc: 0.1590 - val_loss: 2.6374 - val_acc: 0.1573\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 61s 673ms/step - loss: 2.6706 - acc: 0.1867 - val_loss: 2.6360 - val_acc: 0.1681\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 56s 612ms/step - loss: 2.6706 - acc: 0.1824 - val_loss: 2.6381 - val_acc: 0.1659\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 56s 613ms/step - loss: 2.7306 - acc: 0.1604 - val_loss: 2.6403 - val_acc: 0.1681\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 57s 623ms/step - loss: 2.6737 - acc: 0.1668 - val_loss: 2.6234 - val_acc: 0.1595\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 56s 612ms/step - loss: 2.6852 - acc: 0.1831 - val_loss: 2.6146 - val_acc: 0.1509\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 60s 655ms/step - loss: 2.6030 - acc: 0.1774 - val_loss: 2.6191 - val_acc: 0.1509\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 57s 622ms/step - loss: 2.6807 - acc: 0.1689 - val_loss: 2.6194 - val_acc: 0.1616\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 60s 659ms/step - loss: 2.6365 - acc: 0.1838 - val_loss: 2.6180 - val_acc: 0.1616\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 64s 696ms/step - loss: 2.6539 - acc: 0.1725 - val_loss: 2.6089 - val_acc: 0.1659\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 60s 654ms/step - loss: 2.7250 - acc: 0.1583 - val_loss: 2.6042 - val_acc: 0.1573\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 60s 661ms/step - loss: 2.6912 - acc: 0.1824 - val_loss: 2.6176 - val_acc: 0.1595\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 61s 669ms/step - loss: 2.6615 - acc: 0.1696 - val_loss: 2.6060 - val_acc: 0.1681\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 64s 700ms/step - loss: 2.6839 - acc: 0.1703 - val_loss: 2.6087 - val_acc: 0.1573\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 61s 666ms/step - loss: 2.6201 - acc: 0.1718 - val_loss: 2.6247 - val_acc: 0.1573\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 59s 648ms/step - loss: 2.6106 - acc: 0.1902 - val_loss: 2.6193 - val_acc: 0.1552\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 66s 723ms/step - loss: 2.6423 - acc: 0.1838 - val_loss: 2.5987 - val_acc: 0.1703\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 62s 680ms/step - loss: 2.6185 - acc: 0.1789 - val_loss: 2.6113 - val_acc: 0.1573\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 64s 697ms/step - loss: 2.6179 - acc: 0.1852 - val_loss: 2.6216 - val_acc: 0.1681\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 58s 638ms/step - loss: 2.6263 - acc: 0.1923 - val_loss: 2.6060 - val_acc: 0.1724\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 59s 644ms/step - loss: 2.6100 - acc: 0.1916 - val_loss: 2.6124 - val_acc: 0.1595\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 61s 675ms/step - loss: 2.6480 - acc: 0.1902 - val_loss: 2.6106 - val_acc: 0.1681\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 56s 618ms/step - loss: 2.6787 - acc: 0.1710 - val_loss: 2.6074 - val_acc: 0.1681\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 63s 690ms/step - loss: 2.6431 - acc: 0.1675 - val_loss: 2.6070 - val_acc: 0.1681\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 59s 647ms/step - loss: 2.6724 - acc: 0.1725 - val_loss: 2.5981 - val_acc: 0.1638\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 58s 634ms/step - loss: 2.6177 - acc: 0.1760 - val_loss: 2.6127 - val_acc: 0.1703\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 61s 667ms/step - loss: 2.6104 - acc: 0.1654 - val_loss: 2.6138 - val_acc: 0.1659\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 58s 636ms/step - loss: 2.6183 - acc: 0.1703 - val_loss: 2.6104 - val_acc: 0.1681\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 60s 658ms/step - loss: 2.6667 - acc: 0.1767 - val_loss: 2.6174 - val_acc: 0.1681\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 58s 637ms/step - loss: 2.6775 - acc: 0.1867 - val_loss: 2.5941 - val_acc: 0.1681\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 61s 672ms/step - loss: 2.6656 - acc: 0.1760 - val_loss: 2.6157 - val_acc: 0.1681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "06069eaa-0b3e-4806-aa51-09fe798afe88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}