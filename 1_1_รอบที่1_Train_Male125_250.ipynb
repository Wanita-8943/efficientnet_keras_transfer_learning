{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/1_1_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%881_Train_Male125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "80b800a8-b581-433d-878a-e3236114673e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Male_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3194ba88-a0ed-4439-c933-37001d87de5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07M       VV03.jpg   \n",
              "1           2               1          7  Y07M  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M       VV04.jpg   \n",
              "3           4               2          7  Y07M  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M       VV05.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              77         25  Y25M  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M       J464.jpg   \n",
              "2372      123              78         25  Y25M  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M       J465.jpg   \n",
              "2374      125              79         25  Y25M  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec01dd01-0577-4519-b728-803aa9e32b16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec01dd01-0577-4519-b728-803aa9e32b16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec01dd01-0577-4519-b728-803aa9e32b16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec01dd01-0577-4519-b728-803aa9e32b16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 473\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "6bd3492f-3e5c-4a26-bd5e-69ade9617c51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 566, done.\u001b[K\n",
            "remote: Counting objects: 100% (382/382), done.\u001b[K\n",
            "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
            "Receiving objects: 100% (566/566), 10.54 MiB | 18.93 MiB/s, done.\n",
            "remote: Total 566 (delta 268), reused 266 (delta 199), pack-reused 184\u001b[K\n",
            "Resolving deltas: 100% (341/341), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea623db-aece-4be6-bb0c-d2d6e5346c69"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "b7876422-deed-46f5-e41e-e535950b822b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "e5a3dbc8-a8fa-43c5-86ce-a97a3d2b6963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "542c4856-3d7f-44d6-80b0-5f2aaa16ad14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "d3cfa1ec-a39d-47e2-f760-eab615a27f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "bef2b1f0-37f6-4e99-d851-c10b9e8c0a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-15-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 174s 2s/step - loss: 5.1318 - acc: 0.0539 - val_loss: 4.5507 - val_acc: 0.0388\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 69s 758ms/step - loss: 4.3880 - acc: 0.0461 - val_loss: 4.2384 - val_acc: 0.0496\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 69s 761ms/step - loss: 4.0944 - acc: 0.0539 - val_loss: 4.0911 - val_acc: 0.0474\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 74s 796ms/step - loss: 4.0837 - acc: 0.0511 - val_loss: 4.0614 - val_acc: 0.0431\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 72s 783ms/step - loss: 4.0935 - acc: 0.0632 - val_loss: 4.0281 - val_acc: 0.0474\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.9778 - acc: 0.0582 - val_loss: 3.9931 - val_acc: 0.0496\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 71s 780ms/step - loss: 3.9309 - acc: 0.0617 - val_loss: 3.9169 - val_acc: 0.0496\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 3.9311 - acc: 0.0696 - val_loss: 3.8832 - val_acc: 0.0517\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 71s 776ms/step - loss: 3.8553 - acc: 0.0781 - val_loss: 3.8307 - val_acc: 0.0582\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 3.9370 - acc: 0.0603 - val_loss: 3.8215 - val_acc: 0.0603\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 72s 785ms/step - loss: 3.9077 - acc: 0.0625 - val_loss: 3.7672 - val_acc: 0.0690\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 74s 787ms/step - loss: 3.9070 - acc: 0.0603 - val_loss: 3.7562 - val_acc: 0.0603\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 72s 778ms/step - loss: 3.8535 - acc: 0.0646 - val_loss: 3.7206 - val_acc: 0.0690\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 71s 777ms/step - loss: 3.7540 - acc: 0.0724 - val_loss: 3.6847 - val_acc: 0.0668\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 3.7272 - acc: 0.0788 - val_loss: 3.6086 - val_acc: 0.0776\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 71s 776ms/step - loss: 3.7104 - acc: 0.0852 - val_loss: 3.5862 - val_acc: 0.0797\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 3.7130 - acc: 0.0738 - val_loss: 3.5475 - val_acc: 0.0776\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 71s 780ms/step - loss: 3.6229 - acc: 0.0816 - val_loss: 3.5299 - val_acc: 0.0841\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 3.6350 - acc: 0.0845 - val_loss: 3.5185 - val_acc: 0.0841\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 3.7013 - acc: 0.0724 - val_loss: 3.4785 - val_acc: 0.0841\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 3.5814 - acc: 0.0859 - val_loss: 3.4389 - val_acc: 0.0884\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 3.6496 - acc: 0.0837 - val_loss: 3.4234 - val_acc: 0.0884\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 3.6169 - acc: 0.0901 - val_loss: 3.4128 - val_acc: 0.0884\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 3.6260 - acc: 0.0859 - val_loss: 3.3943 - val_acc: 0.0927\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 3.5278 - acc: 0.0852 - val_loss: 3.3997 - val_acc: 0.0927\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.5811 - acc: 0.0908 - val_loss: 3.3805 - val_acc: 0.0905\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.5392 - acc: 0.0830 - val_loss: 3.3448 - val_acc: 0.0927\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 3.5292 - acc: 0.1022 - val_loss: 3.3243 - val_acc: 0.0948\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.4679 - acc: 0.0979 - val_loss: 3.3003 - val_acc: 0.1034\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 72s 789ms/step - loss: 3.5503 - acc: 0.0901 - val_loss: 3.3146 - val_acc: 0.0948\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 3.5309 - acc: 0.0823 - val_loss: 3.2879 - val_acc: 0.0948\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 72s 787ms/step - loss: 3.5192 - acc: 0.0987 - val_loss: 3.2590 - val_acc: 0.1078\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 3.4650 - acc: 0.0994 - val_loss: 3.2656 - val_acc: 0.1034\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 3.4417 - acc: 0.0923 - val_loss: 3.2123 - val_acc: 0.1013\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.4208 - acc: 0.1079 - val_loss: 3.2065 - val_acc: 0.1034\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 3.4384 - acc: 0.0979 - val_loss: 3.2093 - val_acc: 0.1034\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 3.3907 - acc: 0.1008 - val_loss: 3.1968 - val_acc: 0.1034\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 3.3969 - acc: 0.0987 - val_loss: 3.1605 - val_acc: 0.1121\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 3.3916 - acc: 0.1043 - val_loss: 3.1627 - val_acc: 0.1078\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.3117 - acc: 0.1235 - val_loss: 3.1416 - val_acc: 0.1099\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 3.3887 - acc: 0.0894 - val_loss: 3.1226 - val_acc: 0.1099\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 3.3092 - acc: 0.0972 - val_loss: 3.1502 - val_acc: 0.1142\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 3.3830 - acc: 0.0994 - val_loss: 3.1282 - val_acc: 0.1121\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.4170 - acc: 0.0901 - val_loss: 3.1272 - val_acc: 0.1121\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 74s 795ms/step - loss: 3.3675 - acc: 0.1065 - val_loss: 3.1020 - val_acc: 0.1164\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 3.3173 - acc: 0.1050 - val_loss: 3.1001 - val_acc: 0.1185\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 74s 819ms/step - loss: 3.2352 - acc: 0.1121 - val_loss: 3.0936 - val_acc: 0.1142\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.3062 - acc: 0.0994 - val_loss: 3.0802 - val_acc: 0.1121\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 3.2266 - acc: 0.1348 - val_loss: 3.0898 - val_acc: 0.1121\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 3.2652 - acc: 0.1164 - val_loss: 3.0645 - val_acc: 0.1185\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 3.2934 - acc: 0.0994 - val_loss: 3.0431 - val_acc: 0.1164\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 3.2486 - acc: 0.1249 - val_loss: 3.0464 - val_acc: 0.1250\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.2723 - acc: 0.1086 - val_loss: 3.0397 - val_acc: 0.1142\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 3.2630 - acc: 0.1100 - val_loss: 3.0583 - val_acc: 0.1250\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 73s 795ms/step - loss: 3.3232 - acc: 0.1043 - val_loss: 3.0239 - val_acc: 0.1358\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.1519 - acc: 0.1299 - val_loss: 3.0165 - val_acc: 0.1142\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.2757 - acc: 0.1079 - val_loss: 2.9997 - val_acc: 0.1121\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 3.2202 - acc: 0.1008 - val_loss: 3.0136 - val_acc: 0.1121\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.2259 - acc: 0.1128 - val_loss: 2.9920 - val_acc: 0.1185\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 72s 796ms/step - loss: 3.2036 - acc: 0.1214 - val_loss: 2.9928 - val_acc: 0.1293\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 3.1379 - acc: 0.1207 - val_loss: 2.9693 - val_acc: 0.1185\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 3.1542 - acc: 0.1192 - val_loss: 2.9832 - val_acc: 0.1185\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.1607 - acc: 0.1249 - val_loss: 2.9652 - val_acc: 0.1142\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.1554 - acc: 0.1285 - val_loss: 2.9460 - val_acc: 0.1142\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 3.1833 - acc: 0.1107 - val_loss: 2.9442 - val_acc: 0.1164\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.2186 - acc: 0.1221 - val_loss: 2.9447 - val_acc: 0.1164\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.2060 - acc: 0.1143 - val_loss: 2.9333 - val_acc: 0.1121\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.1254 - acc: 0.1178 - val_loss: 2.9354 - val_acc: 0.1164\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 3.1646 - acc: 0.1150 - val_loss: 2.9256 - val_acc: 0.1185\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 3.1775 - acc: 0.1136 - val_loss: 2.9393 - val_acc: 0.1121\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 3.1272 - acc: 0.1164 - val_loss: 2.9179 - val_acc: 0.1121\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.0873 - acc: 0.1313 - val_loss: 2.9124 - val_acc: 0.1121\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.1276 - acc: 0.1292 - val_loss: 2.8968 - val_acc: 0.1034\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 3.0960 - acc: 0.1306 - val_loss: 2.9045 - val_acc: 0.1056\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 3.0425 - acc: 0.1455 - val_loss: 2.8940 - val_acc: 0.1078\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 3.0888 - acc: 0.1356 - val_loss: 2.9092 - val_acc: 0.1142\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 3.1378 - acc: 0.1242 - val_loss: 2.9042 - val_acc: 0.1164\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 3.0577 - acc: 0.1235 - val_loss: 2.9066 - val_acc: 0.0970\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 3.0951 - acc: 0.1278 - val_loss: 2.8926 - val_acc: 0.1185\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 3.0578 - acc: 0.1320 - val_loss: 2.8544 - val_acc: 0.1207\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 3.0620 - acc: 0.1270 - val_loss: 2.8646 - val_acc: 0.1185\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.0731 - acc: 0.1320 - val_loss: 2.8636 - val_acc: 0.1185\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.0786 - acc: 0.1469 - val_loss: 2.8735 - val_acc: 0.1207\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0634 - acc: 0.1249 - val_loss: 2.8691 - val_acc: 0.1207\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.1430 - acc: 0.1150 - val_loss: 2.8582 - val_acc: 0.1293\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 3.0577 - acc: 0.1441 - val_loss: 2.8680 - val_acc: 0.1228\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.0559 - acc: 0.1178 - val_loss: 2.8454 - val_acc: 0.1228\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 3.0327 - acc: 0.1278 - val_loss: 2.8624 - val_acc: 0.1250\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0017 - acc: 0.1306 - val_loss: 2.8382 - val_acc: 0.1272\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 3.0632 - acc: 0.1235 - val_loss: 2.8417 - val_acc: 0.1272\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 3.0338 - acc: 0.1341 - val_loss: 2.8454 - val_acc: 0.1185\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 3.0684 - acc: 0.1256 - val_loss: 2.8513 - val_acc: 0.1121\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 3.0293 - acc: 0.1263 - val_loss: 2.8147 - val_acc: 0.1250\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.0493 - acc: 0.1327 - val_loss: 2.8124 - val_acc: 0.1272\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 3.0334 - acc: 0.1398 - val_loss: 2.8291 - val_acc: 0.1228\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.9741 - acc: 0.1519 - val_loss: 2.8228 - val_acc: 0.1250\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.0023 - acc: 0.1519 - val_loss: 2.8224 - val_acc: 0.1293\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0210 - acc: 0.1285 - val_loss: 2.8171 - val_acc: 0.1293\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 3.0494 - acc: 0.1341 - val_loss: 2.8318 - val_acc: 0.1250\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.9686 - acc: 0.1533 - val_loss: 2.8280 - val_acc: 0.1358\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 74s 819ms/step - loss: 3.0197 - acc: 0.1398 - val_loss: 2.8260 - val_acc: 0.1293\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 3.0286 - acc: 0.1285 - val_loss: 2.8181 - val_acc: 0.1250\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.9935 - acc: 0.1320 - val_loss: 2.8144 - val_acc: 0.1272\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.9578 - acc: 0.1384 - val_loss: 2.8267 - val_acc: 0.1315\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 3.0531 - acc: 0.1263 - val_loss: 2.8210 - val_acc: 0.1250\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.9780 - acc: 0.1363 - val_loss: 2.8072 - val_acc: 0.1250\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 73s 802ms/step - loss: 3.0380 - acc: 0.1263 - val_loss: 2.8213 - val_acc: 0.1250\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.9333 - acc: 0.1512 - val_loss: 2.7883 - val_acc: 0.1207\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 73s 797ms/step - loss: 2.9239 - acc: 0.1384 - val_loss: 2.8118 - val_acc: 0.1228\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.9809 - acc: 0.1547 - val_loss: 2.8071 - val_acc: 0.1250\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.9581 - acc: 0.1554 - val_loss: 2.8128 - val_acc: 0.1250\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 75s 805ms/step - loss: 2.9203 - acc: 0.1313 - val_loss: 2.8117 - val_acc: 0.1228\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.8969 - acc: 0.1512 - val_loss: 2.8506 - val_acc: 0.1207\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.9419 - acc: 0.1334 - val_loss: 2.8036 - val_acc: 0.1228\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.9332 - acc: 0.1256 - val_loss: 2.7950 - val_acc: 0.1228\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 75s 823ms/step - loss: 2.8520 - acc: 0.1561 - val_loss: 2.7918 - val_acc: 0.1250\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.9892 - acc: 0.1320 - val_loss: 2.8003 - val_acc: 0.1185\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.9518 - acc: 0.1348 - val_loss: 2.7941 - val_acc: 0.1250\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.9297 - acc: 0.1448 - val_loss: 2.7965 - val_acc: 0.1272\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.9158 - acc: 0.1441 - val_loss: 2.7942 - val_acc: 0.1185\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.9811 - acc: 0.1391 - val_loss: 2.7928 - val_acc: 0.1228\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.8851 - acc: 0.1625 - val_loss: 2.7996 - val_acc: 0.1228\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 73s 808ms/step - loss: 2.8967 - acc: 0.1356 - val_loss: 2.8006 - val_acc: 0.1164\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.9836 - acc: 0.1306 - val_loss: 2.7973 - val_acc: 0.1250\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 73s 806ms/step - loss: 2.9044 - acc: 0.1377 - val_loss: 2.7776 - val_acc: 0.1315\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.8061 - acc: 0.1668 - val_loss: 2.7671 - val_acc: 0.1250\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 2.9328 - acc: 0.1405 - val_loss: 2.7738 - val_acc: 0.1207\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.8848 - acc: 0.1462 - val_loss: 2.7890 - val_acc: 0.1250\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.9078 - acc: 0.1313 - val_loss: 2.7687 - val_acc: 0.1293\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.8749 - acc: 0.1441 - val_loss: 2.7640 - val_acc: 0.1207\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.9632 - acc: 0.1242 - val_loss: 2.7654 - val_acc: 0.1293\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.8834 - acc: 0.1490 - val_loss: 2.7781 - val_acc: 0.1272\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.9337 - acc: 0.1427 - val_loss: 2.7771 - val_acc: 0.1207\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.8623 - acc: 0.1611 - val_loss: 2.7584 - val_acc: 0.1185\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.8762 - acc: 0.1675 - val_loss: 2.7745 - val_acc: 0.1228\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.9227 - acc: 0.1483 - val_loss: 2.7724 - val_acc: 0.1293\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.9089 - acc: 0.1554 - val_loss: 2.7840 - val_acc: 0.1293\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.8705 - acc: 0.1356 - val_loss: 2.7580 - val_acc: 0.1293\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.8366 - acc: 0.1540 - val_loss: 2.7662 - val_acc: 0.1207\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.8419 - acc: 0.1512 - val_loss: 2.7636 - val_acc: 0.1250\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.8555 - acc: 0.1661 - val_loss: 2.7765 - val_acc: 0.1250\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.8324 - acc: 0.1490 - val_loss: 2.7785 - val_acc: 0.1250\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.7659 - acc: 0.1590 - val_loss: 2.7664 - val_acc: 0.1315\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.8550 - acc: 0.1618 - val_loss: 2.7665 - val_acc: 0.1315\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.8060 - acc: 0.1526 - val_loss: 2.7741 - val_acc: 0.1336\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.8351 - acc: 0.1611 - val_loss: 2.7756 - val_acc: 0.1250\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.8598 - acc: 0.1405 - val_loss: 2.7609 - val_acc: 0.1250\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.8511 - acc: 0.1441 - val_loss: 2.7672 - val_acc: 0.1228\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.7938 - acc: 0.1597 - val_loss: 2.7782 - val_acc: 0.1121\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.8307 - acc: 0.1434 - val_loss: 2.7462 - val_acc: 0.1250\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.8184 - acc: 0.1561 - val_loss: 2.7628 - val_acc: 0.1207\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.7696 - acc: 0.1632 - val_loss: 2.7600 - val_acc: 0.1207\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 76s 839ms/step - loss: 2.8027 - acc: 0.1526 - val_loss: 2.7727 - val_acc: 0.1293\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.8322 - acc: 0.1561 - val_loss: 2.7488 - val_acc: 0.1185\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.7799 - acc: 0.1725 - val_loss: 2.7542 - val_acc: 0.1272\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.7896 - acc: 0.1639 - val_loss: 2.7585 - val_acc: 0.1293\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.7779 - acc: 0.1739 - val_loss: 2.7423 - val_acc: 0.1358\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.8819 - acc: 0.1455 - val_loss: 2.7376 - val_acc: 0.1250\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.7907 - acc: 0.1576 - val_loss: 2.7369 - val_acc: 0.1315\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.8320 - acc: 0.1498 - val_loss: 2.7584 - val_acc: 0.1250\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.7735 - acc: 0.1689 - val_loss: 2.7716 - val_acc: 0.1272\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.7315 - acc: 0.1675 - val_loss: 2.7551 - val_acc: 0.1207\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.7554 - acc: 0.1739 - val_loss: 2.7402 - val_acc: 0.1336\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.7663 - acc: 0.1561 - val_loss: 2.7347 - val_acc: 0.1315\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.7557 - acc: 0.1810 - val_loss: 2.7468 - val_acc: 0.1228\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 2.8097 - acc: 0.1476 - val_loss: 2.7426 - val_acc: 0.1250\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.7679 - acc: 0.1568 - val_loss: 2.7424 - val_acc: 0.1250\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 74s 809ms/step - loss: 2.8105 - acc: 0.1462 - val_loss: 2.7677 - val_acc: 0.1272\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.7987 - acc: 0.1639 - val_loss: 2.7177 - val_acc: 0.1379\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 73s 808ms/step - loss: 2.7775 - acc: 0.1647 - val_loss: 2.7275 - val_acc: 0.1228\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.8479 - acc: 0.1469 - val_loss: 2.7475 - val_acc: 0.1228\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.7326 - acc: 0.1739 - val_loss: 2.7356 - val_acc: 0.1272\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.7734 - acc: 0.1668 - val_loss: 2.7398 - val_acc: 0.1293\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 2.7308 - acc: 0.1739 - val_loss: 2.7460 - val_acc: 0.1293\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.8148 - acc: 0.1561 - val_loss: 2.7197 - val_acc: 0.1401\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.7583 - acc: 0.1639 - val_loss: 2.7300 - val_acc: 0.1207\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.7276 - acc: 0.1632 - val_loss: 2.7436 - val_acc: 0.1164\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.7616 - acc: 0.1611 - val_loss: 2.7205 - val_acc: 0.1336\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.7674 - acc: 0.1611 - val_loss: 2.7368 - val_acc: 0.1293\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 76s 817ms/step - loss: 2.7403 - acc: 0.1689 - val_loss: 2.7298 - val_acc: 0.1272\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 2.7355 - acc: 0.1639 - val_loss: 2.7358 - val_acc: 0.1250\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.7398 - acc: 0.1427 - val_loss: 2.7256 - val_acc: 0.1250\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.6804 - acc: 0.1654 - val_loss: 2.7486 - val_acc: 0.1185\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.7116 - acc: 0.1675 - val_loss: 2.7414 - val_acc: 0.1228\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 74s 838ms/step - loss: 2.7587 - acc: 0.1852 - val_loss: 2.7256 - val_acc: 0.1272\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.7734 - acc: 0.1597 - val_loss: 2.7399 - val_acc: 0.1250\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 74s 813ms/step - loss: 2.7552 - acc: 0.1590 - val_loss: 2.7244 - val_acc: 0.1315\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.7841 - acc: 0.1643 - val_loss: 2.7377 - val_acc: 0.1336\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.7282 - acc: 0.1767 - val_loss: 2.7005 - val_acc: 0.1358\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.7007 - acc: 0.1632 - val_loss: 2.7027 - val_acc: 0.1379\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.7155 - acc: 0.1689 - val_loss: 2.7428 - val_acc: 0.1315\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.7270 - acc: 0.1661 - val_loss: 2.7175 - val_acc: 0.1358\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.6739 - acc: 0.1746 - val_loss: 2.7172 - val_acc: 0.1315\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 2.7267 - acc: 0.1760 - val_loss: 2.7380 - val_acc: 0.1315\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.7479 - acc: 0.1540 - val_loss: 2.7229 - val_acc: 0.1293\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.7133 - acc: 0.1625 - val_loss: 2.7195 - val_acc: 0.1228\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.6810 - acc: 0.1767 - val_loss: 2.7210 - val_acc: 0.1293\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 77s 831ms/step - loss: 2.7024 - acc: 0.1774 - val_loss: 2.7294 - val_acc: 0.1315\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.6953 - acc: 0.1746 - val_loss: 2.7255 - val_acc: 0.1336\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.7691 - acc: 0.1476 - val_loss: 2.7263 - val_acc: 0.1207\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.7348 - acc: 0.1661 - val_loss: 2.7414 - val_acc: 0.1228\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.6475 - acc: 0.1888 - val_loss: 2.7296 - val_acc: 0.1293\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.7178 - acc: 0.1703 - val_loss: 2.7378 - val_acc: 0.1228\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.7235 - acc: 0.1696 - val_loss: 2.7277 - val_acc: 0.1250\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.6971 - acc: 0.1781 - val_loss: 2.7528 - val_acc: 0.1272\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.6788 - acc: 0.1547 - val_loss: 2.7433 - val_acc: 0.1228\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 76s 839ms/step - loss: 2.6729 - acc: 0.1760 - val_loss: 2.7321 - val_acc: 0.1185\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 75s 829ms/step - loss: 2.7007 - acc: 0.1576 - val_loss: 2.7469 - val_acc: 0.1250\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.6488 - acc: 0.1725 - val_loss: 2.7567 - val_acc: 0.1250\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 2.7014 - acc: 0.1661 - val_loss: 2.7494 - val_acc: 0.1207\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 74s 818ms/step - loss: 2.7236 - acc: 0.1654 - val_loss: 2.7379 - val_acc: 0.1228\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 76s 840ms/step - loss: 2.6871 - acc: 0.1703 - val_loss: 2.7203 - val_acc: 0.1207\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.6630 - acc: 0.1675 - val_loss: 2.7413 - val_acc: 0.1250\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.7192 - acc: 0.1625 - val_loss: 2.7407 - val_acc: 0.1207\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 74s 817ms/step - loss: 2.6974 - acc: 0.1689 - val_loss: 2.7380 - val_acc: 0.1207\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.6676 - acc: 0.1838 - val_loss: 2.7131 - val_acc: 0.1185\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 74s 819ms/step - loss: 2.6554 - acc: 0.1760 - val_loss: 2.7015 - val_acc: 0.1185\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.6630 - acc: 0.1874 - val_loss: 2.7211 - val_acc: 0.1207\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.6249 - acc: 0.1881 - val_loss: 2.7086 - val_acc: 0.1164\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.6706 - acc: 0.1824 - val_loss: 2.6972 - val_acc: 0.1250\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.7283 - acc: 0.1859 - val_loss: 2.7212 - val_acc: 0.1272\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.6300 - acc: 0.1845 - val_loss: 2.7107 - val_acc: 0.1185\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.6885 - acc: 0.1718 - val_loss: 2.7292 - val_acc: 0.1185\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.7005 - acc: 0.1710 - val_loss: 2.7294 - val_acc: 0.1228\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 74s 816ms/step - loss: 2.6243 - acc: 0.1781 - val_loss: 2.7278 - val_acc: 0.1293\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.7016 - acc: 0.1774 - val_loss: 2.7409 - val_acc: 0.1142\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.6681 - acc: 0.1840 - val_loss: 2.7402 - val_acc: 0.1293\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.6882 - acc: 0.1639 - val_loss: 2.7068 - val_acc: 0.1250\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.6757 - acc: 0.1838 - val_loss: 2.7257 - val_acc: 0.1228\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.6501 - acc: 0.1881 - val_loss: 2.7362 - val_acc: 0.1228\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.6859 - acc: 0.1568 - val_loss: 2.7454 - val_acc: 0.1207\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.6299 - acc: 0.1852 - val_loss: 2.7461 - val_acc: 0.1250\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.5968 - acc: 0.1852 - val_loss: 2.7255 - val_acc: 0.1315\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.6593 - acc: 0.1774 - val_loss: 2.7174 - val_acc: 0.1250\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.6288 - acc: 0.1938 - val_loss: 2.7433 - val_acc: 0.1185\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.6402 - acc: 0.1852 - val_loss: 2.7357 - val_acc: 0.1207\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.6513 - acc: 0.1625 - val_loss: 2.7292 - val_acc: 0.1272\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.6366 - acc: 0.1781 - val_loss: 2.7371 - val_acc: 0.1293\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 75s 830ms/step - loss: 2.6146 - acc: 0.1781 - val_loss: 2.7309 - val_acc: 0.1336\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.7120 - acc: 0.1668 - val_loss: 2.7220 - val_acc: 0.1272\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.6384 - acc: 0.1859 - val_loss: 2.7077 - val_acc: 0.1336\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.6465 - acc: 0.1647 - val_loss: 2.7140 - val_acc: 0.1250\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.5942 - acc: 0.1803 - val_loss: 2.7243 - val_acc: 0.1250\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 78s 861ms/step - loss: 2.6238 - acc: 0.1909 - val_loss: 2.7466 - val_acc: 0.1121\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.5826 - acc: 0.1895 - val_loss: 2.7365 - val_acc: 0.1164\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.6701 - acc: 0.1725 - val_loss: 2.7608 - val_acc: 0.1250\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.6245 - acc: 0.1774 - val_loss: 2.7337 - val_acc: 0.1272\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.6028 - acc: 0.1881 - val_loss: 2.7398 - val_acc: 0.1207\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.6540 - acc: 0.1753 - val_loss: 2.7515 - val_acc: 0.1250\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.5600 - acc: 0.1930 - val_loss: 2.7616 - val_acc: 0.1099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'co', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "8339bc62-11f6-49d6-ebe4-574bbe2e0785"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "222e0d46-c392-4b4d-be05-3618f4b18f39"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0aed91d-cb63-4a94-81b2-692a8c69c5f1\", \"1.1_\\u0e23\\u0e2d\\u0e1a\\u0e41\\u0e23\\u0e01_Flimpano_Male125_250.h5\", 16779376)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}