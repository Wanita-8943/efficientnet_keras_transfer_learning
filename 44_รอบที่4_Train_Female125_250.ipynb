{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/44_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%884_Train_Female125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKSs7cyoPHcD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LoeZxmVPMxp",
        "outputId": "d7e9f370-d104-4d5b-8e54-70dce2d51a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EG3WyBRiPM0P",
        "outputId": "52a9b359-e3e9-4e05-91c1-91c2826f85f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07F         V1.jpg   \n",
              "1           2               1          7  Y07F    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         V2.jpg   \n",
              "3           4               2          7  Y07F    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         V3.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              65         25  Y25F  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4b1b673-e944-465a-8ea7-4ac1dd161b52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4b1b673-e944-465a-8ea7-4ac1dd161b52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4b1b673-e944-465a-8ea7-4ac1dd161b52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4b1b673-e944-465a-8ea7-4ac1dd161b52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Female_125.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1pX9g1HxPM2f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eSFtvGyvPM6O"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 473\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4K4CsMPNAW",
        "outputId": "0a555e16-9c17-47fb-c362-a886c3ba5d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 554, done.\u001b[K\n",
            "remote: Counting objects: 100% (370/370), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 554 (delta 262), reused 266 (delta 199), pack-reused 184\u001b[K\n",
            "Receiving objects: 100% (554/554), 10.37 MiB | 21.03 MiB/s, done.\n",
            "Resolving deltas: 100% (335/335), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eyBg0dLKPND3"
      },
      "outputs": [],
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SxQTV4IKPb5h",
        "outputId": "2d7f8cee-1d88-464f-b527-dd90a6dc0c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVGeF9M7PchT",
        "outputId": "c8a199c8-aef4-4749-8782-7368f6cb144c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary() #ดู Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jwpq_-KvPef8"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od-ZSNm5PoGy"
      },
      "source": [
        "#load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n5iPL5MNPkhE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/cut_panoramic/Model/33_รอบที่3_Flimpano_Female125_250.h5')\n",
        "\n",
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "plYz49xMPkly"
      },
      "outputs": [],
      "source": [
        "#load model \n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/cut_panoramic/Model/33_รอบที่3_Flimpano_Female125_250.h5')\n",
        "height = width = model.input_shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMZbdr2Pgw4",
        "outputId": "4aea930d-7ad4-426b-d8b2-719597102ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od14yWT7Pka1",
        "outputId": "414825aa-acc6-4a55-e81b-ffeb2a5548f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Cf1dwyP1PD",
        "outputId": "e869f2f3-8bac-4976-e5c8-25cb293e3988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-15-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 114s 1s/step - loss: 2.2638 - acc: 0.2470 - val_loss: 2.7411 - val_acc: 0.1724\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 71s 774ms/step - loss: 2.3090 - acc: 0.2449 - val_loss: 2.7247 - val_acc: 0.1853\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 71s 777ms/step - loss: 2.2562 - acc: 0.2654 - val_loss: 2.7608 - val_acc: 0.1897\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 71s 781ms/step - loss: 2.2568 - acc: 0.2548 - val_loss: 2.7495 - val_acc: 0.1810\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.3156 - acc: 0.2285 - val_loss: 2.7182 - val_acc: 0.1897\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 76s 809ms/step - loss: 2.2905 - acc: 0.2661 - val_loss: 2.7035 - val_acc: 0.1918\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.2477 - acc: 0.2477 - val_loss: 2.6942 - val_acc: 0.1918\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.2806 - acc: 0.2590 - val_loss: 2.7177 - val_acc: 0.1789\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 72s 794ms/step - loss: 2.2764 - acc: 0.2541 - val_loss: 2.7017 - val_acc: 0.1832\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2893 - acc: 0.2512 - val_loss: 2.6777 - val_acc: 0.1810\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.2628 - acc: 0.2498 - val_loss: 2.7197 - val_acc: 0.1789\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 78s 860ms/step - loss: 2.1939 - acc: 0.2754 - val_loss: 2.7286 - val_acc: 0.1875\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.2871 - acc: 0.2420 - val_loss: 2.7164 - val_acc: 0.1810\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.2412 - acc: 0.2505 - val_loss: 2.7433 - val_acc: 0.1832\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2454 - acc: 0.2541 - val_loss: 2.7342 - val_acc: 0.1810\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.2749 - acc: 0.2399 - val_loss: 2.7127 - val_acc: 0.1810\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.2618 - acc: 0.2619 - val_loss: 2.7156 - val_acc: 0.1810\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.2754 - acc: 0.2498 - val_loss: 2.7373 - val_acc: 0.1832\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.2210 - acc: 0.2661 - val_loss: 2.7498 - val_acc: 0.1789\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 77s 852ms/step - loss: 2.2721 - acc: 0.2370 - val_loss: 2.7483 - val_acc: 0.1853\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.2794 - acc: 0.2555 - val_loss: 2.7313 - val_acc: 0.1789\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2151 - acc: 0.2725 - val_loss: 2.7374 - val_acc: 0.1832\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.2442 - acc: 0.2434 - val_loss: 2.7426 - val_acc: 0.1746\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.2426 - acc: 0.2413 - val_loss: 2.7358 - val_acc: 0.1746\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 79s 863ms/step - loss: 2.2539 - acc: 0.2427 - val_loss: 2.7339 - val_acc: 0.1810\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.2566 - acc: 0.2541 - val_loss: 2.7627 - val_acc: 0.1832\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 74s 805ms/step - loss: 2.2616 - acc: 0.2413 - val_loss: 2.7412 - val_acc: 0.1789\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 73s 804ms/step - loss: 2.2674 - acc: 0.2441 - val_loss: 2.7190 - val_acc: 0.1853\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.2632 - acc: 0.2527 - val_loss: 2.7342 - val_acc: 0.1724\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.2356 - acc: 0.2676 - val_loss: 2.7495 - val_acc: 0.1789\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 2.2502 - acc: 0.2534 - val_loss: 2.7399 - val_acc: 0.1681\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2566 - acc: 0.2619 - val_loss: 2.7323 - val_acc: 0.1767\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.2610 - acc: 0.2598 - val_loss: 2.7358 - val_acc: 0.1724\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.2457 - acc: 0.2541 - val_loss: 2.7261 - val_acc: 0.1810\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 74s 807ms/step - loss: 2.2322 - acc: 0.2661 - val_loss: 2.7479 - val_acc: 0.1789\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.2402 - acc: 0.2583 - val_loss: 2.7263 - val_acc: 0.1767\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 73s 808ms/step - loss: 2.2176 - acc: 0.2505 - val_loss: 2.7396 - val_acc: 0.1746\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.2007 - acc: 0.2711 - val_loss: 2.7608 - val_acc: 0.1724\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 75s 829ms/step - loss: 2.2891 - acc: 0.2385 - val_loss: 2.7701 - val_acc: 0.1703\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.3217 - acc: 0.2335 - val_loss: 2.7446 - val_acc: 0.1767\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2719 - acc: 0.2491 - val_loss: 2.7414 - val_acc: 0.1789\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.3068 - acc: 0.2406 - val_loss: 2.7256 - val_acc: 0.1746\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.2367 - acc: 0.2626 - val_loss: 2.7254 - val_acc: 0.1918\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.2539 - acc: 0.2484 - val_loss: 2.7542 - val_acc: 0.1810\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 79s 866ms/step - loss: 2.2274 - acc: 0.2640 - val_loss: 2.7407 - val_acc: 0.1832\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.2411 - acc: 0.2493 - val_loss: 2.7524 - val_acc: 0.1746\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 78s 859ms/step - loss: 2.2645 - acc: 0.2406 - val_loss: 2.7365 - val_acc: 0.1746\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 74s 811ms/step - loss: 2.2517 - acc: 0.2576 - val_loss: 2.7450 - val_acc: 0.1810\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 78s 858ms/step - loss: 2.2450 - acc: 0.2470 - val_loss: 2.7531 - val_acc: 0.1918\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2632 - acc: 0.2512 - val_loss: 2.7394 - val_acc: 0.1810\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2516 - acc: 0.2505 - val_loss: 2.7198 - val_acc: 0.1810\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.2637 - acc: 0.2633 - val_loss: 2.7116 - val_acc: 0.1810\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.2962 - acc: 0.2388 - val_loss: 2.7276 - val_acc: 0.1767\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 77s 842ms/step - loss: 2.2710 - acc: 0.2598 - val_loss: 2.7025 - val_acc: 0.1940\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.2566 - acc: 0.2456 - val_loss: 2.7120 - val_acc: 0.1832\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2888 - acc: 0.2527 - val_loss: 2.7274 - val_acc: 0.1810\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 75s 822ms/step - loss: 2.2401 - acc: 0.2555 - val_loss: 2.7256 - val_acc: 0.1724\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2579 - acc: 0.2555 - val_loss: 2.7602 - val_acc: 0.1789\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 75s 818ms/step - loss: 2.2615 - acc: 0.2434 - val_loss: 2.7286 - val_acc: 0.1767\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 79s 867ms/step - loss: 2.2301 - acc: 0.2718 - val_loss: 2.7282 - val_acc: 0.1767\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 74s 815ms/step - loss: 2.2553 - acc: 0.2704 - val_loss: 2.7360 - val_acc: 0.1659\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 79s 897ms/step - loss: 2.2282 - acc: 0.2605 - val_loss: 2.7499 - val_acc: 0.1703\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 77s 843ms/step - loss: 2.2811 - acc: 0.2292 - val_loss: 2.7208 - val_acc: 0.1724\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.2441 - acc: 0.2534 - val_loss: 2.7430 - val_acc: 0.1789\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2319 - acc: 0.2569 - val_loss: 2.7042 - val_acc: 0.1832\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.2301 - acc: 0.2661 - val_loss: 2.7176 - val_acc: 0.1832\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 77s 853ms/step - loss: 2.2112 - acc: 0.2363 - val_loss: 2.7251 - val_acc: 0.1961\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 78s 852ms/step - loss: 2.1839 - acc: 0.2661 - val_loss: 2.7033 - val_acc: 0.1853\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 79s 868ms/step - loss: 2.2498 - acc: 0.2498 - val_loss: 2.7015 - val_acc: 0.1940\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.2343 - acc: 0.2590 - val_loss: 2.7340 - val_acc: 0.1789\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2257 - acc: 0.2470 - val_loss: 2.7371 - val_acc: 0.1746\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 75s 844ms/step - loss: 2.1971 - acc: 0.2555 - val_loss: 2.7247 - val_acc: 0.1724\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 79s 874ms/step - loss: 2.2379 - acc: 0.2640 - val_loss: 2.7586 - val_acc: 0.1789\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.2064 - acc: 0.2960 - val_loss: 2.7332 - val_acc: 0.1789\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2725 - acc: 0.2562 - val_loss: 2.7488 - val_acc: 0.1724\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 75s 820ms/step - loss: 2.2357 - acc: 0.2385 - val_loss: 2.7333 - val_acc: 0.1853\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 79s 872ms/step - loss: 2.2352 - acc: 0.2427 - val_loss: 2.7195 - val_acc: 0.1853\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.2107 - acc: 0.2491 - val_loss: 2.7047 - val_acc: 0.1853\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 77s 850ms/step - loss: 2.1892 - acc: 0.2640 - val_loss: 2.7060 - val_acc: 0.1832\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 77s 848ms/step - loss: 2.2750 - acc: 0.2300 - val_loss: 2.6972 - val_acc: 0.1810\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.2160 - acc: 0.2732 - val_loss: 2.7219 - val_acc: 0.1832\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 77s 841ms/step - loss: 2.2313 - acc: 0.2576 - val_loss: 2.6977 - val_acc: 0.1789\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.1641 - acc: 0.2789 - val_loss: 2.7203 - val_acc: 0.1832\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 79s 869ms/step - loss: 2.2070 - acc: 0.2818 - val_loss: 2.7106 - val_acc: 0.1832\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.2313 - acc: 0.2512 - val_loss: 2.7373 - val_acc: 0.1832\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 79s 872ms/step - loss: 2.2329 - acc: 0.2541 - val_loss: 2.7215 - val_acc: 0.1897\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.2589 - acc: 0.2491 - val_loss: 2.7272 - val_acc: 0.1897\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 79s 871ms/step - loss: 2.2800 - acc: 0.2449 - val_loss: 2.7037 - val_acc: 0.1918\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.2380 - acc: 0.2527 - val_loss: 2.7237 - val_acc: 0.1832\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 79s 875ms/step - loss: 2.2185 - acc: 0.2796 - val_loss: 2.7265 - val_acc: 0.2004\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.2142 - acc: 0.2590 - val_loss: 2.7225 - val_acc: 0.1961\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 79s 867ms/step - loss: 2.2329 - acc: 0.2576 - val_loss: 2.7390 - val_acc: 0.1940\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.2340 - acc: 0.2463 - val_loss: 2.7314 - val_acc: 0.1789\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 79s 869ms/step - loss: 2.2446 - acc: 0.2555 - val_loss: 2.7294 - val_acc: 0.1810\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.2119 - acc: 0.2669 - val_loss: 2.7329 - val_acc: 0.1918\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 79s 875ms/step - loss: 2.2248 - acc: 0.2605 - val_loss: 2.7325 - val_acc: 0.1918\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.2485 - acc: 0.2434 - val_loss: 2.7387 - val_acc: 0.1940\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 80s 873ms/step - loss: 2.2353 - acc: 0.2534 - val_loss: 2.7515 - val_acc: 0.1789\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2249 - acc: 0.2541 - val_loss: 2.7509 - val_acc: 0.1961\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 81s 888ms/step - loss: 2.2446 - acc: 0.2697 - val_loss: 2.7487 - val_acc: 0.1789\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1969 - acc: 0.2789 - val_loss: 2.7514 - val_acc: 0.1853\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.2591 - acc: 0.2512 - val_loss: 2.7665 - val_acc: 0.1789\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 80s 878ms/step - loss: 2.2376 - acc: 0.2335 - val_loss: 2.7772 - val_acc: 0.1810\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2561 - acc: 0.2427 - val_loss: 2.7520 - val_acc: 0.1767\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.2226 - acc: 0.2569 - val_loss: 2.7464 - val_acc: 0.1789\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 81s 888ms/step - loss: 2.1939 - acc: 0.2633 - val_loss: 2.7458 - val_acc: 0.1832\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2389 - acc: 0.2477 - val_loss: 2.7184 - val_acc: 0.1853\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2408 - acc: 0.2498 - val_loss: 2.7468 - val_acc: 0.1853\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.2204 - acc: 0.2569 - val_loss: 2.7741 - val_acc: 0.1961\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.2247 - acc: 0.2491 - val_loss: 2.7592 - val_acc: 0.1875\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 80s 884ms/step - loss: 2.1962 - acc: 0.2626 - val_loss: 2.7620 - val_acc: 0.1853\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 76s 840ms/step - loss: 2.2018 - acc: 0.2548 - val_loss: 2.7376 - val_acc: 0.1918\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.2369 - acc: 0.2520 - val_loss: 2.7349 - val_acc: 0.1961\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2401 - acc: 0.2654 - val_loss: 2.7545 - val_acc: 0.1918\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2340 - acc: 0.2590 - val_loss: 2.7499 - val_acc: 0.1918\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.2185 - acc: 0.2690 - val_loss: 2.7302 - val_acc: 0.1897\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 81s 893ms/step - loss: 2.2354 - acc: 0.2427 - val_loss: 2.7506 - val_acc: 0.1897\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2491 - acc: 0.2470 - val_loss: 2.7376 - val_acc: 0.1875\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2810 - acc: 0.2441 - val_loss: 2.7535 - val_acc: 0.1918\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 80s 883ms/step - loss: 2.2249 - acc: 0.2590 - val_loss: 2.7379 - val_acc: 0.1897\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 77s 844ms/step - loss: 2.2723 - acc: 0.2562 - val_loss: 2.7670 - val_acc: 0.2004\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.2225 - acc: 0.2569 - val_loss: 2.7649 - val_acc: 0.1918\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 78s 844ms/step - loss: 2.2470 - acc: 0.2491 - val_loss: 2.7896 - val_acc: 0.1875\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2536 - acc: 0.2669 - val_loss: 2.7724 - val_acc: 0.1983\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 81s 885ms/step - loss: 2.2526 - acc: 0.2527 - val_loss: 2.7623 - val_acc: 0.1897\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.2291 - acc: 0.2534 - val_loss: 2.7659 - val_acc: 0.1918\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2112 - acc: 0.2676 - val_loss: 2.7679 - val_acc: 0.1897\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 80s 885ms/step - loss: 2.2048 - acc: 0.2598 - val_loss: 2.7578 - val_acc: 0.1918\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.2264 - acc: 0.2569 - val_loss: 2.7630 - val_acc: 0.1832\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 80s 877ms/step - loss: 2.2119 - acc: 0.2512 - val_loss: 2.7443 - val_acc: 0.1875\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.2139 - acc: 0.2740 - val_loss: 2.7562 - val_acc: 0.1853\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 80s 882ms/step - loss: 2.2389 - acc: 0.2569 - val_loss: 2.7598 - val_acc: 0.1875\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.1870 - acc: 0.2612 - val_loss: 2.7275 - val_acc: 0.1961\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 80s 879ms/step - loss: 2.2218 - acc: 0.2654 - val_loss: 2.7464 - val_acc: 0.1832\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.2203 - acc: 0.2619 - val_loss: 2.7540 - val_acc: 0.1746\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 80s 878ms/step - loss: 2.2466 - acc: 0.2491 - val_loss: 2.7532 - val_acc: 0.1767\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.2232 - acc: 0.2541 - val_loss: 2.7492 - val_acc: 0.1940\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 79s 846ms/step - loss: 2.2279 - acc: 0.2498 - val_loss: 2.7621 - val_acc: 0.1789\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.2373 - acc: 0.2647 - val_loss: 2.7701 - val_acc: 0.1789\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 77s 851ms/step - loss: 2.2202 - acc: 0.2640 - val_loss: 2.7598 - val_acc: 0.1897\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.2358 - acc: 0.2498 - val_loss: 2.7410 - val_acc: 0.1810\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2108 - acc: 0.2633 - val_loss: 2.7525 - val_acc: 0.1789\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 77s 849ms/step - loss: 2.2503 - acc: 0.2562 - val_loss: 2.7415 - val_acc: 0.1875\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 78s 856ms/step - loss: 2.2329 - acc: 0.2640 - val_loss: 2.7461 - val_acc: 0.1897\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 78s 854ms/step - loss: 2.2447 - acc: 0.2427 - val_loss: 2.7659 - val_acc: 0.1853\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2348 - acc: 0.2548 - val_loss: 2.7558 - val_acc: 0.1897\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 78s 851ms/step - loss: 2.2515 - acc: 0.2484 - val_loss: 2.7738 - val_acc: 0.1789\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 77s 869ms/step - loss: 2.2373 - acc: 0.2569 - val_loss: 2.7579 - val_acc: 0.1810\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.2199 - acc: 0.2605 - val_loss: 2.7342 - val_acc: 0.1832\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.2200 - acc: 0.2669 - val_loss: 2.7563 - val_acc: 0.1789\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 80s 877ms/step - loss: 2.1763 - acc: 0.2796 - val_loss: 2.7768 - val_acc: 0.1832\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 79s 866ms/step - loss: 2.1542 - acc: 0.2839 - val_loss: 2.7431 - val_acc: 0.1810\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 79s 875ms/step - loss: 2.2130 - acc: 0.2669 - val_loss: 2.7810 - val_acc: 0.1810\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 78s 840ms/step - loss: 2.2477 - acc: 0.2498 - val_loss: 2.7923 - val_acc: 0.1789\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.2097 - acc: 0.2484 - val_loss: 2.7721 - val_acc: 0.1789\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 78s 855ms/step - loss: 2.2048 - acc: 0.2761 - val_loss: 2.7336 - val_acc: 0.1789\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1971 - acc: 0.2860 - val_loss: 2.7668 - val_acc: 0.1767\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 80s 864ms/step - loss: 2.1997 - acc: 0.2477 - val_loss: 2.7652 - val_acc: 0.1703\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.2134 - acc: 0.2697 - val_loss: 2.7538 - val_acc: 0.1897\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 79s 873ms/step - loss: 2.2213 - acc: 0.2747 - val_loss: 2.7531 - val_acc: 0.1897\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 75s 821ms/step - loss: 2.2186 - acc: 0.2505 - val_loss: 2.7476 - val_acc: 0.1875\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2487 - acc: 0.2683 - val_loss: 2.7385 - val_acc: 0.1940\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.1830 - acc: 0.2590 - val_loss: 2.7481 - val_acc: 0.1767\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2100 - acc: 0.2590 - val_loss: 2.7380 - val_acc: 0.1897\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 80s 881ms/step - loss: 2.2204 - acc: 0.2676 - val_loss: 2.7609 - val_acc: 0.1789\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1908 - acc: 0.2690 - val_loss: 2.7499 - val_acc: 0.1853\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.1774 - acc: 0.2711 - val_loss: 2.7434 - val_acc: 0.1767\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.2152 - acc: 0.2704 - val_loss: 2.7503 - val_acc: 0.1724\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 76s 827ms/step - loss: 2.2102 - acc: 0.2711 - val_loss: 2.7794 - val_acc: 0.1746\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 80s 878ms/step - loss: 2.1838 - acc: 0.2711 - val_loss: 2.7618 - val_acc: 0.1724\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.2145 - acc: 0.2683 - val_loss: 2.7498 - val_acc: 0.1810\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.2257 - acc: 0.2789 - val_loss: 2.7863 - val_acc: 0.1789\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 80s 874ms/step - loss: 2.2216 - acc: 0.2569 - val_loss: 2.7775 - val_acc: 0.1918\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.2532 - acc: 0.2676 - val_loss: 2.7770 - val_acc: 0.1853\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 75s 825ms/step - loss: 2.2369 - acc: 0.2463 - val_loss: 2.7428 - val_acc: 0.1897\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 80s 878ms/step - loss: 2.2367 - acc: 0.2683 - val_loss: 2.7939 - val_acc: 0.1832\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1928 - acc: 0.2839 - val_loss: 2.7720 - val_acc: 0.1832\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.2524 - acc: 0.2548 - val_loss: 2.7839 - val_acc: 0.1853\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 80s 883ms/step - loss: 2.2088 - acc: 0.2590 - val_loss: 2.7702 - val_acc: 0.1875\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1886 - acc: 0.2782 - val_loss: 2.7592 - val_acc: 0.1940\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1955 - acc: 0.2647 - val_loss: 2.7826 - val_acc: 0.1853\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 80s 879ms/step - loss: 2.2297 - acc: 0.2534 - val_loss: 2.7790 - val_acc: 0.1832\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.2187 - acc: 0.2761 - val_loss: 2.7551 - val_acc: 0.1832\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2152 - acc: 0.2569 - val_loss: 2.7568 - val_acc: 0.1918\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 80s 879ms/step - loss: 2.1740 - acc: 0.2768 - val_loss: 2.7543 - val_acc: 0.1918\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.2110 - acc: 0.2598 - val_loss: 2.7941 - val_acc: 0.1810\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 76s 832ms/step - loss: 2.2264 - acc: 0.2725 - val_loss: 2.7766 - val_acc: 0.1853\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2226 - acc: 0.2683 - val_loss: 2.7603 - val_acc: 0.1875\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.1897 - acc: 0.2661 - val_loss: 2.7775 - val_acc: 0.1918\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.2118 - acc: 0.2697 - val_loss: 2.7634 - val_acc: 0.1810\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 81s 895ms/step - loss: 2.2278 - acc: 0.2590 - val_loss: 2.7524 - val_acc: 0.1767\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.2090 - acc: 0.2583 - val_loss: 2.7416 - val_acc: 0.1853\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.2224 - acc: 0.2555 - val_loss: 2.7391 - val_acc: 0.1897\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 80s 883ms/step - loss: 2.2237 - acc: 0.2711 - val_loss: 2.7323 - val_acc: 0.1832\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.2120 - acc: 0.2555 - val_loss: 2.7362 - val_acc: 0.1810\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.2337 - acc: 0.2612 - val_loss: 2.7318 - val_acc: 0.1897\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 80s 883ms/step - loss: 2.2071 - acc: 0.2505 - val_loss: 2.7429 - val_acc: 0.1897\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 76s 859ms/step - loss: 2.2190 - acc: 0.2640 - val_loss: 2.7389 - val_acc: 0.1875\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.1859 - acc: 0.2711 - val_loss: 2.7247 - val_acc: 0.1918\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 81s 888ms/step - loss: 2.1482 - acc: 0.2676 - val_loss: 2.7502 - val_acc: 0.1875\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.2232 - acc: 0.2449 - val_loss: 2.7609 - val_acc: 0.1918\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1922 - acc: 0.2711 - val_loss: 2.7399 - val_acc: 0.1897\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 81s 887ms/step - loss: 2.2166 - acc: 0.2569 - val_loss: 2.7609 - val_acc: 0.1810\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1916 - acc: 0.2754 - val_loss: 2.7435 - val_acc: 0.1875\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.2026 - acc: 0.2811 - val_loss: 2.7838 - val_acc: 0.1832\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 80s 882ms/step - loss: 2.1625 - acc: 0.2747 - val_loss: 2.7756 - val_acc: 0.1810\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 75s 824ms/step - loss: 2.2101 - acc: 0.2661 - val_loss: 2.7259 - val_acc: 0.1897\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1956 - acc: 0.2598 - val_loss: 2.7919 - val_acc: 0.1810\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 80s 881ms/step - loss: 2.1630 - acc: 0.2711 - val_loss: 2.8107 - val_acc: 0.1832\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1786 - acc: 0.2697 - val_loss: 2.7745 - val_acc: 0.1746\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.2231 - acc: 0.2498 - val_loss: 2.7851 - val_acc: 0.1918\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2123 - acc: 0.2534 - val_loss: 2.7648 - val_acc: 0.1897\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.1788 - acc: 0.2796 - val_loss: 2.7610 - val_acc: 0.1853\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 77s 840ms/step - loss: 2.2199 - acc: 0.2711 - val_loss: 2.7719 - val_acc: 0.1853\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 81s 894ms/step - loss: 2.1751 - acc: 0.2789 - val_loss: 2.7738 - val_acc: 0.1832\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 83s 907ms/step - loss: 2.2117 - acc: 0.2654 - val_loss: 2.7560 - val_acc: 0.1875\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 84s 928ms/step - loss: 2.1643 - acc: 0.2789 - val_loss: 2.7487 - val_acc: 0.1832\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 76s 827ms/step - loss: 2.1898 - acc: 0.2740 - val_loss: 2.7882 - val_acc: 0.1746\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 80s 873ms/step - loss: 2.2195 - acc: 0.2711 - val_loss: 2.7779 - val_acc: 0.1724\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.1806 - acc: 0.2775 - val_loss: 2.7781 - val_acc: 0.1746\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1929 - acc: 0.2725 - val_loss: 2.7528 - val_acc: 0.1832\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 80s 881ms/step - loss: 2.2022 - acc: 0.2669 - val_loss: 2.7363 - val_acc: 0.1832\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 76s 837ms/step - loss: 2.1566 - acc: 0.2803 - val_loss: 2.7683 - val_acc: 0.1746\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 76s 834ms/step - loss: 2.1480 - acc: 0.2803 - val_loss: 2.7871 - val_acc: 0.1767\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 79s 873ms/step - loss: 2.1667 - acc: 0.2896 - val_loss: 2.7353 - val_acc: 0.1918\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 77s 826ms/step - loss: 2.1892 - acc: 0.2697 - val_loss: 2.7492 - val_acc: 0.1897\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 75s 826ms/step - loss: 2.2358 - acc: 0.2520 - val_loss: 2.7680 - val_acc: 0.1832\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 75s 819ms/step - loss: 2.1809 - acc: 0.2740 - val_loss: 2.7638 - val_acc: 0.1810\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 78s 831ms/step - loss: 2.1664 - acc: 0.2761 - val_loss: 2.7629 - val_acc: 0.1918\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.2120 - acc: 0.2583 - val_loss: 2.7464 - val_acc: 0.1961\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1882 - acc: 0.2846 - val_loss: 2.7785 - val_acc: 0.1918\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 81s 885ms/step - loss: 2.1489 - acc: 0.2832 - val_loss: 2.7831 - val_acc: 0.1853\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 75s 827ms/step - loss: 2.1823 - acc: 0.2647 - val_loss: 2.7912 - val_acc: 0.1832\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 76s 828ms/step - loss: 2.1958 - acc: 0.2477 - val_loss: 2.7763 - val_acc: 0.1918\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 80s 882ms/step - loss: 2.2127 - acc: 0.2576 - val_loss: 2.7789 - val_acc: 0.1832\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.1999 - acc: 0.2569 - val_loss: 2.7746 - val_acc: 0.1940\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 76s 829ms/step - loss: 2.2216 - acc: 0.2661 - val_loss: 2.7840 - val_acc: 0.1853\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 80s 880ms/step - loss: 2.2130 - acc: 0.2732 - val_loss: 2.7459 - val_acc: 0.1940\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 75s 828ms/step - loss: 2.1941 - acc: 0.2541 - val_loss: 2.7784 - val_acc: 0.1703\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 77s 845ms/step - loss: 2.1466 - acc: 0.2860 - val_loss: 2.7369 - val_acc: 0.1767\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 82s 901ms/step - loss: 2.2120 - acc: 0.2725 - val_loss: 2.7641 - val_acc: 0.1810\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.2182 - acc: 0.2590 - val_loss: 2.7478 - val_acc: 0.1810\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 76s 830ms/step - loss: 2.1798 - acc: 0.2619 - val_loss: 2.7593 - val_acc: 0.1853\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 80s 884ms/step - loss: 2.1853 - acc: 0.2576 - val_loss: 2.7683 - val_acc: 0.1789\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 76s 831ms/step - loss: 2.2283 - acc: 0.2548 - val_loss: 2.7737 - val_acc: 0.1810\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 76s 836ms/step - loss: 2.2152 - acc: 0.2583 - val_loss: 2.7855 - val_acc: 0.1767\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 81s 885ms/step - loss: 2.1889 - acc: 0.2768 - val_loss: 2.7872 - val_acc: 0.1832\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 76s 835ms/step - loss: 2.1803 - acc: 0.2747 - val_loss: 2.7780 - val_acc: 0.1789\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 76s 833ms/step - loss: 2.1790 - acc: 0.2598 - val_loss: 2.7592 - val_acc: 0.1918\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 80s 881ms/step - loss: 2.1914 - acc: 0.2683 - val_loss: 2.7701 - val_acc: 0.1810\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kwylTJpTP5XI",
        "outputId": "e082c605-22c8-4272-ac0c-4e960cb74970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc)) \n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD-vKaoHQAFd"
      },
      "source": [
        "#Download the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "74dL7-HLP_Sh"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/44_รอบที่4_Flimpano_Female125_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qcPW-brHQDpc",
        "outputId": "d570ccfb-fc78-417f-c016-fe23945bce91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dde6a9e7-2642-4255-a54b-1e68ec1c3c0e\", \"44_\\u0e23\\u0e2d\\u0e1a\\u0e17\\u0e35\\u0e484_Flimpano_Female125_250.h5\", 16780032)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/My Drive/cut_panoramic/Model/44_รอบที่4_Flimpano_Female125_250.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}