{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/New_1M_MAE_dataframe_Male_500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "91d789ff-6a39-4643-8ecf-42d75f064ec4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 500\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "3952028d-ceea-4982-a1c2-97eba3866b7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 779, done.\u001b[K\n",
            "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 779 (delta 219), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (779/779), 13.20 MiB | 13.60 MiB/s, done.\n",
            "Resolving deltas: 100% (459/459), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "fd9e6e90-20fa-40f6-b267-55a6afb65fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "13aa2484-f941-4798-97a5-a33a02108916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "16911564-0ace-462c-8d1c-05e692312fd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "15f7be04-85aa-4d89-916a-924705525c26"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Male125.csv')\n",
        "DATA_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "f75fd2fa-82ee-46da-fb39-e2525975e9d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07M         0       VV03.jpg   \n",
              "1           2               1          7  Y07M         0  Flip_VV03.jpg   \n",
              "2           3               2          7  Y07M         0       VV04.jpg   \n",
              "3           4               2          7  Y07M         0  Flip_VV04.jpg   \n",
              "4           5               3          7  Y07M         0       VV05.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "2370      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "2371      122              78         25  Y25M        18       J464.jpg   \n",
              "2372      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "2373      124              79         25  Y25M        18       J465.jpg   \n",
              "2374      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "1     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "2     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "3     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "4     /content/drive/My Drive/TVT_Male125/train/Y07M...  เพศชาย   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "2370  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2371  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2372  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2373  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "2374  /content/drive/My Drive/TVT_Male125/test/Y25M/...  เพศชาย   Both  \n",
              "\n",
              "[2375 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ea75652-c192-4fea-8f02-1a89cc6e6a65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV03.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_VV04.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07M</td>\n",
              "      <td>0</td>\n",
              "      <td>VV05.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/train/Y07M...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Male125/test/Y25M/...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ea75652-c192-4fea-8f02-1a89cc6e6a65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ea75652-c192-4fea-8f02-1a89cc6e6a65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ea75652-c192-4fea-8f02-1a89cc6e6a65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = DATA_PATH[DATA_PATH['Fig_Age'].between(1,75)]\n",
        "val = DATA_PATH[DATA_PATH['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Male125\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "334ed496-64b2-45f3-dfdb-cfa70f4f9242"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Male125/train\n",
            "/content/drive/My Drive/TVT_Male125/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "737b3571-e095-4bbc-cc99-994586f43ba6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 validated image filenames.\n",
            "Found 475 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(lr=2e-6),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "c92cb43d-ae58-480e-cffc-f655dca2e43a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "<ipython-input-26-90b2ae0efec2>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 413s 4s/step - loss: 111.4251 - mae: 9.0349 - val_loss: 110.5777 - val_mae: 9.0000\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 111.1731 - mae: 9.0195 - val_loss: 110.5392 - val_mae: 8.9734\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 110.4449 - mae: 8.9673 - val_loss: 109.1081 - val_mae: 8.9051\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 110.3509 - mae: 8.9653 - val_loss: 109.9071 - val_mae: 8.9496\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 109.4274 - mae: 8.9179 - val_loss: 108.7717 - val_mae: 8.8704\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 109.2046 - mae: 8.9196 - val_loss: 109.2980 - val_mae: 8.9191\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 108.4615 - mae: 8.8695 - val_loss: 107.5438 - val_mae: 8.8320\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 107.1231 - mae: 8.8035 - val_loss: 107.5454 - val_mae: 8.8148\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 107.5031 - mae: 8.8315 - val_loss: 107.0718 - val_mae: 8.8003\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 19s 211ms/step - loss: 106.9012 - mae: 8.7971 - val_loss: 106.3849 - val_mae: 8.7729\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 106.3714 - mae: 8.7619 - val_loss: 104.6805 - val_mae: 8.6752\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 106.0788 - mae: 8.7496 - val_loss: 104.6749 - val_mae: 8.6655\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 19s 211ms/step - loss: 105.1078 - mae: 8.7015 - val_loss: 104.9936 - val_mae: 8.6967\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 105.1658 - mae: 8.6979 - val_loss: 105.6154 - val_mae: 8.7512\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 104.5037 - mae: 8.6687 - val_loss: 105.1997 - val_mae: 8.7137\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 104.1914 - mae: 8.6513 - val_loss: 102.5544 - val_mae: 8.5656\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 19s 199ms/step - loss: 104.2677 - mae: 8.6599 - val_loss: 103.8996 - val_mae: 8.6355\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 103.5896 - mae: 8.6193 - val_loss: 102.7803 - val_mae: 8.5856\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 103.8068 - mae: 8.6292 - val_loss: 102.1595 - val_mae: 8.5561\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 103.6305 - mae: 8.6221 - val_loss: 102.6245 - val_mae: 8.5673\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 103.1274 - mae: 8.5936 - val_loss: 102.1655 - val_mae: 8.5639\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 103.2467 - mae: 8.6035 - val_loss: 102.3617 - val_mae: 8.5746\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 103.4256 - mae: 8.6058 - val_loss: 102.0501 - val_mae: 8.5405\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 103.1659 - mae: 8.5995 - val_loss: 101.9822 - val_mae: 8.5261\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 103.1384 - mae: 8.5953 - val_loss: 102.6758 - val_mae: 8.5704\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 103.2119 - mae: 8.6064 - val_loss: 101.7288 - val_mae: 8.5414\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 19s 208ms/step - loss: 102.9192 - mae: 8.5820 - val_loss: 103.8619 - val_mae: 8.6313\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 103.5914 - mae: 8.6261 - val_loss: 102.7393 - val_mae: 8.5900\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 103.0754 - mae: 8.5950 - val_loss: 102.8042 - val_mae: 8.5856\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 102.9229 - mae: 8.5876 - val_loss: 102.9319 - val_mae: 8.5747\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 102.8824 - mae: 8.5906 - val_loss: 101.6931 - val_mae: 8.5274\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 102.5795 - mae: 8.5688 - val_loss: 102.1548 - val_mae: 8.5276\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 102.6361 - mae: 8.5708 - val_loss: 103.0507 - val_mae: 8.5905\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 102.7743 - mae: 8.5716 - val_loss: 101.8039 - val_mae: 8.5070\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 102.4609 - mae: 8.5631 - val_loss: 101.2544 - val_mae: 8.4968\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 102.3703 - mae: 8.5608 - val_loss: 102.4702 - val_mae: 8.5645\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 102.4946 - mae: 8.5691 - val_loss: 101.3807 - val_mae: 8.5069\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 102.2419 - mae: 8.5474 - val_loss: 102.5895 - val_mae: 8.5770\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 102.3636 - mae: 8.5578 - val_loss: 102.3435 - val_mae: 8.5564\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 102.2652 - mae: 8.5538 - val_loss: 100.7446 - val_mae: 8.4607\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 102.7291 - mae: 8.5765 - val_loss: 100.4576 - val_mae: 8.4511\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 102.0369 - mae: 8.5431 - val_loss: 101.0895 - val_mae: 8.5149\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 102.5572 - mae: 8.5658 - val_loss: 100.9087 - val_mae: 8.4991\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 102.3102 - mae: 8.5545 - val_loss: 102.0053 - val_mae: 8.5350\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 102.2047 - mae: 8.5464 - val_loss: 102.4599 - val_mae: 8.5666\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 102.1115 - mae: 8.5517 - val_loss: 103.3902 - val_mae: 8.6155\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 102.0807 - mae: 8.5419 - val_loss: 101.0303 - val_mae: 8.4900\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 102.0094 - mae: 8.5388 - val_loss: 102.5333 - val_mae: 8.5735\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 102.3696 - mae: 8.5569 - val_loss: 102.3904 - val_mae: 8.5643\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 17s 187ms/step - loss: 102.1255 - mae: 8.5447 - val_loss: 100.4504 - val_mae: 8.4476\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 102.2437 - mae: 8.5464 - val_loss: 101.2322 - val_mae: 8.5074\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.9865 - mae: 8.5456 - val_loss: 101.9496 - val_mae: 8.5543\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 101.9822 - mae: 8.5350 - val_loss: 102.8496 - val_mae: 8.5862\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 102.1682 - mae: 8.5503 - val_loss: 101.5001 - val_mae: 8.5191\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 102.0107 - mae: 8.5350 - val_loss: 102.4030 - val_mae: 8.5854\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.8318 - mae: 8.5366 - val_loss: 102.3101 - val_mae: 8.5655\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 101.6616 - mae: 8.5235 - val_loss: 101.0307 - val_mae: 8.4964\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.9666 - mae: 8.5388 - val_loss: 102.5065 - val_mae: 8.5757\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 101.8822 - mae: 8.5324 - val_loss: 102.1080 - val_mae: 8.5647\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 102.0258 - mae: 8.5415 - val_loss: 102.1882 - val_mae: 8.5471\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 19s 208ms/step - loss: 101.5519 - mae: 8.5134 - val_loss: 101.5536 - val_mae: 8.5208\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 102.1663 - mae: 8.5497 - val_loss: 101.2901 - val_mae: 8.4859\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 102.3793 - mae: 8.5611 - val_loss: 101.9052 - val_mae: 8.5459\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 101.5754 - mae: 8.5188 - val_loss: 100.8809 - val_mae: 8.4810\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.8093 - mae: 8.5258 - val_loss: 101.4251 - val_mae: 8.5001\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 101.8441 - mae: 8.5251 - val_loss: 102.8485 - val_mae: 8.5923\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.6078 - mae: 8.5163 - val_loss: 103.2245 - val_mae: 8.6091\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 101.6951 - mae: 8.5297 - val_loss: 101.0527 - val_mae: 8.4968\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.6516 - mae: 8.5226 - val_loss: 101.7596 - val_mae: 8.5307\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.6910 - mae: 8.5262 - val_loss: 101.8879 - val_mae: 8.5198\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 101.7709 - mae: 8.5279 - val_loss: 102.3072 - val_mae: 8.5412\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 102.2041 - mae: 8.5431 - val_loss: 101.8706 - val_mae: 8.5301\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.7213 - mae: 8.5215 - val_loss: 102.7800 - val_mae: 8.5707\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.6840 - mae: 8.5186 - val_loss: 101.0157 - val_mae: 8.4927\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 101.7192 - mae: 8.5310 - val_loss: 101.3966 - val_mae: 8.5076\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 102.1927 - mae: 8.5506 - val_loss: 101.7826 - val_mae: 8.5049\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 101.9269 - mae: 8.5315 - val_loss: 101.5403 - val_mae: 8.4961\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 101.7524 - mae: 8.5254 - val_loss: 100.5969 - val_mae: 8.4613\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 19s 199ms/step - loss: 101.7148 - mae: 8.5308 - val_loss: 101.4663 - val_mae: 8.5171\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.9834 - mae: 8.5379 - val_loss: 101.6064 - val_mae: 8.5209\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.6689 - mae: 8.5136 - val_loss: 100.7682 - val_mae: 8.4647\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 101.3761 - mae: 8.5077 - val_loss: 101.1052 - val_mae: 8.4902\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 102.0676 - mae: 8.5492 - val_loss: 101.8976 - val_mae: 8.5350\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.9824 - mae: 8.5417 - val_loss: 101.5401 - val_mae: 8.5067\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 101.7044 - mae: 8.5265 - val_loss: 101.9459 - val_mae: 8.5367\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.3162 - mae: 8.5032 - val_loss: 102.8106 - val_mae: 8.5923\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.3448 - mae: 8.5092 - val_loss: 102.0877 - val_mae: 8.5508\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 101.1938 - mae: 8.5039 - val_loss: 101.7213 - val_mae: 8.5314\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.9317 - mae: 8.5441 - val_loss: 101.3378 - val_mae: 8.5053\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.3401 - mae: 8.5102 - val_loss: 102.3788 - val_mae: 8.5674\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 101.5867 - mae: 8.5185 - val_loss: 100.9484 - val_mae: 8.4809\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.7260 - mae: 8.5224 - val_loss: 101.8580 - val_mae: 8.5129\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 18s 189ms/step - loss: 102.1961 - mae: 8.5553 - val_loss: 101.5628 - val_mae: 8.5146\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.7804 - mae: 8.5325 - val_loss: 102.1832 - val_mae: 8.5486\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 101.5836 - mae: 8.5156 - val_loss: 101.7998 - val_mae: 8.5292\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.4664 - mae: 8.5033 - val_loss: 102.5109 - val_mae: 8.5634\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.7039 - mae: 8.5270 - val_loss: 102.0407 - val_mae: 8.5435\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 102.0552 - mae: 8.5409 - val_loss: 102.3785 - val_mae: 8.5561\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.6326 - mae: 8.5171 - val_loss: 102.8799 - val_mae: 8.5732\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.8951 - mae: 8.5366 - val_loss: 102.1424 - val_mae: 8.5532\n",
            "Epoch 101/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 101.7394 - mae: 8.5320 - val_loss: 101.4840 - val_mae: 8.5228\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 101.8042 - mae: 8.5347 - val_loss: 101.8644 - val_mae: 8.5421\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.0087 - mae: 8.4938 - val_loss: 101.4712 - val_mae: 8.5262\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 101.4612 - mae: 8.5112 - val_loss: 101.9474 - val_mae: 8.5370\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.4388 - mae: 8.5116 - val_loss: 102.3587 - val_mae: 8.5476\n",
            "Epoch 106/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.4671 - mae: 8.5134 - val_loss: 101.4083 - val_mae: 8.5042\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.5811 - mae: 8.5116 - val_loss: 102.0762 - val_mae: 8.5315\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 101.7435 - mae: 8.5268 - val_loss: 102.0836 - val_mae: 8.5316\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.6333 - mae: 8.5216 - val_loss: 101.8726 - val_mae: 8.5570\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.3360 - mae: 8.5022 - val_loss: 101.7273 - val_mae: 8.5243\n",
            "Epoch 111/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.5021 - mae: 8.5110 - val_loss: 102.1810 - val_mae: 8.5436\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 101.3662 - mae: 8.5114 - val_loss: 101.1539 - val_mae: 8.4892\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.6296 - mae: 8.5174 - val_loss: 102.1090 - val_mae: 8.5386\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.4545 - mae: 8.5085 - val_loss: 101.7732 - val_mae: 8.5168\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 101.1695 - mae: 8.4962 - val_loss: 102.2413 - val_mae: 8.5568\n",
            "Epoch 116/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.4816 - mae: 8.5072 - val_loss: 100.8864 - val_mae: 8.4685\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.7320 - mae: 8.4728 - val_loss: 101.6377 - val_mae: 8.5309\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 101.6129 - mae: 8.5186 - val_loss: 101.0575 - val_mae: 8.4961\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 101.0490 - mae: 8.4892 - val_loss: 102.0174 - val_mae: 8.5368\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 18s 188ms/step - loss: 101.1749 - mae: 8.4938 - val_loss: 101.0701 - val_mae: 8.5082\n",
            "Epoch 121/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 101.4373 - mae: 8.5027 - val_loss: 101.9714 - val_mae: 8.5340\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.7793 - mae: 8.4826 - val_loss: 100.6777 - val_mae: 8.4776\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.7273 - mae: 8.5206 - val_loss: 100.4067 - val_mae: 8.4534\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.2830 - mae: 8.5004 - val_loss: 101.6494 - val_mae: 8.5137\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 101.7909 - mae: 8.5292 - val_loss: 101.2461 - val_mae: 8.4789\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 101.5287 - mae: 8.5119 - val_loss: 100.9119 - val_mae: 8.4826\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.9023 - mae: 8.4909 - val_loss: 100.3018 - val_mae: 8.4479\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 101.4831 - mae: 8.5153 - val_loss: 100.9816 - val_mae: 8.4863\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 101.6835 - mae: 8.5145 - val_loss: 101.4044 - val_mae: 8.5099\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.7106 - mae: 8.5212 - val_loss: 101.9310 - val_mae: 8.5290\n",
            "Epoch 131/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 101.1421 - mae: 8.4931 - val_loss: 102.2892 - val_mae: 8.5503\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 18s 188ms/step - loss: 101.6842 - mae: 8.5311 - val_loss: 101.7971 - val_mae: 8.5390\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.5507 - mae: 8.5215 - val_loss: 101.0978 - val_mae: 8.4936\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.9091 - mae: 8.4837 - val_loss: 100.5156 - val_mae: 8.4416\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 101.6132 - mae: 8.5225 - val_loss: 101.2454 - val_mae: 8.4930\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.2021 - mae: 8.4972 - val_loss: 100.8705 - val_mae: 8.4776\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 100.9424 - mae: 8.4835 - val_loss: 100.7455 - val_mae: 8.4622\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 101.4020 - mae: 8.5073 - val_loss: 101.4507 - val_mae: 8.5392\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.3187 - mae: 8.5049 - val_loss: 100.5829 - val_mae: 8.4616\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.7057 - mae: 8.5286 - val_loss: 101.5366 - val_mae: 8.5127\n",
            "Epoch 141/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 101.7653 - mae: 8.5277 - val_loss: 101.1140 - val_mae: 8.4995\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.7069 - mae: 8.5273 - val_loss: 101.1062 - val_mae: 8.4776\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.1905 - mae: 8.4943 - val_loss: 100.7844 - val_mae: 8.4517\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.9303 - mae: 8.4820 - val_loss: 101.7885 - val_mae: 8.5160\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 100.8256 - mae: 8.4767 - val_loss: 101.8753 - val_mae: 8.5306\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.1920 - mae: 8.4983 - val_loss: 101.0097 - val_mae: 8.4745\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 101.3381 - mae: 8.5044 - val_loss: 102.3478 - val_mae: 8.5560\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.1955 - mae: 8.5010 - val_loss: 100.0717 - val_mae: 8.4329\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 101.8855 - mae: 8.5307 - val_loss: 101.3214 - val_mae: 8.4951\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 101.1413 - mae: 8.4964 - val_loss: 101.0533 - val_mae: 8.4883\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 101.3803 - mae: 8.5110 - val_loss: 102.8493 - val_mae: 8.5909\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.2169 - mae: 8.4993 - val_loss: 100.6584 - val_mae: 8.4833\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 100.9108 - mae: 8.4883 - val_loss: 101.7165 - val_mae: 8.5216\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.7054 - mae: 8.4746 - val_loss: 101.3507 - val_mae: 8.5064\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.1426 - mae: 8.4955 - val_loss: 101.7599 - val_mae: 8.5274\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 100.9962 - mae: 8.4804 - val_loss: 101.4533 - val_mae: 8.5209\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.7888 - mae: 8.4792 - val_loss: 100.6592 - val_mae: 8.4796\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.2964 - mae: 8.5060 - val_loss: 101.7468 - val_mae: 8.5197\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 100.8251 - mae: 8.4800 - val_loss: 102.4599 - val_mae: 8.5628\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.8358 - mae: 8.4795 - val_loss: 99.9958 - val_mae: 8.4377\n",
            "Epoch 161/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.3238 - mae: 8.5042 - val_loss: 101.3907 - val_mae: 8.5064\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 101.1116 - mae: 8.4968 - val_loss: 101.4742 - val_mae: 8.5098\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.9964 - mae: 8.4852 - val_loss: 100.9367 - val_mae: 8.4907\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.9997 - mae: 8.4906 - val_loss: 101.0564 - val_mae: 8.4861\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 101.4797 - mae: 8.5178 - val_loss: 101.0554 - val_mae: 8.4814\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 101.2222 - mae: 8.4983 - val_loss: 102.5815 - val_mae: 8.5673\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.2708 - mae: 8.5051 - val_loss: 101.6857 - val_mae: 8.5153\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 100.9829 - mae: 8.4900 - val_loss: 101.9229 - val_mae: 8.5344\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 101.3696 - mae: 8.5060 - val_loss: 101.0853 - val_mae: 8.4971\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 101.1665 - mae: 8.4951 - val_loss: 100.9478 - val_mae: 8.4842\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.1804 - mae: 8.4934 - val_loss: 100.7973 - val_mae: 8.4688\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 101.1861 - mae: 8.5014 - val_loss: 100.6667 - val_mae: 8.4639\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.7990 - mae: 8.4757 - val_loss: 101.4142 - val_mae: 8.5048\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.7803 - mae: 8.4754 - val_loss: 101.5852 - val_mae: 8.5298\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.3772 - mae: 8.5091 - val_loss: 100.9657 - val_mae: 8.4826\n",
            "Epoch 176/500\n",
            "89/89 [==============================] - 20s 213ms/step - loss: 100.9982 - mae: 8.4868 - val_loss: 101.5540 - val_mae: 8.5189\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 101.6441 - mae: 8.5163 - val_loss: 101.2306 - val_mae: 8.5030\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.7744 - mae: 8.4699 - val_loss: 101.5245 - val_mae: 8.4903\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 100.9199 - mae: 8.4845 - val_loss: 100.1873 - val_mae: 8.4232\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.3414 - mae: 8.5026 - val_loss: 100.8878 - val_mae: 8.4574\n",
            "Epoch 181/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.5657 - mae: 8.5283 - val_loss: 99.7966 - val_mae: 8.4179\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 18s 203ms/step - loss: 100.9695 - mae: 8.4870 - val_loss: 100.2674 - val_mae: 8.4330\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.5802 - mae: 8.4698 - val_loss: 101.0402 - val_mae: 8.4737\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.1919 - mae: 8.4971 - val_loss: 99.9373 - val_mae: 8.4281\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 100.2732 - mae: 8.4471 - val_loss: 101.4071 - val_mae: 8.5075\n",
            "Epoch 186/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.2251 - mae: 8.4962 - val_loss: 102.4651 - val_mae: 8.5694\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.0669 - mae: 8.4912 - val_loss: 100.6509 - val_mae: 8.4681\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 100.8016 - mae: 8.4780 - val_loss: 100.5116 - val_mae: 8.4656\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 101.0774 - mae: 8.4926 - val_loss: 101.7313 - val_mae: 8.5149\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.4454 - mae: 8.4555 - val_loss: 100.3564 - val_mae: 8.4434\n",
            "Epoch 191/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 100.8455 - mae: 8.4819 - val_loss: 101.3512 - val_mae: 8.4970\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.4355 - mae: 8.5122 - val_loss: 100.5076 - val_mae: 8.4748\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.3171 - mae: 8.5140 - val_loss: 100.7159 - val_mae: 8.4551\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 100.7862 - mae: 8.4755 - val_loss: 100.9097 - val_mae: 8.4742\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.4251 - mae: 8.4497 - val_loss: 100.7914 - val_mae: 8.4785\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.7403 - mae: 8.4649 - val_loss: 100.1889 - val_mae: 8.4330\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 20s 217ms/step - loss: 100.8152 - mae: 8.4753 - val_loss: 100.0999 - val_mae: 8.4413\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.9029 - mae: 8.4832 - val_loss: 101.4625 - val_mae: 8.5121\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 101.3450 - mae: 8.5065 - val_loss: 102.2646 - val_mae: 8.5549\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 101.2596 - mae: 8.5037 - val_loss: 100.6064 - val_mae: 8.4511\n",
            "Epoch 201/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.7492 - mae: 8.4817 - val_loss: 100.9049 - val_mae: 8.4871\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.2434 - mae: 8.5047 - val_loss: 101.0738 - val_mae: 8.4742\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 100.9775 - mae: 8.4889 - val_loss: 101.6305 - val_mae: 8.5148\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.2431 - mae: 8.5042 - val_loss: 100.1880 - val_mae: 8.4366\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.3799 - mae: 8.5083 - val_loss: 101.5201 - val_mae: 8.5354\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.4658 - mae: 8.4603 - val_loss: 99.7225 - val_mae: 8.4191\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 100.7198 - mae: 8.4693 - val_loss: 100.5209 - val_mae: 8.4575\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 17s 188ms/step - loss: 100.6938 - mae: 8.4704 - val_loss: 100.1884 - val_mae: 8.4483\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 101.0812 - mae: 8.4938 - val_loss: 101.0782 - val_mae: 8.4828\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 100.7181 - mae: 8.4655 - val_loss: 101.1898 - val_mae: 8.4994\n",
            "Epoch 211/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.5297 - mae: 8.4524 - val_loss: 100.2990 - val_mae: 8.4538\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.5602 - mae: 8.4642 - val_loss: 100.3764 - val_mae: 8.4448\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.6541 - mae: 8.4695 - val_loss: 100.8433 - val_mae: 8.4790\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 19s 198ms/step - loss: 100.3673 - mae: 8.4584 - val_loss: 101.7582 - val_mae: 8.5412\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.0115 - mae: 8.4843 - val_loss: 100.8825 - val_mae: 8.4852\n",
            "Epoch 216/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 101.0517 - mae: 8.4960 - val_loss: 100.3550 - val_mae: 8.4590\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 101.1585 - mae: 8.4937 - val_loss: 101.6373 - val_mae: 8.5381\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.9484 - mae: 8.4835 - val_loss: 99.5501 - val_mae: 8.4067\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.1164 - mae: 8.4951 - val_loss: 100.4666 - val_mae: 8.4581\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 100.7605 - mae: 8.4751 - val_loss: 100.1709 - val_mae: 8.4384\n",
            "Epoch 221/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.9031 - mae: 8.4827 - val_loss: 100.8579 - val_mae: 8.4937\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.4267 - mae: 8.4483 - val_loss: 100.0708 - val_mae: 8.4248\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 100.3265 - mae: 8.4514 - val_loss: 101.2796 - val_mae: 8.5064\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.6452 - mae: 8.4710 - val_loss: 100.9153 - val_mae: 8.4820\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.9349 - mae: 8.4847 - val_loss: 101.6643 - val_mae: 8.5266\n",
            "Epoch 226/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 100.5781 - mae: 8.4627 - val_loss: 101.3607 - val_mae: 8.5051\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.4761 - mae: 8.4594 - val_loss: 100.1436 - val_mae: 8.4319\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.5236 - mae: 8.4557 - val_loss: 100.8956 - val_mae: 8.4592\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 100.4272 - mae: 8.4524 - val_loss: 100.3534 - val_mae: 8.4463\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 100.5743 - mae: 8.4613 - val_loss: 100.5773 - val_mae: 8.4633\n",
            "Epoch 231/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.7176 - mae: 8.4696 - val_loss: 99.0152 - val_mae: 8.3897\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 100.8287 - mae: 8.4736 - val_loss: 101.3153 - val_mae: 8.5097\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.9732 - mae: 8.4887 - val_loss: 100.8457 - val_mae: 8.4774\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 101.1249 - mae: 8.4962 - val_loss: 100.5862 - val_mae: 8.4677\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.0390 - mae: 8.4833 - val_loss: 100.2369 - val_mae: 8.4402\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - 20s 211ms/step - loss: 100.3555 - mae: 8.4460 - val_loss: 99.8822 - val_mae: 8.4140\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 101.0363 - mae: 8.5017 - val_loss: 100.6369 - val_mae: 8.4503\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.9223 - mae: 8.4873 - val_loss: 100.9803 - val_mae: 8.4949\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 100.4074 - mae: 8.4522 - val_loss: 100.0343 - val_mae: 8.4467\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.9904 - mae: 8.4890 - val_loss: 100.2783 - val_mae: 8.4490\n",
            "Epoch 241/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.2106 - mae: 8.4466 - val_loss: 100.1338 - val_mae: 8.4504\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 100.9759 - mae: 8.4832 - val_loss: 101.2537 - val_mae: 8.4958\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.5904 - mae: 8.4683 - val_loss: 100.4582 - val_mae: 8.4523\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 101.0637 - mae: 8.4959 - val_loss: 100.5514 - val_mae: 8.4732\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 100.8935 - mae: 8.4857 - val_loss: 100.7677 - val_mae: 8.4650\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.9669 - mae: 8.4869 - val_loss: 100.4238 - val_mae: 8.4518\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.9549 - mae: 8.4886 - val_loss: 101.4177 - val_mae: 8.5175\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 100.5262 - mae: 8.4649 - val_loss: 99.7080 - val_mae: 8.4361\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.6828 - mae: 8.4681 - val_loss: 99.8522 - val_mae: 8.4375\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.1518 - mae: 8.4444 - val_loss: 101.1547 - val_mae: 8.4932\n",
            "Epoch 251/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 100.7602 - mae: 8.4689 - val_loss: 100.2740 - val_mae: 8.4265\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 101.0467 - mae: 8.4835 - val_loss: 100.7724 - val_mae: 8.4715\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.3664 - mae: 8.4478 - val_loss: 99.9256 - val_mae: 8.4281\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.3158 - mae: 8.4518 - val_loss: 99.4188 - val_mae: 8.4079\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 100.4290 - mae: 8.4522 - val_loss: 99.8519 - val_mae: 8.4335\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.0990 - mae: 8.4382 - val_loss: 100.3302 - val_mae: 8.4508\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.2462 - mae: 8.4464 - val_loss: 101.8499 - val_mae: 8.5410\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 100.9246 - mae: 8.4877 - val_loss: 99.5565 - val_mae: 8.4006\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.5733 - mae: 8.4637 - val_loss: 100.3156 - val_mae: 8.4564\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.6894 - mae: 8.4696 - val_loss: 101.0102 - val_mae: 8.4858\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.7714 - mae: 8.4700 - val_loss: 101.0247 - val_mae: 8.4919\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 20s 205ms/step - loss: 100.2260 - mae: 8.4422 - val_loss: 101.1744 - val_mae: 8.5084\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.2956 - mae: 8.4474 - val_loss: 100.1722 - val_mae: 8.4508\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.5918 - mae: 8.4635 - val_loss: 99.5745 - val_mae: 8.4328\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 100.6664 - mae: 8.4716 - val_loss: 99.3530 - val_mae: 8.3920\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.7882 - mae: 8.4713 - val_loss: 100.7313 - val_mae: 8.4542\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.5426 - mae: 8.4569 - val_loss: 101.4552 - val_mae: 8.5095\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 19s 208ms/step - loss: 100.7589 - mae: 8.4735 - val_loss: 100.1575 - val_mae: 8.4380\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.7611 - mae: 8.4746 - val_loss: 99.3486 - val_mae: 8.4011\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.1610 - mae: 8.4429 - val_loss: 100.6272 - val_mae: 8.4680\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 100.5058 - mae: 8.4585 - val_loss: 99.9865 - val_mae: 8.4311\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.4608 - mae: 8.4600 - val_loss: 99.4101 - val_mae: 8.3963\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.9087 - mae: 8.4840 - val_loss: 99.4877 - val_mae: 8.4089\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.4371 - mae: 8.4622 - val_loss: 100.2611 - val_mae: 8.4318\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 100.2499 - mae: 8.4409 - val_loss: 99.6276 - val_mae: 8.4229\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.8908 - mae: 8.4704 - val_loss: 99.4125 - val_mae: 8.3950\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.1239 - mae: 8.4367 - val_loss: 99.3917 - val_mae: 8.3839\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 100.4216 - mae: 8.4577 - val_loss: 101.1251 - val_mae: 8.4978\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 100.6722 - mae: 8.4666 - val_loss: 100.5172 - val_mae: 8.4669\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.9221 - mae: 8.4784 - val_loss: 101.2679 - val_mae: 8.4994\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 100.1679 - mae: 8.4383 - val_loss: 99.4520 - val_mae: 8.4150\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 100.3344 - mae: 8.4487 - val_loss: 99.6531 - val_mae: 8.4147\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.3834 - mae: 8.4505 - val_loss: 100.9094 - val_mae: 8.4764\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.3000 - mae: 8.4409 - val_loss: 100.2395 - val_mae: 8.4567\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 20s 211ms/step - loss: 100.3409 - mae: 8.4469 - val_loss: 100.2536 - val_mae: 8.4461\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.4459 - mae: 8.4522 - val_loss: 101.6390 - val_mae: 8.5487\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.4529 - mae: 8.4521 - val_loss: 99.9299 - val_mae: 8.4325\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 100.6459 - mae: 8.4637 - val_loss: 100.3682 - val_mae: 8.4516\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.6072 - mae: 8.4641 - val_loss: 101.5410 - val_mae: 8.5172\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.4004 - mae: 8.4483 - val_loss: 99.7624 - val_mae: 8.4246\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 100.6754 - mae: 8.4677 - val_loss: 100.0846 - val_mae: 8.4416\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 99.8130 - mae: 8.4186 - val_loss: 101.1068 - val_mae: 8.4882\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.4117 - mae: 8.4571 - val_loss: 99.6862 - val_mae: 8.3983\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 19s 208ms/step - loss: 100.3753 - mae: 8.4588 - val_loss: 99.7738 - val_mae: 8.4212\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.3401 - mae: 8.4572 - val_loss: 98.7933 - val_mae: 8.3675\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.3066 - mae: 8.4414 - val_loss: 100.1910 - val_mae: 8.4508\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.5296 - mae: 8.4587 - val_loss: 99.8034 - val_mae: 8.4057\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 99.9970 - mae: 8.4336 - val_loss: 100.7727 - val_mae: 8.4954\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.5596 - mae: 8.4625 - val_loss: 99.4760 - val_mae: 8.4067\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 100.2544 - mae: 8.4423 - val_loss: 100.3767 - val_mae: 8.4581\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 18s 190ms/step - loss: 100.1414 - mae: 8.4431 - val_loss: 101.0719 - val_mae: 8.4863\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.3965 - mae: 8.4563 - val_loss: 99.3335 - val_mae: 8.4084\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.3544 - mae: 8.4485 - val_loss: 100.8849 - val_mae: 8.4792\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 100.7862 - mae: 8.4755 - val_loss: 99.4962 - val_mae: 8.3992\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.4136 - mae: 8.4534 - val_loss: 100.3924 - val_mae: 8.4506\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.6189 - mae: 8.4674 - val_loss: 99.2195 - val_mae: 8.4072\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 100.0540 - mae: 8.4344 - val_loss: 100.7732 - val_mae: 8.4672\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.6742 - mae: 8.4710 - val_loss: 100.4938 - val_mae: 8.4561\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.2718 - mae: 8.4471 - val_loss: 100.5559 - val_mae: 8.4601\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 100.6162 - mae: 8.4603 - val_loss: 98.8552 - val_mae: 8.3693\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.2903 - mae: 8.4499 - val_loss: 100.9700 - val_mae: 8.5004\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 18s 192ms/step - loss: 100.3599 - mae: 8.4527 - val_loss: 99.5874 - val_mae: 8.4307\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.1056 - mae: 8.4422 - val_loss: 100.4123 - val_mae: 8.4567\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 20s 214ms/step - loss: 100.5774 - mae: 8.4592 - val_loss: 100.2747 - val_mae: 8.4478\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 100.3914 - mae: 8.4582 - val_loss: 99.7397 - val_mae: 8.4065\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 100.5203 - mae: 8.4634 - val_loss: 100.5222 - val_mae: 8.4450\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 20s 213ms/step - loss: 100.2686 - mae: 8.4405 - val_loss: 101.2471 - val_mae: 8.4899\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 100.6027 - mae: 8.4606 - val_loss: 100.6514 - val_mae: 8.4654\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 100.0831 - mae: 8.4307 - val_loss: 99.7558 - val_mae: 8.4203\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 19s 211ms/step - loss: 100.5301 - mae: 8.4593 - val_loss: 100.7287 - val_mae: 8.4739\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.3124 - mae: 8.4492 - val_loss: 100.9016 - val_mae: 8.4822\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 99.9275 - mae: 8.4303 - val_loss: 100.3150 - val_mae: 8.4383\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 100.1370 - mae: 8.4435 - val_loss: 100.3839 - val_mae: 8.4655\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.9454 - mae: 8.4856 - val_loss: 100.6721 - val_mae: 8.4662\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 99.7537 - mae: 8.4189 - val_loss: 101.2662 - val_mae: 8.4955\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 100.2845 - mae: 8.4497 - val_loss: 99.9375 - val_mae: 8.4246\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 100.2799 - mae: 8.4472 - val_loss: 100.8291 - val_mae: 8.4739\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.1036 - mae: 8.4357 - val_loss: 99.5791 - val_mae: 8.3960\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 100.3367 - mae: 8.4501 - val_loss: 99.4213 - val_mae: 8.4000\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.6074 - mae: 8.4682 - val_loss: 99.9010 - val_mae: 8.4234\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 99.7851 - mae: 8.4177 - val_loss: 99.8408 - val_mae: 8.4166\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 99.7070 - mae: 8.4167 - val_loss: 99.5365 - val_mae: 8.4179\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 100.5256 - mae: 8.4574 - val_loss: 100.1698 - val_mae: 8.4478\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.1637 - mae: 8.4386 - val_loss: 100.1418 - val_mae: 8.4324\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 18s 202ms/step - loss: 99.8351 - mae: 8.4275 - val_loss: 99.3298 - val_mae: 8.4003\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 99.8323 - mae: 8.4264 - val_loss: 99.7205 - val_mae: 8.4172\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 99.8031 - mae: 8.4242 - val_loss: 100.5531 - val_mae: 8.4600\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 99.8640 - mae: 8.4239 - val_loss: 100.9303 - val_mae: 8.4909\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 99.6724 - mae: 8.4228 - val_loss: 101.0936 - val_mae: 8.5181\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.0553 - mae: 8.4298 - val_loss: 99.2883 - val_mae: 8.3793\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 100.1642 - mae: 8.4415 - val_loss: 99.9974 - val_mae: 8.4156\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 19s 199ms/step - loss: 99.9047 - mae: 8.4316 - val_loss: 100.1654 - val_mae: 8.4525\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.2794 - mae: 8.4438 - val_loss: 101.0149 - val_mae: 8.5007\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.5684 - mae: 8.4658 - val_loss: 101.1076 - val_mae: 8.4998\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 20s 211ms/step - loss: 100.1175 - mae: 8.4399 - val_loss: 100.5029 - val_mae: 8.4505\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 99.6527 - mae: 8.4102 - val_loss: 100.1059 - val_mae: 8.4458\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.0544 - mae: 8.4359 - val_loss: 99.8592 - val_mae: 8.4261\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 19s 207ms/step - loss: 100.3864 - mae: 8.4576 - val_loss: 100.0662 - val_mae: 8.4221\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.1248 - mae: 8.4426 - val_loss: 99.2070 - val_mae: 8.4018\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 99.9838 - mae: 8.4323 - val_loss: 99.4086 - val_mae: 8.4020\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.3571 - mae: 8.4556 - val_loss: 100.2074 - val_mae: 8.4405\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.2490 - mae: 8.4464 - val_loss: 99.9077 - val_mae: 8.4515\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 99.6314 - mae: 8.4232 - val_loss: 100.8387 - val_mae: 8.4673\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 99.7877 - mae: 8.4224 - val_loss: 99.2634 - val_mae: 8.4024\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 18s 191ms/step - loss: 99.7119 - mae: 8.4128 - val_loss: 100.3319 - val_mae: 8.4473\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 99.9228 - mae: 8.4312 - val_loss: 99.3862 - val_mae: 8.3851\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 100.4645 - mae: 8.4486 - val_loss: 100.3613 - val_mae: 8.4408\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 100.3263 - mae: 8.4497 - val_loss: 100.0333 - val_mae: 8.4334\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.5663 - mae: 8.4722 - val_loss: 100.3881 - val_mae: 8.4547\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 20s 213ms/step - loss: 99.8094 - mae: 8.4205 - val_loss: 99.2537 - val_mae: 8.4054\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 100.0149 - mae: 8.4315 - val_loss: 100.5531 - val_mae: 8.4809\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 99.9553 - mae: 8.4346 - val_loss: 99.5443 - val_mae: 8.4026\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 100.4194 - mae: 8.4605 - val_loss: 100.4600 - val_mae: 8.4540\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.3388 - mae: 8.4483 - val_loss: 99.8210 - val_mae: 8.4192\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 99.6551 - mae: 8.4180 - val_loss: 100.3619 - val_mae: 8.4534\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 100.0081 - mae: 8.4365 - val_loss: 100.0799 - val_mae: 8.4380\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 100.1610 - mae: 8.4410 - val_loss: 100.9166 - val_mae: 8.4937\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 18s 193ms/step - loss: 99.7173 - mae: 8.4222 - val_loss: 101.0652 - val_mae: 8.4805\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 100.2046 - mae: 8.4443 - val_loss: 100.6601 - val_mae: 8.4737\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 99.8405 - mae: 8.4266 - val_loss: 99.4236 - val_mae: 8.4022\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 18s 196ms/step - loss: 99.8798 - mae: 8.4261 - val_loss: 99.8198 - val_mae: 8.3976\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 100.0011 - mae: 8.4354 - val_loss: 99.9233 - val_mae: 8.4232\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 100.3755 - mae: 8.4595 - val_loss: 98.9120 - val_mae: 8.3797\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.7213 - mae: 8.4184 - val_loss: 99.7459 - val_mae: 8.4139\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 100.0767 - mae: 8.4397 - val_loss: 101.1269 - val_mae: 8.4804\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 100.1509 - mae: 8.4497 - val_loss: 99.5013 - val_mae: 8.3982\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 99.6256 - mae: 8.4182 - val_loss: 99.8090 - val_mae: 8.4022\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 100.0153 - mae: 8.4340 - val_loss: 99.7406 - val_mae: 8.4256\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 99.9335 - mae: 8.4365 - val_loss: 100.0932 - val_mae: 8.4231\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 18s 194ms/step - loss: 99.9349 - mae: 8.4265 - val_loss: 99.6962 - val_mae: 8.4034\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 100.3884 - mae: 8.4642 - val_loss: 100.4307 - val_mae: 8.4527\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 19s 196ms/step - loss: 99.6230 - mae: 8.4122 - val_loss: 99.4013 - val_mae: 8.4136\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 18s 195ms/step - loss: 99.5101 - mae: 8.4000 - val_loss: 99.8605 - val_mae: 8.4305\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.7450 - mae: 8.4109 - val_loss: 100.0684 - val_mae: 8.4339\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 100.3884 - mae: 8.4498 - val_loss: 100.3697 - val_mae: 8.4471\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 18s 205ms/step - loss: 99.7570 - mae: 8.4225 - val_loss: 100.3232 - val_mae: 8.4354\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 99.6893 - mae: 8.4191 - val_loss: 100.1831 - val_mae: 8.4250\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.7117 - mae: 8.4146 - val_loss: 100.7629 - val_mae: 8.4844\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.9060 - mae: 8.4242 - val_loss: 99.9712 - val_mae: 8.4129\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 99.4235 - mae: 8.4075 - val_loss: 99.8827 - val_mae: 8.4148\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.7642 - mae: 8.4174 - val_loss: 100.4896 - val_mae: 8.4548\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 100.2336 - mae: 8.4476 - val_loss: 99.7042 - val_mae: 8.4222\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 100.1953 - mae: 8.4456 - val_loss: 100.4501 - val_mae: 8.4634\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.6150 - mae: 8.4051 - val_loss: 100.1161 - val_mae: 8.4379\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.7571 - mae: 8.4205 - val_loss: 98.7940 - val_mae: 8.3535\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 20s 214ms/step - loss: 99.3654 - mae: 8.4073 - val_loss: 99.0743 - val_mae: 8.4015\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.8649 - mae: 8.4259 - val_loss: 100.0898 - val_mae: 8.4369\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.4486 - mae: 8.4123 - val_loss: 100.1400 - val_mae: 8.4215\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 99.8261 - mae: 8.4262 - val_loss: 99.3844 - val_mae: 8.3910\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 19s 218ms/step - loss: 100.0129 - mae: 8.4323 - val_loss: 101.2781 - val_mae: 8.4985\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 100.3056 - mae: 8.4562 - val_loss: 100.0079 - val_mae: 8.4292\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 19s 199ms/step - loss: 99.5126 - mae: 8.4073 - val_loss: 100.0639 - val_mae: 8.4470\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.5559 - mae: 8.4042 - val_loss: 100.0779 - val_mae: 8.4409\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 20s 212ms/step - loss: 100.1152 - mae: 8.4415 - val_loss: 100.3569 - val_mae: 8.4535\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.7467 - mae: 8.4192 - val_loss: 99.9269 - val_mae: 8.4390\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 99.6577 - mae: 8.4034 - val_loss: 99.6401 - val_mae: 8.4061\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 99.8344 - mae: 8.4244 - val_loss: 99.0349 - val_mae: 8.3777\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.8876 - mae: 8.4287 - val_loss: 99.2482 - val_mae: 8.3796\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.4707 - mae: 8.3997 - val_loss: 98.1932 - val_mae: 8.3275\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 21s 225ms/step - loss: 99.7336 - mae: 8.4204 - val_loss: 100.0785 - val_mae: 8.4402\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 100.1905 - mae: 8.4494 - val_loss: 99.9173 - val_mae: 8.4146\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.8465 - mae: 8.4214 - val_loss: 99.6743 - val_mae: 8.4143\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 99.8670 - mae: 8.4264 - val_loss: 99.1358 - val_mae: 8.3823\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.1325 - mae: 8.3825 - val_loss: 100.6636 - val_mae: 8.4648\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.7012 - mae: 8.4245 - val_loss: 99.3832 - val_mae: 8.3946\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 20s 213ms/step - loss: 99.8283 - mae: 8.4256 - val_loss: 100.2535 - val_mae: 8.4331\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.3305 - mae: 8.3946 - val_loss: 99.6515 - val_mae: 8.4091\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.9948 - mae: 8.4321 - val_loss: 100.0270 - val_mae: 8.4275\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 20s 214ms/step - loss: 99.5172 - mae: 8.4055 - val_loss: 99.3596 - val_mae: 8.4028\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.6731 - mae: 8.4147 - val_loss: 101.1254 - val_mae: 8.4922\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.8361 - mae: 8.4283 - val_loss: 100.8144 - val_mae: 8.4718\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 100.0794 - mae: 8.4384 - val_loss: 99.5918 - val_mae: 8.4170\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 98.7144 - mae: 8.3598 - val_loss: 99.2210 - val_mae: 8.3900\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 99.9334 - mae: 8.4314 - val_loss: 99.7190 - val_mae: 8.4328\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.3280 - mae: 8.3890 - val_loss: 100.3688 - val_mae: 8.4555\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.6015 - mae: 8.4078 - val_loss: 100.3223 - val_mae: 8.4365\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 99.3726 - mae: 8.3971 - val_loss: 100.3888 - val_mae: 8.4635\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.7909 - mae: 8.4295 - val_loss: 99.7863 - val_mae: 8.4164\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.5364 - mae: 8.4090 - val_loss: 98.5839 - val_mae: 8.3558\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 20s 212ms/step - loss: 99.1517 - mae: 8.3860 - val_loss: 101.1449 - val_mae: 8.4970\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.4398 - mae: 8.4034 - val_loss: 100.4046 - val_mae: 8.4443\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.7918 - mae: 8.4242 - val_loss: 98.9082 - val_mae: 8.3786\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.5025 - mae: 8.4071 - val_loss: 99.0791 - val_mae: 8.3754\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 99.5182 - mae: 8.4113 - val_loss: 98.7128 - val_mae: 8.3837\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 99.2495 - mae: 8.4022 - val_loss: 99.8725 - val_mae: 8.4487\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 99.7485 - mae: 8.4229 - val_loss: 99.6528 - val_mae: 8.4132\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 99.2865 - mae: 8.3987 - val_loss: 100.0198 - val_mae: 8.4093\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 20s 216ms/step - loss: 99.8057 - mae: 8.4211 - val_loss: 100.0314 - val_mae: 8.4349\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.3584 - mae: 8.4021 - val_loss: 98.6930 - val_mae: 8.3699\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.5434 - mae: 8.4122 - val_loss: 100.3922 - val_mae: 8.4558\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 20s 219ms/step - loss: 99.5178 - mae: 8.4046 - val_loss: 100.4986 - val_mae: 8.4656\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 99.8177 - mae: 8.4281 - val_loss: 99.7729 - val_mae: 8.4142\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 19s 200ms/step - loss: 100.0799 - mae: 8.4380 - val_loss: 99.5883 - val_mae: 8.4175\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 99.7115 - mae: 8.4202 - val_loss: 99.8133 - val_mae: 8.4495\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 99.4739 - mae: 8.4045 - val_loss: 100.4432 - val_mae: 8.4456\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 18s 202ms/step - loss: 99.2924 - mae: 8.3909 - val_loss: 99.3135 - val_mae: 8.3993\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 99.9067 - mae: 8.4304 - val_loss: 99.5648 - val_mae: 8.4062\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.4001 - mae: 8.3936 - val_loss: 99.4585 - val_mae: 8.4073\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 19s 206ms/step - loss: 99.7084 - mae: 8.4139 - val_loss: 99.6257 - val_mae: 8.4077\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.0848 - mae: 8.3805 - val_loss: 98.9006 - val_mae: 8.3535\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.8315 - mae: 8.4227 - val_loss: 99.1047 - val_mae: 8.3935\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 100.0667 - mae: 8.4349 - val_loss: 99.3222 - val_mae: 8.3982\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.6002 - mae: 8.4112 - val_loss: 99.1160 - val_mae: 8.4043\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 98.8992 - mae: 8.3806 - val_loss: 99.0857 - val_mae: 8.3738\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 99.4009 - mae: 8.4037 - val_loss: 99.3551 - val_mae: 8.3987\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 99.0861 - mae: 8.3840 - val_loss: 97.5727 - val_mae: 8.2999\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 99.8213 - mae: 8.4230 - val_loss: 99.1452 - val_mae: 8.3851\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 99.3869 - mae: 8.4007 - val_loss: 100.5222 - val_mae: 8.4545\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 19s 200ms/step - loss: 99.3745 - mae: 8.3980 - val_loss: 100.2957 - val_mae: 8.4664\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.1662 - mae: 8.3910 - val_loss: 98.7268 - val_mae: 8.3583\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 20s 215ms/step - loss: 99.0250 - mae: 8.3803 - val_loss: 98.1614 - val_mae: 8.3458\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.5892 - mae: 8.4145 - val_loss: 99.9161 - val_mae: 8.4266\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.5152 - mae: 8.4100 - val_loss: 100.2175 - val_mae: 8.4608\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 20s 216ms/step - loss: 99.2615 - mae: 8.3888 - val_loss: 99.9984 - val_mae: 8.4282\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 18s 202ms/step - loss: 99.7799 - mae: 8.4280 - val_loss: 98.4284 - val_mae: 8.3402\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.1263 - mae: 8.3925 - val_loss: 99.3446 - val_mae: 8.3887\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 20s 210ms/step - loss: 99.3423 - mae: 8.3993 - val_loss: 98.6301 - val_mae: 8.3461\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 98.9587 - mae: 8.3705 - val_loss: 99.0091 - val_mae: 8.3903\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 99.4469 - mae: 8.4026 - val_loss: 98.3413 - val_mae: 8.3497\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.4746 - mae: 8.4028 - val_loss: 98.8567 - val_mae: 8.3753\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.7132 - mae: 8.4214 - val_loss: 98.7934 - val_mae: 8.3764\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 99.8094 - mae: 8.4185 - val_loss: 99.6996 - val_mae: 8.4091\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 18s 200ms/step - loss: 99.4078 - mae: 8.4004 - val_loss: 99.2748 - val_mae: 8.4081\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.6343 - mae: 8.4145 - val_loss: 99.5683 - val_mae: 8.4272\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 99.5554 - mae: 8.4112 - val_loss: 99.0504 - val_mae: 8.3651\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.2176 - mae: 8.3948 - val_loss: 99.4392 - val_mae: 8.3950\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.2809 - mae: 8.4018 - val_loss: 99.2664 - val_mae: 8.3666\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 20s 218ms/step - loss: 99.3519 - mae: 8.3958 - val_loss: 98.5560 - val_mae: 8.3569\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.9308 - mae: 8.4272 - val_loss: 99.1926 - val_mae: 8.3933\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.2600 - mae: 8.3921 - val_loss: 99.6153 - val_mae: 8.4124\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 19s 200ms/step - loss: 99.4184 - mae: 8.4043 - val_loss: 99.7127 - val_mae: 8.4250\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.3523 - mae: 8.4019 - val_loss: 99.5354 - val_mae: 8.4125\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 20s 229ms/step - loss: 99.7300 - mae: 8.4139 - val_loss: 100.3656 - val_mae: 8.4588\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.1268 - mae: 8.3946 - val_loss: 99.9365 - val_mae: 8.4269\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 99.5595 - mae: 8.4106 - val_loss: 100.0166 - val_mae: 8.4366\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 99.0154 - mae: 8.3843 - val_loss: 97.9364 - val_mae: 8.3178\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 19s 201ms/step - loss: 99.1557 - mae: 8.3892 - val_loss: 99.9418 - val_mae: 8.4346\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 98.9192 - mae: 8.3789 - val_loss: 100.5464 - val_mae: 8.4753\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 99.6704 - mae: 8.4134 - val_loss: 99.5174 - val_mae: 8.4131\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 98.8552 - mae: 8.3750 - val_loss: 99.1642 - val_mae: 8.3747\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 99.1038 - mae: 8.3818 - val_loss: 99.7585 - val_mae: 8.4197\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 99.2986 - mae: 8.3921 - val_loss: 99.6009 - val_mae: 8.3978\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 19s 204ms/step - loss: 99.7052 - mae: 8.4154 - val_loss: 98.9785 - val_mae: 8.3530\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 20s 221ms/step - loss: 99.0333 - mae: 8.3745 - val_loss: 98.9398 - val_mae: 8.3692\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 99.5689 - mae: 8.4141 - val_loss: 99.7721 - val_mae: 8.4149\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 19s 205ms/step - loss: 98.9129 - mae: 8.3724 - val_loss: 99.8765 - val_mae: 8.4497\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 19s 202ms/step - loss: 98.9902 - mae: 8.3700 - val_loss: 98.5565 - val_mae: 8.3582\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 98.9312 - mae: 8.3754 - val_loss: 99.2663 - val_mae: 8.4024\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 21s 226ms/step - loss: 99.7767 - mae: 8.4204 - val_loss: 98.7384 - val_mae: 8.3676\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 19s 203ms/step - loss: 98.8777 - mae: 8.3691 - val_loss: 98.4349 - val_mae: 8.3565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'co', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'co', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "ae96bbef-ed32-4341-b80f-6c6131ee476c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "c00f7fd0-d17e-471b-872f-ffe9353c3c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/OK_New_MAE_Flimpano_Male18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}