{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%881_Train_Gender_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow7eWoNw6U-c"
      },
      "source": [
        "#เรียกใช้ CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1_2Fe8u81d5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509c3277-456d-496e-bb3a-a7aefe0a4799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fbd34479-9d3f-47aa-a88e-a07d7d3df034"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         0         V1.jpg   \n",
              "1           2               1          7  Y07F         0    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         0         V2.jpg   \n",
              "3           4               2          7  Y07F         0    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25  Y25M         1  Flip_J463.jpg   \n",
              "4746      122              78         25  Y25M         1       J464.jpg   \n",
              "4747      123              78         25  Y25M         1  Flip_J464.jpg   \n",
              "4748      124              79         25  Y25M         1       J465.jpg   \n",
              "4749      125              79         25  Y25M         1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d33afaa-880b-4db0-97d0-0c9fa90fd0e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d33afaa-880b-4db0-97d0-0c9fa90fd0e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d33afaa-880b-4db0-97d0-0c9fa90fd0e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d33afaa-880b-4db0-97d0-0c9fa90fd0e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Gender.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxePnnn7TGW"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RooqSdBc7QHC"
      },
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pumGmy6f3eSW"
      },
      "source": [
        "#Clone efficientnet repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "f6e87583-393f-4076-89dd-c7f96b3c3403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 831, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 831 (delta 249), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (831/831), 13.73 MiB | 9.09 MiB/s, done.\n",
            "Resolving deltas: 100% (489/489), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "outputs": [],
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uhCmH24AKmQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0242238a-64b0-46d3-d985-6025f93d012c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadBB12251jh",
        "outputId": "83f3c75d-856c-4975-8aaf-714a973d766a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GepWq3yy53t5",
        "outputId": "47cc9b61-9a51-4c2d-e023-677e16d74d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIWHby0gKpEq",
        "outputId": "53d578e8-682f-4a90-8b25-cac03b3f5f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary() #ดู Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J36J9EAE7qSB"
      },
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Gender'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWEnlTSwazL5"
      },
      "source": [
        "\n",
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPrsn9no_pa",
        "outputId": "f4419a16-10a2-449a-ce9f-688991946143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 images belonging to 2 classes.\n",
            "Found 950 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6qUmmF856ZE",
        "outputId": "4c42dac1-6e3b-4ea1-bc7c-75e9745c5327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-95ae5648fc7b>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 322s 2s/step - loss: 1.1816 - acc: 0.5212 - val_loss: 1.1258 - val_acc: 0.5064\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 41s 225ms/step - loss: 1.0522 - acc: 0.5201 - val_loss: 1.0969 - val_acc: 0.5095\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 1.0246 - acc: 0.5423 - val_loss: 1.0594 - val_acc: 0.5074\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 1.0426 - acc: 0.5233 - val_loss: 0.9833 - val_acc: 0.5180\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 47s 263ms/step - loss: 1.0505 - acc: 0.5187 - val_loss: 0.9219 - val_acc: 0.5222\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 41s 224ms/step - loss: 1.0406 - acc: 0.5268 - val_loss: 0.8914 - val_acc: 0.5254\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 1.0197 - acc: 0.5226 - val_loss: 0.9025 - val_acc: 0.5275\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 1.0185 - acc: 0.5286 - val_loss: 0.9043 - val_acc: 0.5318\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 1.0026 - acc: 0.5307 - val_loss: 0.8360 - val_acc: 0.5275\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.9886 - acc: 0.5205 - val_loss: 0.8531 - val_acc: 0.5371\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.9726 - acc: 0.5335 - val_loss: 0.8776 - val_acc: 0.5286\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 45s 244ms/step - loss: 0.9686 - acc: 0.5367 - val_loss: 0.8399 - val_acc: 0.5424\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.9507 - acc: 0.5335 - val_loss: 0.8328 - val_acc: 0.5424\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.9901 - acc: 0.5328 - val_loss: 0.7751 - val_acc: 0.5625\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.9689 - acc: 0.5367 - val_loss: 0.7891 - val_acc: 0.5583\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.9586 - acc: 0.5254 - val_loss: 0.8210 - val_acc: 0.5498\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.9609 - acc: 0.5360 - val_loss: 0.7823 - val_acc: 0.5604\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.9299 - acc: 0.5409 - val_loss: 0.7837 - val_acc: 0.5519\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.9579 - acc: 0.5254 - val_loss: 0.7571 - val_acc: 0.5678\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.9309 - acc: 0.5452 - val_loss: 0.7376 - val_acc: 0.5816\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.9306 - acc: 0.5505 - val_loss: 0.7459 - val_acc: 0.5720\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.8885 - acc: 0.5462 - val_loss: 0.7448 - val_acc: 0.5731\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.9028 - acc: 0.5452 - val_loss: 0.7388 - val_acc: 0.5773\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 0.8869 - acc: 0.5593 - val_loss: 0.7135 - val_acc: 0.6017\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.9093 - acc: 0.5561 - val_loss: 0.7406 - val_acc: 0.5773\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.8924 - acc: 0.5536 - val_loss: 0.7070 - val_acc: 0.5996\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.8693 - acc: 0.5635 - val_loss: 0.7328 - val_acc: 0.5837\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 48s 264ms/step - loss: 0.9061 - acc: 0.5466 - val_loss: 0.6980 - val_acc: 0.6070\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.9063 - acc: 0.5476 - val_loss: 0.6960 - val_acc: 0.6081\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.9312 - acc: 0.5378 - val_loss: 0.7002 - val_acc: 0.6070\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.8910 - acc: 0.5434 - val_loss: 0.6954 - val_acc: 0.6123\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 45s 245ms/step - loss: 0.8746 - acc: 0.5649 - val_loss: 0.6861 - val_acc: 0.6133\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 44s 238ms/step - loss: 0.8840 - acc: 0.5441 - val_loss: 0.6762 - val_acc: 0.6186\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 0.8719 - acc: 0.5600 - val_loss: 0.6838 - val_acc: 0.6155\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.8447 - acc: 0.5663 - val_loss: 0.6986 - val_acc: 0.6017\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.8433 - acc: 0.5685 - val_loss: 0.6997 - val_acc: 0.5975\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.8668 - acc: 0.5579 - val_loss: 0.6774 - val_acc: 0.6250\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.8415 - acc: 0.5653 - val_loss: 0.6874 - val_acc: 0.6144\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 45s 244ms/step - loss: 0.8524 - acc: 0.5522 - val_loss: 0.6753 - val_acc: 0.6250\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.8338 - acc: 0.5639 - val_loss: 0.6913 - val_acc: 0.6123\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.8185 - acc: 0.5674 - val_loss: 0.6677 - val_acc: 0.6261\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.8011 - acc: 0.5836 - val_loss: 0.6575 - val_acc: 0.6250\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 0.8112 - acc: 0.5737 - val_loss: 0.6534 - val_acc: 0.6261\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.8060 - acc: 0.5706 - val_loss: 0.6783 - val_acc: 0.6218\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.8169 - acc: 0.5836 - val_loss: 0.6420 - val_acc: 0.6303\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.8060 - acc: 0.5903 - val_loss: 0.6451 - val_acc: 0.6335\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7872 - acc: 0.5829 - val_loss: 0.6439 - val_acc: 0.6271\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.7960 - acc: 0.5861 - val_loss: 0.6395 - val_acc: 0.6356\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.8381 - acc: 0.5607 - val_loss: 0.6464 - val_acc: 0.6345\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.8170 - acc: 0.5755 - val_loss: 0.6444 - val_acc: 0.6345\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.8226 - acc: 0.5797 - val_loss: 0.6587 - val_acc: 0.6303\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.8002 - acc: 0.5748 - val_loss: 0.6431 - val_acc: 0.6335\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.7885 - acc: 0.5826 - val_loss: 0.6434 - val_acc: 0.6335\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 47s 257ms/step - loss: 0.7945 - acc: 0.5843 - val_loss: 0.6429 - val_acc: 0.6356\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.7853 - acc: 0.5928 - val_loss: 0.6356 - val_acc: 0.6377\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 0.8069 - acc: 0.5723 - val_loss: 0.6263 - val_acc: 0.6494\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.7981 - acc: 0.5737 - val_loss: 0.6428 - val_acc: 0.6335\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7908 - acc: 0.5720 - val_loss: 0.6302 - val_acc: 0.6419\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.7826 - acc: 0.5857 - val_loss: 0.6228 - val_acc: 0.6494\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7681 - acc: 0.5977 - val_loss: 0.6394 - val_acc: 0.6419\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 47s 254ms/step - loss: 0.7948 - acc: 0.5759 - val_loss: 0.6196 - val_acc: 0.6600\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.7774 - acc: 0.5857 - val_loss: 0.6216 - val_acc: 0.6547\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.7652 - acc: 0.5921 - val_loss: 0.6199 - val_acc: 0.6557\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.7684 - acc: 0.5889 - val_loss: 0.6138 - val_acc: 0.6695\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.7953 - acc: 0.5653 - val_loss: 0.6220 - val_acc: 0.6504\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.7891 - acc: 0.5836 - val_loss: 0.6100 - val_acc: 0.6706\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 0.7679 - acc: 0.5879 - val_loss: 0.6087 - val_acc: 0.6663\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 47s 264ms/step - loss: 0.7834 - acc: 0.5670 - val_loss: 0.6072 - val_acc: 0.6663\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7471 - acc: 0.5935 - val_loss: 0.6046 - val_acc: 0.6886\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.7585 - acc: 0.5932 - val_loss: 0.6030 - val_acc: 0.6833\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 51s 283ms/step - loss: 0.7658 - acc: 0.5903 - val_loss: 0.6031 - val_acc: 0.6727\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.7483 - acc: 0.5995 - val_loss: 0.6009 - val_acc: 0.6695\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.7524 - acc: 0.5900 - val_loss: 0.6081 - val_acc: 0.6642\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.7305 - acc: 0.5879 - val_loss: 0.6020 - val_acc: 0.6716\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 0.7424 - acc: 0.6037 - val_loss: 0.5986 - val_acc: 0.6727\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7434 - acc: 0.5992 - val_loss: 0.5973 - val_acc: 0.6758\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7366 - acc: 0.5981 - val_loss: 0.5971 - val_acc: 0.6727\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.7366 - acc: 0.5974 - val_loss: 0.5949 - val_acc: 0.6939\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 0.7526 - acc: 0.5949 - val_loss: 0.5911 - val_acc: 0.6875\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.7464 - acc: 0.5984 - val_loss: 0.5921 - val_acc: 0.6960\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.7215 - acc: 0.6122 - val_loss: 0.5859 - val_acc: 0.6981\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.7311 - acc: 0.6059 - val_loss: 0.5866 - val_acc: 0.6949\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.7481 - acc: 0.5999 - val_loss: 0.5906 - val_acc: 0.6939\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.7204 - acc: 0.6101 - val_loss: 0.5865 - val_acc: 0.6970\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.7123 - acc: 0.6087 - val_loss: 0.5841 - val_acc: 0.6970\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.7266 - acc: 0.6062 - val_loss: 0.5825 - val_acc: 0.6992\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.7256 - acc: 0.6041 - val_loss: 0.5882 - val_acc: 0.7002\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.7139 - acc: 0.6203 - val_loss: 0.5873 - val_acc: 0.6949\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.7368 - acc: 0.6027 - val_loss: 0.5942 - val_acc: 0.6896\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 45s 244ms/step - loss: 0.7192 - acc: 0.5988 - val_loss: 0.5901 - val_acc: 0.6917\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.7159 - acc: 0.6055 - val_loss: 0.5872 - val_acc: 0.6907\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.7235 - acc: 0.6048 - val_loss: 0.5849 - val_acc: 0.6960\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 47s 263ms/step - loss: 0.7183 - acc: 0.6087 - val_loss: 0.5832 - val_acc: 0.7044\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6877 - acc: 0.6274 - val_loss: 0.5804 - val_acc: 0.7034\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6822 - acc: 0.6450 - val_loss: 0.5793 - val_acc: 0.7034\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.7258 - acc: 0.6023 - val_loss: 0.5812 - val_acc: 0.7044\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.6957 - acc: 0.6309 - val_loss: 0.5776 - val_acc: 0.7066\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6956 - acc: 0.6221 - val_loss: 0.5775 - val_acc: 0.7129\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.7077 - acc: 0.6200 - val_loss: 0.5795 - val_acc: 0.7034\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6985 - acc: 0.6168 - val_loss: 0.5830 - val_acc: 0.6970\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.7031 - acc: 0.6217 - val_loss: 0.5813 - val_acc: 0.7023\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7070 - acc: 0.6157 - val_loss: 0.5774 - val_acc: 0.7034\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.7050 - acc: 0.6083 - val_loss: 0.5760 - val_acc: 0.7002\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 0.6906 - acc: 0.6291 - val_loss: 0.5769 - val_acc: 0.6981\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 0.7015 - acc: 0.6133 - val_loss: 0.5745 - val_acc: 0.7066\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.6978 - acc: 0.6168 - val_loss: 0.5713 - val_acc: 0.7214\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.7068 - acc: 0.6179 - val_loss: 0.5726 - val_acc: 0.7119\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6948 - acc: 0.6203 - val_loss: 0.5714 - val_acc: 0.7034\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6857 - acc: 0.6231 - val_loss: 0.5699 - val_acc: 0.7119\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 45s 245ms/step - loss: 0.7070 - acc: 0.6062 - val_loss: 0.5684 - val_acc: 0.7182\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.6878 - acc: 0.6221 - val_loss: 0.5690 - val_acc: 0.7193\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6990 - acc: 0.6154 - val_loss: 0.5723 - val_acc: 0.7108\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 47s 261ms/step - loss: 0.6923 - acc: 0.6119 - val_loss: 0.5689 - val_acc: 0.7193\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6789 - acc: 0.6359 - val_loss: 0.5659 - val_acc: 0.7225\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 45s 243ms/step - loss: 0.6941 - acc: 0.6108 - val_loss: 0.5703 - val_acc: 0.7172\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 47s 262ms/step - loss: 0.6663 - acc: 0.6394 - val_loss: 0.5689 - val_acc: 0.7214\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6623 - acc: 0.6390 - val_loss: 0.5672 - val_acc: 0.7172\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6789 - acc: 0.6231 - val_loss: 0.5777 - val_acc: 0.6960\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 41s 227ms/step - loss: 0.6829 - acc: 0.6221 - val_loss: 0.5646 - val_acc: 0.7225\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 47s 253ms/step - loss: 0.6628 - acc: 0.6284 - val_loss: 0.5654 - val_acc: 0.7214\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6892 - acc: 0.6196 - val_loss: 0.5688 - val_acc: 0.7023\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6791 - acc: 0.6313 - val_loss: 0.5656 - val_acc: 0.7256\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 0.6599 - acc: 0.6397 - val_loss: 0.5709 - val_acc: 0.7108\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.6838 - acc: 0.6115 - val_loss: 0.5611 - val_acc: 0.7267\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6760 - acc: 0.6306 - val_loss: 0.5628 - val_acc: 0.7214\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6790 - acc: 0.6284 - val_loss: 0.5648 - val_acc: 0.7288\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6673 - acc: 0.6246 - val_loss: 0.5684 - val_acc: 0.7193\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6629 - acc: 0.6330 - val_loss: 0.5675 - val_acc: 0.7193\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.6783 - acc: 0.6217 - val_loss: 0.5617 - val_acc: 0.7299\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.6533 - acc: 0.6493 - val_loss: 0.5671 - val_acc: 0.7161\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6871 - acc: 0.6316 - val_loss: 0.5608 - val_acc: 0.7182\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6670 - acc: 0.6291 - val_loss: 0.5604 - val_acc: 0.7246\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.6781 - acc: 0.6288 - val_loss: 0.5769 - val_acc: 0.7076\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.6553 - acc: 0.6426 - val_loss: 0.5605 - val_acc: 0.7299\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6616 - acc: 0.6274 - val_loss: 0.5686 - val_acc: 0.7150\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6643 - acc: 0.6369 - val_loss: 0.5580 - val_acc: 0.7225\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6585 - acc: 0.6274 - val_loss: 0.5706 - val_acc: 0.7119\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.6483 - acc: 0.6447 - val_loss: 0.5629 - val_acc: 0.7246\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.6685 - acc: 0.6306 - val_loss: 0.5791 - val_acc: 0.7013\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6553 - acc: 0.6366 - val_loss: 0.5801 - val_acc: 0.7034\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 47s 263ms/step - loss: 0.6491 - acc: 0.6397 - val_loss: 0.5663 - val_acc: 0.7150\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6485 - acc: 0.6447 - val_loss: 0.5786 - val_acc: 0.7034\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6592 - acc: 0.6320 - val_loss: 0.5763 - val_acc: 0.7066\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.6584 - acc: 0.6376 - val_loss: 0.5592 - val_acc: 0.7235\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 0.6495 - acc: 0.6376 - val_loss: 0.5740 - val_acc: 0.7108\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.6585 - acc: 0.6362 - val_loss: 0.5672 - val_acc: 0.7150\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6767 - acc: 0.6284 - val_loss: 0.5656 - val_acc: 0.7150\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.6629 - acc: 0.6429 - val_loss: 0.5551 - val_acc: 0.7267\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6476 - acc: 0.6433 - val_loss: 0.5653 - val_acc: 0.7182\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 47s 255ms/step - loss: 0.6564 - acc: 0.6426 - val_loss: 0.5666 - val_acc: 0.7193\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.6544 - acc: 0.6471 - val_loss: 0.5621 - val_acc: 0.7172\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6676 - acc: 0.6415 - val_loss: 0.5609 - val_acc: 0.7214\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6564 - acc: 0.6337 - val_loss: 0.5557 - val_acc: 0.7246\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6423 - acc: 0.6471 - val_loss: 0.5667 - val_acc: 0.7161\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6456 - acc: 0.6408 - val_loss: 0.5610 - val_acc: 0.7161\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6341 - acc: 0.6606 - val_loss: 0.5512 - val_acc: 0.7362\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 0.6499 - acc: 0.6433 - val_loss: 0.5677 - val_acc: 0.7140\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6527 - acc: 0.6415 - val_loss: 0.5568 - val_acc: 0.7256\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.6472 - acc: 0.6411 - val_loss: 0.5573 - val_acc: 0.7214\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.6465 - acc: 0.6493 - val_loss: 0.5707 - val_acc: 0.7066\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6424 - acc: 0.6500 - val_loss: 0.5589 - val_acc: 0.7256\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 47s 258ms/step - loss: 0.6447 - acc: 0.6475 - val_loss: 0.5780 - val_acc: 0.7002\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6374 - acc: 0.6496 - val_loss: 0.5488 - val_acc: 0.7362\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 45s 243ms/step - loss: 0.6589 - acc: 0.6355 - val_loss: 0.5589 - val_acc: 0.7235\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.6451 - acc: 0.6411 - val_loss: 0.5575 - val_acc: 0.7203\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6445 - acc: 0.6457 - val_loss: 0.5601 - val_acc: 0.7129\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6351 - acc: 0.6482 - val_loss: 0.5649 - val_acc: 0.7097\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6476 - acc: 0.6507 - val_loss: 0.5546 - val_acc: 0.7288\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 47s 260ms/step - loss: 0.6337 - acc: 0.6643 - val_loss: 0.5566 - val_acc: 0.7246\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 0.6458 - acc: 0.6486 - val_loss: 0.5705 - val_acc: 0.7066\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.6387 - acc: 0.6535 - val_loss: 0.5599 - val_acc: 0.7172\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6453 - acc: 0.6471 - val_loss: 0.5636 - val_acc: 0.7172\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 48s 264ms/step - loss: 0.6414 - acc: 0.6486 - val_loss: 0.5601 - val_acc: 0.7182\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6552 - acc: 0.6373 - val_loss: 0.5649 - val_acc: 0.7140\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6471 - acc: 0.6440 - val_loss: 0.5574 - val_acc: 0.7203\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6403 - acc: 0.6560 - val_loss: 0.5508 - val_acc: 0.7373\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 0.6344 - acc: 0.6528 - val_loss: 0.5471 - val_acc: 0.7383\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6359 - acc: 0.6493 - val_loss: 0.5498 - val_acc: 0.7352\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6482 - acc: 0.6454 - val_loss: 0.5575 - val_acc: 0.7225\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.6393 - acc: 0.6507 - val_loss: 0.5529 - val_acc: 0.7288\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6338 - acc: 0.6500 - val_loss: 0.5648 - val_acc: 0.7214\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6356 - acc: 0.6524 - val_loss: 0.5519 - val_acc: 0.7278\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.6363 - acc: 0.6620 - val_loss: 0.5542 - val_acc: 0.7256\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6433 - acc: 0.6369 - val_loss: 0.5603 - val_acc: 0.7150\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 46s 251ms/step - loss: 0.6422 - acc: 0.6556 - val_loss: 0.5481 - val_acc: 0.7383\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 47s 259ms/step - loss: 0.6465 - acc: 0.6514 - val_loss: 0.5509 - val_acc: 0.7299\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6301 - acc: 0.6447 - val_loss: 0.5585 - val_acc: 0.7203\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6144 - acc: 0.6704 - val_loss: 0.5596 - val_acc: 0.7182\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 42s 226ms/step - loss: 0.6264 - acc: 0.6546 - val_loss: 0.5507 - val_acc: 0.7341\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6184 - acc: 0.6694 - val_loss: 0.5651 - val_acc: 0.7119\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6305 - acc: 0.6613 - val_loss: 0.5493 - val_acc: 0.7341\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6232 - acc: 0.6595 - val_loss: 0.5516 - val_acc: 0.7267\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 0.6244 - acc: 0.6595 - val_loss: 0.5600 - val_acc: 0.7172\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 47s 262ms/step - loss: 0.6334 - acc: 0.6535 - val_loss: 0.5471 - val_acc: 0.7352\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6259 - acc: 0.6630 - val_loss: 0.5498 - val_acc: 0.7383\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 0.6304 - acc: 0.6440 - val_loss: 0.5810 - val_acc: 0.6939\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6254 - acc: 0.6538 - val_loss: 0.5562 - val_acc: 0.7214\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 48s 265ms/step - loss: 0.6352 - acc: 0.6493 - val_loss: 0.5699 - val_acc: 0.7023\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6167 - acc: 0.6662 - val_loss: 0.5576 - val_acc: 0.7225\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6399 - acc: 0.6553 - val_loss: 0.5567 - val_acc: 0.7246\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.6196 - acc: 0.6616 - val_loss: 0.5447 - val_acc: 0.7426\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6378 - acc: 0.6496 - val_loss: 0.5696 - val_acc: 0.7108\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 0.6333 - acc: 0.6563 - val_loss: 0.5551 - val_acc: 0.7203\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6280 - acc: 0.6535 - val_loss: 0.5449 - val_acc: 0.7426\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.6231 - acc: 0.6644 - val_loss: 0.5829 - val_acc: 0.7002\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.6268 - acc: 0.6577 - val_loss: 0.5467 - val_acc: 0.7394\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 45s 246ms/step - loss: 0.6207 - acc: 0.6598 - val_loss: 0.5447 - val_acc: 0.7394\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6130 - acc: 0.6613 - val_loss: 0.5425 - val_acc: 0.7426\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 48s 261ms/step - loss: 0.6252 - acc: 0.6496 - val_loss: 0.5874 - val_acc: 0.6992\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.6223 - acc: 0.6630 - val_loss: 0.5435 - val_acc: 0.7415\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.6214 - acc: 0.6602 - val_loss: 0.5438 - val_acc: 0.7447\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6322 - acc: 0.6609 - val_loss: 0.5567 - val_acc: 0.7161\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6149 - acc: 0.6673 - val_loss: 0.5458 - val_acc: 0.7426\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 0.6228 - acc: 0.6665 - val_loss: 0.5446 - val_acc: 0.7394\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 0.6276 - acc: 0.6464 - val_loss: 0.5557 - val_acc: 0.7203\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6256 - acc: 0.6602 - val_loss: 0.5458 - val_acc: 0.7394\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 45s 253ms/step - loss: 0.6270 - acc: 0.6500 - val_loss: 0.5523 - val_acc: 0.7267\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6314 - acc: 0.6535 - val_loss: 0.5584 - val_acc: 0.7172\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6139 - acc: 0.6669 - val_loss: 0.5540 - val_acc: 0.7267\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.6181 - acc: 0.6630 - val_loss: 0.5492 - val_acc: 0.7267\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 0.6261 - acc: 0.6560 - val_loss: 0.5539 - val_acc: 0.7267\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 0.6134 - acc: 0.6701 - val_loss: 0.5471 - val_acc: 0.7341\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6156 - acc: 0.6634 - val_loss: 0.5514 - val_acc: 0.7267\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6251 - acc: 0.6514 - val_loss: 0.5481 - val_acc: 0.7341\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.6309 - acc: 0.6538 - val_loss: 0.5452 - val_acc: 0.7426\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 0.6086 - acc: 0.6708 - val_loss: 0.5448 - val_acc: 0.7426\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6098 - acc: 0.6658 - val_loss: 0.5594 - val_acc: 0.7193\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.6173 - acc: 0.6588 - val_loss: 0.5581 - val_acc: 0.7235\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.6299 - acc: 0.6637 - val_loss: 0.5382 - val_acc: 0.7426\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.6152 - acc: 0.6630 - val_loss: 0.5497 - val_acc: 0.7278\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 46s 256ms/step - loss: 0.6240 - acc: 0.6609 - val_loss: 0.5542 - val_acc: 0.7225\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 46s 255ms/step - loss: 0.6093 - acc: 0.6676 - val_loss: 0.5460 - val_acc: 0.7352\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6108 - acc: 0.6694 - val_loss: 0.5496 - val_acc: 0.7214\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 47s 255ms/step - loss: 0.6149 - acc: 0.6697 - val_loss: 0.5837 - val_acc: 0.7002\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 0.6116 - acc: 0.6722 - val_loss: 0.5542 - val_acc: 0.7172\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 45s 251ms/step - loss: 0.6197 - acc: 0.6627 - val_loss: 0.5471 - val_acc: 0.7341\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 46s 253ms/step - loss: 0.6109 - acc: 0.6761 - val_loss: 0.5520 - val_acc: 0.7225\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.6108 - acc: 0.6807 - val_loss: 0.5560 - val_acc: 0.7225\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 45s 250ms/step - loss: 0.6108 - acc: 0.6687 - val_loss: 0.5586 - val_acc: 0.7193\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 0.6143 - acc: 0.6740 - val_loss: 0.5692 - val_acc: 0.7044\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 0.5946 - acc: 0.6877 - val_loss: 0.5452 - val_acc: 0.7373\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6077 - acc: 0.6814 - val_loss: 0.5660 - val_acc: 0.7066\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.6205 - acc: 0.6613 - val_loss: 0.5456 - val_acc: 0.7362\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 46s 254ms/step - loss: 0.6167 - acc: 0.6722 - val_loss: 0.5467 - val_acc: 0.7341\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 46s 252ms/step - loss: 0.6068 - acc: 0.6778 - val_loss: 0.5570 - val_acc: 0.7246\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 0.6160 - acc: 0.6623 - val_loss: 0.5608 - val_acc: 0.7129\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 43s 242ms/step - loss: 0.6150 - acc: 0.6637 - val_loss: 0.5434 - val_acc: 0.7394\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 0.6143 - acc: 0.6598 - val_loss: 0.5429 - val_acc: 0.7383\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 45s 249ms/step - loss: 0.6084 - acc: 0.6736 - val_loss: 0.5563 - val_acc: 0.7235\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 45s 252ms/step - loss: 0.6237 - acc: 0.6556 - val_loss: 0.5696 - val_acc: 0.7087\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "a47731df-896f-4f13-a1cd-19cce70a5e52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU1fnA8e+bkAAhEEhAZMsCsmoQMCwCAoqtgqgUccGA4Ia4Iu78UEErbaVooS1iwRVMUSqIoFBaWaqoVRFRdmULBhQlyJpAtvf3xyzNMpNMkkmGmbyf5/Exc++5d86d0feeec+554iqYowxJviFBboCxhhj/MMCujHGhAgL6MYYEyIsoBtjTIiwgG6MMSHCAroxxoQIC+jGIxFZISKj/V02kERkr4hcWgXnVRE5x/n3iyLyhC9lK/A+qSLyr4rWs5TzDhCRDH+f11S/WoGugPEfETlR6GUUcBrId76+Q1XTfD2Xqg6qirKhTlXH+eM8IpII7AEiVDXPee40wOfv0NQ8FtBDiKpGu/4Wkb3Abar6QfFyIlLLFSSMMaHDUi41gOsntYg8KiI/Aq+KSCMReU9EfhaRX5x/tyx0zFoRuc359xgRWSci051l94jIoAqWTRKRD0XkuIh8ICKzROQNL/X2pY6/FZGPnef7l4g0LrR/lIiki0imiEwq5fPpKSI/ikh4oW2/EZFvnH/3EJFPReSIiPwgIn8VkUgv53pNRJ4p9Pph5zEHROSWYmWvEJGvROSYiHwvIlMK7f7Q+e8jInJCRC50fbaFju8tIl+IyFHnv3v7+tmURkQ6Oo8/IiJbROSqQvsGi8hW5zn3i8hDzu2Nnd/PERE5LCIfiYjFl2pmH3jNcTYQCyQAY3F89686X8cD2cBfSzm+J7ADaAxMA14WEalA2b8DnwNxwBRgVCnv6UsdbwRuBs4CIgFXgOkEzHaev7nz/Vrigap+BpwELil23r87/84HJjiv50JgIHBXKfXGWYfLnfX5FdAWKJ6/PwncBDQErgDuFJGhzn39nP9uqKrRqvppsXPHAu8Df3Ze2/PA+yISV+waSnw2ZdQ5AlgG/Mt53L1Amoi0dxZ5GUf6rj5wHrDauf1BIANoAjQF/g+weUWqmQX0mqMAmKyqp1U1W1UzVXWRqmap6nFgKtC/lOPTVXWuquYDrwPNcPyP63NZEYkHugNPqmqOqq4Dlnp7Qx/r+Kqqfquq2cBCoItz+3DgPVX9UFVPA084PwNvFgAjAESkPjDYuQ1V/VJV/6uqeaq6F/ibh3p4cp2zfptV9SSOG1jh61urqptUtUBVv3G+ny/nBccN4DtVne+s1wJgO3BloTLePpvS9AKigT84v6PVwHs4PxsgF+gkIg1U9RdV3VBoezMgQVVzVfUjtYmiqp0F9JrjZ1U95XohIlEi8jdnSuIYjp/4DQunHYr50fWHqmY5/4wuZ9nmwOFC2wC+91ZhH+v4Y6G/swrVqXnhczsDaqa398LRGh8mIrWBYcAGVU131qOdM53wo7Mev8PRWi9LkToA6cWur6eIrHGmlI4C43w8r+vc6cW2pQMtCr329tmUWWdVLXzzK3zea3Dc7NJF5D8icqFz+x+BncC/RGS3iDzm22UYf7KAXnMUby09CLQHeqpqA/73E99bGsUffgBiRSSq0LZWpZSvTB1/KHxu53vGeSusqltxBK5BFE23gCN1sx1o66zH/1WkDjjSRoX9HccvlFaqGgO8WOi8ZbVuD+BIRRUWD+z3oV5lnbdVsfy3+7yq+oWqXo0jHbMER8sfVT2uqg+qamvgKuABERlYybqYcrKAXnPVx5GTPuLMx06u6jd0tnjXA1NEJNLZuruylEMqU8e3gSEi0tfZgfk0Zf/3/ndgPI4bxz+K1eMYcEJEOgB3+liHhcAYEenkvKEUr399HL9YTolIDxw3EpefcaSIWns593KgnYjcKCK1ROR6oBOO9EhlfIajNf+IiESIyAAc39Gbzu8sVURiVDUXx2dSACAiQ0TkHGdfyVEc/Q6lpbhMFbCAXnPNAOoCh4D/Av+spvdNxdGxmAk8A7yFY7y8JxWuo6puAe7GEaR/AH7B0WlXGlcOe7WqHiq0/SEcwfY4MNdZZ1/qsMJ5DatxpCNWFytyF/C0iBwHnsTZ2nUem4Wjz+Bj58iRXsXOnQkMwfErJhN4BBhSrN7lpqo5OAL4IByf+wvATaq63VlkFLDXmXoah+P7BEen7wfACeBT4AVVXVOZupjyE+u3MIEkIm8B21W1yn8hGBPqrIVuqpWIdBeRNiIS5hzWdzWOXKwxppLsSVFT3c4GFuPooMwA7lTVrwJbJWNCg6VcjDEmRFjKxRhjQkTAUi6NGzfWxMTEQL29McYEpS+//PKQqjbxtK/MgC4ir+AYHvWTqp7nYX8q8CiOByKO48iJfl3WeRMTE1m/fn1ZxYwxxhQiIsWfEHbzJeXyGnB5Kfv3AP1VNRn4LTCnXLUzxhjjF2W20FX1Q3FMtu9t/yeFXv4XLzPaGWOMqVr+7hS9FVjh53MaY4zxgd86RUXkYhwBvW8pZcbimIub+Pji8xQZY6pabm4uGRkZnDp1quzCJqDq1KlDy5YtiYiI8PkYvwR0EekMvAQMcs4x4ZGqzsGZY09JSbEB8MZUs4yMDOrXr09iYiLe1ycxgaaqZGZmkpGRQVJSks/HVTrl4ly0YDEwSlW/rez5SpO2KY3EGYmEPRVG4oxE0jbZernGlMepU6eIi4uzYH6GExHi4uLK/UvKl2GLC4ABQGMRycAxBWgEgKq+iGOWuDjgBed/JHmqmlKuWvggbVMaY5eNJSvXsTZC+tF0xi4bC0BqcmpphxpjCrFgHhwq8j35MsplRBn7bwNuK/c7l9OkVZPcwdwlKzeLSasmWUA3xhiC6NH/fUf3lWu7MebMk5mZSZcuXejSpQtnn302LVq0cL/Oyckp9dj169dz3333lfkevXv39ktd165dy5AhQ/xyruoSNLMtxsfEk3605ANS8TE2WsaYqpK2KY1Jqyax7+g+4mPimTpwaqV+EcfFxbFx40YApkyZQnR0NA899JB7f15eHrVqeQ5LKSkppKSUnc395JNPyiwTqoKmhT514FSiIqKKbIuKiGLqwKkBqpExoc3Vb5V+NB1F3f1W/h6MMGbMGMaNG0fPnj155JFH+Pzzz7nwwgvp2rUrvXv3ZseOHUDRFvOUKVO45ZZbGDBgAK1bt+bPf/6z+3zR0dHu8gMGDGD48OF06NCB1NRUXLPLLl++nA4dOnDBBRdw3333ldkSP3z4MEOHDqVz58706tWLb775BoD//Oc/7l8YXbt25fjx4/zwww/069ePLl26cN555/HRRx/59fMqTdC00F2tAn+2Fowx3lVnv1VGRgaffPIJ4eHhHDt2jI8++ohatWrxwQcf8H//938sWrSoxDHbt29nzZo1HD9+nPbt23PnnXeWGLP91VdfsWXLFpo3b06fPn34+OOPSUlJ4Y477uDDDz8kKSmJESNK7SYEYPLkyXTt2pUlS5awevVqbrrpJjZu3Mj06dOZNWsWffr04cSJE9SpU4c5c+Zw2WWXMWnSJPLz88nKyirz/P4SNAEdHEHdArgx1aM6+62uvfZawsPDATh69CijR4/mu+++Q0TIzc31eMwVV1xB7dq1qV27NmeddRYHDx6kZcuiM4/06NHDva1Lly7s3buX6OhoWrdu7R7fPWLECObMKX0KqnXr1rlvKpdccgmZmZkcO3aMPn368MADD5CamsqwYcNo2bIl3bt355ZbbiE3N5ehQ4fSpUuXSn025RE0KRdjTPXy1j9VFf1W9erVc//9xBNPcPHFF7N582aWLVvmdSx27dq13X+Hh4eTl5dXoTKV8dhjj/HSSy+RnZ1Nnz592L59O/369ePDDz+kRYsWjBkzhnnz5vn1PUtjAd0Y41Gg+q2OHj1KixYtAHjttdf8fv727duze/du9u7dC8Bbb71V5jEXXXQRaWmOvoO1a9fSuHFjGjRowK5du0hOTubRRx+le/fubN++nfT0dJo2bcrtt9/ObbfdxoYNG/x+Dd5YQDfGeJSanMqcK+eQEJOAICTEJDDnyjlVnvZ85JFHmDhxIl27dvV7ixqgbt26vPDCC1x++eVccMEF1K9fn5iYmFKPmTJlCl9++SWdO3fmscce4/XXXwdgxowZnHfeeXTu3JmIiAgGDRrE2rVrOf/88+natStvvfUW48eP9/s1eBOwNUVTUlLUFrgwpnpt27aNjh07BroaAXfixAmio6NRVe6++27atm3LhAkTAl2tEjx9XyLypben8a2FboypcebOnUuXLl0499xzOXr0KHfccUegq+QXQTXKxRhj/GHChAlnZIu8sqyFbowxIcICujHGhAgL6MYYEyIsoBtjTIiwgG6MqTYXX3wxK1euLLJtxowZ3HnnnV6PGTBgAK4hzoMHD+bIkSMlykyZMoXp06eX+t5Llixh69at7tdPPvkkH3zwQXmq79GZNM1u0AX077//ntdee42TJ08GuirGmHIaMWIEb775ZpFtb775pk8TZIFjlsSGDRtW6L2LB/Snn36aSy+9tELnOlMFXUD/7LPPuPnmm/nuu+8CXRVjTDkNHz6c999/372Yxd69ezlw4AAXXXQRd955JykpKZx77rlMnjzZ4/GJiYkcOnQIgKlTp9KuXTv69u3rnmIXHGPMu3fvzvnnn88111xDVlYWn3zyCUuXLuXhhx+mS5cu7Nq1izFjxvD2228DsGrVKrp27UpycjK33HILp0+fdr/f5MmT6datG8nJyWzfvr3U6wv0NLtBNw79nHPOAWDnzp3VOouZMaHm/vvvdy824S9dunRhxowZXvfHxsbSo0cPVqxYwdVXX82bb77Jddddh4gwdepUYmNjyc/PZ+DAgXzzzTd07tzZ43m+/PJL3nzzTTZu3EheXh7dunXjggsuAGDYsGHcfvvtADz++OO8/PLL3HvvvVx11VUMGTKE4cOHFznXqVOnGDNmDKtWraJdu3bcdNNNzJ49m/vvvx+Axo0bs2HDBl544QWmT5/OSy+95PX6Aj3NbtC10Nu0aQPArl27AlwTY0xFFE67FE63LFy4kG7dutG1a1e2bNlSJD1S3EcffcRvfvMboqKiaNCgAVdddZV73+bNm7noootITk4mLS2NLVu2lFqfHTt2kJSURLt27QAYPXo0H374oXv/sGHDALjgggvcE3p5s27dOkaNGgV4nmb3z3/+M0eOHKFWrVp0796dV199lSlTprBp0ybq169f6rl9EXQt9Pr169OkSRN27twZ6KoYE9RKa0lXpauvvpoJEyawYcMGsrKyuOCCC9izZw/Tp0/niy++oFGjRowZM8brtLllGTNmDEuWLOH888/ntddeY+3atZWqr2sK3spMv/vYY49xxRVXsHz5cvr06cPKlSvd0+y+//77jBkzhgceeICbbrqpUnUNuhY6OFrp1kI3JjhFR0dz8cUXc8stt7hb58eOHaNevXrExMRw8OBBVqxYUeo5+vXrx5IlS8jOzub48eMsW7bMve/48eM0a9aM3Nxc95S34GgMHj9+vMS52rdvz969e92NxPnz59O/f/8KXVugp9ktM6CLyCsi8pOIbPayv4OIfCoip0XkIU9l/O2cc86xgG5MEBsxYgRff/21O6C7ppvt0KEDN954I3369Cn1+G7dunH99ddz/vnnM2jQILp37+7e99vf/paePXvSp08fOnTo4N5+ww038Mc//pGuXbsWiR916tTh1Vdf5dprryU5OZmwsDDGjRtXoesK9DS7ZU6fKyL9gBPAPFU9z8P+s4AEYCjwi6qWPhjUqTLT506ZMoWnn36a7OzsIiuSGGNKZ9PnBhe/T5+rqh8Ch0vZ/5OqfgF4XvivCrRp0wZVZc+ePdX1lsYYc8ar1hy6iIwVkfUisv7nn3+u8HlspIsxxpRUrQFdVeeoaoqqpjRp0qTC52ndujWAtdCNqYBArVJmyqci31NQjnI566yzqFWrFvv37w90VYwJKnXq1CEzM9OC+hlOVcnMzKROnTrlOi7oxqEDhIWF0bx5cwvoxpRTy5YtycjIoDIpT1M96tSpQ8uWLct1TJkBXUQWAAOAxiKSAUwGIgBU9UURORtYDzQACkTkfqCTqh4rX/XLp0WLFhbQjSmniIgIkpKSAl0NU0XKDOiqWuo0aKr6I1C+24gftGjRgk2bNlX32xpjzBkrKHPo4AjoGRkZlgs0xhinoA7oJ0+e5NixKs3sGGNM0AjqgA5YHt0YY5wsoBtjTIgI2oDuGs5jAd0YYxyCNqA3b94csIBujDEuQRnQ0zal0fFvHaEu/GHFH0jblFb2QcYYE+KCLqCnbUpj7LKxpB9Nh7pw4ugJRi0ehTwlJM5ItOBujKmxgi6gT1o1iaxc52KqkcBpUBxj0dOPpjN22VgL6saYGinoAvq+o/v+96I2kFN0f1ZuFpNWTarWOhljzJkg6AJ6fEz8/17UBk6XLJN+NN1a6caYGifoAvrUgVOJiohyvPAS0AFLvRhjapygC+ipyanMuXKO40UkJVIuLpZ6McbUNEEX0MER1BNiEkptoUOxfLsxxoS4oAzoAIPbDnYE9Dwg33OZIvl2Y4wJcUEZ0NM2pfH61687Ui7gMe0SFRHF1IFTq7VexhgTSEEZ0N1j0Ws7NzjTLoK4y2TlZjF+xXjrGDXG1BhBGdDdufFiAd31gJFLZnYmt7x7iwV1Y0yNEJQB3Z0bLyXl4pKTn2OjXYwxNUJQBnT3WPRiLXRvbLSLMaYmCMqA7hqL3iyuGQCNwxsTVzfOa3kb7WKMqQmCMqCDI6h/evenADzb71lmDppJRFiEx7KD2w6uzqoZY0xAlBnQReQVEflJRDZ72S8i8mcR2Ski34hIN/9X07P69esDcPz4cVKTU3l16KvUi6hXotzrX79uHaPGmJDnSwv9NeDyUvYPAto6/xkLzK58tXxTOKCDo9XeOKpxiXI2DYAxpiYoM6Cr6ofA4VKKXA3MU4f/Ag1FpJm/KliaiIgI6tSpw7Fjx9zbvHWAWseoMSbU+SOH3gL4vtDrDOe2EkRkrIisF5H1P//8sx/e2tFKd7XQwXsHaHxMPGmb0kickUjYU2G2upExJuRUa6eoqs5R1RRVTWnSpIlfztmgQYMiLfQi0+s6CcI5see4l65T1FY3MsaEHH8E9P1Aq0KvWzq3VYviLfTU5FRGnz+6yDQAirJ6z+r/LV3nZLl1Y0wo8UdAXwrc5Bzt0gs4qqo/+OG8PmnQoEGRgA6w/LvlJaYBKP7axXLrxphQUausAiKyABgANBaRDGAyEAGgqi8Cy4HBwE4gC7i5qirrSf369fnhh6L3j/IEaXvoyBgTKsoM6Ko6ooz9CtzttxqVU4MGDdi+fXuRbfEx8aQfTS/zWJti1xgTSoL2SVGXRo0aceTIkSLbPHWMurhy6wkxCcy5cg6pyalVXkdjjKkOIRPQHT8UHFxzvYRLeInyirqfJh21eJQNXzTGhIygD+gNGzYkPz+fEydOFNmempxKgRZ4POZk7kkbvmiMCTlBH9AbNWoEwC+//FJin68dnlm5WYx+Z7QFdWNMUAv6gN6wYUOAEnl0oFwdnvmaz8jFI2k8rbEFdmNMUAr6gF5aCz01ObXUedI9yczOtBSMMSYohXRAB5g5aKbXES/e2BOkxphgFPQBvbSUC3ieCsAX9gSpMSbYBH1AL6uFDp6nAiiLPUFqjAk2QR/QGzRogIh4baFD+Vvb9gSpMSYYBX1ADwsLIyYmptQWurfWdriEIwhxdeOIqxuHIPYEqTEmaJU5l0swaNSoUakBferAqYxdNrbI9LlREVEWuI0xISXoW+jg6BgtLeXimgogISah1FZ42qY0Gk9rjDwlyFNS5ph0WwHJGHMmqREtdHAEdU+t8bRNaUxaNcnj7IyZ2Znc8u4t7uOLH1e41e+aQsBTWWOMqQ4h0UL3JaB74grKpU21m5Of43FM+qRVk2wFJGPMGSUkAnpZKRdvPAVlTzyNkvE2csbGrxtjAiUkAnpFW+i+Bl9Po2S8jZyx8evGmEAJiYDesGFDsrOzOX36dLmO8yX4RoZHehyT7mkRDRu/bowJpJAI6GeffTZAibVFy1LaykYAcXXjeOXqVzx2cvo6csYYY6pLSIxySUpKAmD37t0kJib6fJwr+E5aNYl9R/cRHxPP1IFTPY5o8VTG28gZY4wJBCm8dFt1SklJ0fXr1/vlXHv27KF169a89NJL3HrrrX45p0vx4YngWJdUUcIlnHzNJyEmweONwBhj/E1EvlTVFE/7QqKF3qpVK8LDw9mzZ4/fzlna+HTXRF/5mg/YGHRjzJnBpxy6iFwuIjtEZKeIPOZhf4KIrBKRb0RkrYi09H9VvatVqxbx8fHugL5t2zYOHDhQ4fP5Mj69OBuDbowJtDIDuoiEA7OAQUAnYISIdCpWbDowT1U7A08Dv/d3RcuSlJTErl27uOGGG+jUqRN33nlnhc/l6/j04mwMujEmkHxpofcAdqrqblXNAd4Eri5WphOw2vn3Gg/7q1xSUhJffPEFb731FuHh4eUe8VJYRQOzjUE3xgSSLwG9BfB9odcZzm2FfQ0Mc/79G6C+iJRYzFNExorIehFZ//PPP1ekvl61bt2agoICoqKiuOyyyzh69GiFzxVbN7ZCx53IOWETdBljAsZf49AfAvqLyFdAf2A/kF+8kKrOUdUUVU1p0qSJn97awTV0cejQobRo0aLCAT1tUxrHTh+r0LG2wLQxJpB8Cej7gVaFXrd0bnNT1QOqOkxVuwKTnNvKP7lKJXTp0oXw8HBuvfVWYmJiKhzQJ62aRG5BboXrkZWbxcjFI206XWNMtfMloH8BtBWRJBGJBG4AlhYuICKNRcR1ronAK/6tZtk6duzI4cOHueSSS4iJieHUqVPk5OSU+zz+6th0DWW0oG6MqS5lBnRVzQPuAVYC24CFqrpFRJ4WkaucxQYAO0TkW6ApEJAJTRo0aABATEwMAMeOlT914mvHZlREFHF1S3QTFGFDGY0x1cmnHLqqLlfVdqraRlWnOrc9qapLnX+/raptnWVuU9XyzZLlZ66A7kq7nDp1Cl+fiC1rfhdwrEU658o5zBw0s8yy5RnLbowxlRESk3MVVzigHzp0iCZNmvDee+/5dGzhSbfA8Zh/YYKQr/nulvfo80eXKFO8vKVdjDHVIeQD+tdff82JEyfYuHGjz8enJqey9/696GRl/rD5RYK767F/V4584ZaF7m2eKGqdpMaYahGSAd2VSz969Chbt24FYP/+/aUd4pUruCfEJJQI3Fm5WWRmZ/p0HuskNcZUtZAM6IVb6Nu2bQMqHtBd/DH6xTpJjTFVKeQDemVb6C7eRr/E1Y0rs2O0MJvvxRhTVSyg+8jbknMzB80ssnJRXN24UoczKmr5dGNMlQiJ+dCLi4iIoG7duuzevZuff/6ZRo0a8dNPP5GTk0NkZGSFzlnW6kaeVjkqvjCGi82fboypCiGxYpEnzZo1o2HDhmzfvp1rrrmGRYsWsXfvXhISEqrsPYsrbZEMgISYBPbev7fa6mOMCX6lrVgUkikXcKRdtm/fDsCgQYOAyqddfJW2KY3G0xozcvHIUh8ssny6McafQjLlAv/LoycmJtK9e3egegJ62qY0bl5ys08TfNn86cYYfwrpFjpAnz59aNHCMX17dQR0X2drjAyPZOpA71PepG1KI3FGImFPhVknqjHGJyHfQu/bty+xsbHUrl27WgK6r2mUvII8r/uKd6haJ6oxxhc1ooUuIpx//vm88847FZpStzx8TaMUaIHXJ0c9rWlqDyUZY8oSsgH9nHPOIT4+nnPPPReAp59+ml27djFr1qwqfd+pA6cSERbhU1lvQdpbK986UY0xpQnZgP7www+zbds2wsIcl3jZZZfRr18/XnrppSp939TkVF4d+mqZc6W7eArS3lr51olqjClNyAb08PBwoqKKPtnZqVMn/L04tSepyakceuQQOlnRycobw94gXMI9lvUUpD09lSoI6UfTrYPUGONVyAZ0Txo1asThw4d9XuzCX1KTU3n9N697DNKD2w4uMaIFYM6Vc4q08otP22tB3RhTXI0K6LGxseTn53PixAlUlUcffZTPP/+8Wt47NTm1xGIYivLShpe45d1bSD+ajqLugP3xvo/Jzsv2eC7rIDXGeBKywxY9iY2NBeDw4cPk5eUxbdo0cnJy6NGjR7W8//LvlpeYU93TmPWs3CzmfDmHfM33ei7rIDXGFFejWuiNGjUCHAF97969ABw4cKDa3r88Qbi0YA6O3Ls9fGSMKaxGttB/+eUX9wLS1RnQ42PifV40OkzCKNACj/uiIqIY3HawPXxkjCnCpxa6iFwuIjtEZKeIPOZhf7yIrBGRr0TkGxEZ7P+qVl7hlEsgWuieRq94IwiR4Z6n+q1bqy4Ltyy0h4+MMUWUGdBFJByYBQwCOgEjRKRTsWKPAwtVtStwA/CCvyvqD55SLvv376+2US+pyaklRq94k6/51I+sX2SBapfM7Eyva5n6+gvAGBN6fGmh9wB2qupuVc0B3gSuLlZGgQbOv2OA6mv2lkPhlIsroJ8+fZpffvml2uqQmpxKdGS0T2VdQTuublyJzlRvBOGu9+8qkVu3fLsxoc+XHHoL4PtCrzOAnsXKTAH+JSL3AvWASz2dSETGAmMB4uOr/6nHunXrEhkZyeHDh0lPTycsLIyCggIOHDjgDvbVoTydo+VtcSvK7PWzixx/85KbERFy8nPc2yzfbkzo8dcolxHAa6raEhgMzBeREudW1TmqmqKqKU2aNPHTW/tORIiNjXW30Dt37gxUbx4dqv8R/tyCXHcwd8nKzWL8ivHVWg9jTNXyJaDvB1oVet3Sua2wW4GFAKr6KVAHaOyPCvpbbGwsu3fv5ujRo/Tu3RuovpWMXMrTOVqVMrMzLfViTAjxJaB/AbQVkSQRicTR6bm0WJl9wEAAEemII6BX/aQpFdCoUSM2bNgA4A7o1d1Cd3WOJsQkIAgJMQm8MewNdweoJ2Elf/D4xeh3RltQNyZElJlDV9U8EbkHWAmEA6+o6hYReRpYr6pLgQeBuSU7+H4AACAASURBVCIyAUcH6RgN1OrTZXClXOB/i19s2bKF77//nlatWpVxtP+kJqeWyF+PWjzKa3lvY9IrK1/zLZ9uTIjwqdmnqstVtZ2qtlHVqc5tTzqDOaq6VVX7qOr5qtpFVf9VlZWuDNfQxU6dOpGQkEDz5s1ZsGAB3bp1q/ZJu4rzlluPqxtXauu9smz8ujGhoUY9+g//G7o4aNAgAJ544gkGDhzIoUOHqj2XXpyn3HpURBQzB830S9698Fj24mxuGGOCX4169B9KBvTrrruOuLg4Vq1axbfffkvLli0DVjdXymPSqknsO7qP+Jh4pg6cWiQVMn7F+BIPFQni0zh1Rb2WtcUzjAl+Na6Ffskll3DllVfSt29f97Z27doB8O233waqWm6pyansvX8vBZML2Hv/3iLB3LVwhqsD1dWhOi5lnM+td0/BPFzCOZFzwh46MibISaDyxikpKbp+/fqAvHdxBQUF1K9fn7Fjx/KnP/0p0NWpkLRNaYx+Z3SZszT6IioiijlXzrFOUmPOQCLypaqmeNpX41ronoSFhdG2bdszooVeUanJqX4bCWOdpMYEJwvoTu3atQvqgA7+zYNbJ6kxwccCulP79u3Zs2cPOTk5ZRc+Q/nzCdQwCSuRS7cJvow5s1lAd2rXrh35+fns3Lkz0FWpsMJPoELJYYqCMDBpoLtDtTSuB45cQTttUxpjl40tsfapp5kdjTGBYZ2iTps2baJz587Mnz+fkSNHBro6fpG2Ka3UIZCNpzX2Oq+6S0JMAnvv30vijESfZn60DlVjqlZpnaIW0J3y8vKIiYnh9ttvZ8aMGYGuTpVL25TGzUtu9rhIdWW5bgLGGP8rLaDXuAeLvKlVqxZdu3Zl/fr1zJgxg8zMTEaNGuUeox5qJq2aVCXBHKxD1ZhAsRx6ISkpKXz++edMmDCBZ555hl69evHDDz8EulpVoiqDrmu0jXWiGlO9LKAXkpKSQm5uLvXq1WPdunVkZ2czbtw4CgoKSE5OZt68eYGuot9U1aP+URFRTB041WsnqgV1Y6qOBfRCevToAcC4cePo06cPjz32GEuXLuWzzz5j8+bNrFu3LsA19B9PQxxdI1/KO/e6q3xCTIK7Q3TSqklk5WYVKWcPLBlTtSygF9KuXTtWrlzJb3/7WwD3fC9LlzrW89i3bx9fffUVL7zwQsDq6C+eFtmYP2w+bwx7g3AJL9e5CrSAqIgoBrcdzKRVk5CnxOuImOKpHkvLGOM/NsqlFAcOHKBFixZ06tSJrVu30rFjR3r06MH8+fM5ffo0tWqFXp+yr8MTPfFl1sdwCadAC4iPiWdw28G8/vXrRVryNuzRmNLZXC4V1KxZM+rXr8/WrVsBSE9PZ8eOHRQUFFhnqQe+TOGbr/nunPqL61+0tIwxfmQBvRQiQseOHd2vs7Ky+OqrrwD4/vvvA1WtKlVaZ2l5UzFl8XYDsGGPxlSMBfQydOjQAYCoKEcH4unTp4HQDejeVk16Y9gb5D2ZV6VL4bnYYhvGVIwF9DK4Anq/fv2KbN+3LzRbkZ46SwvntKu69ewa9miMKT8L6GVwpVwuvfRS9zYRCdkWOpS+alJVtZ4FIa5uHHVr1WXU4lEkzkj0OvFX8ZExNkGYMQ42yqUMv/zyC7feeit//etfOeecc1BVkpKSaN++Pe+8806gq1ftXA8MFe/MrIyEmASmDpxa5nkF4ZKkS/g049NSy9lIGRPKKj3KRUQuF5EdIrJTRB7zsP9PIrLR+c+3InKkspU+UzRq1IjFixfTvHlz4uPjadu2LQkJCSHdQi+Np5RMdGR0hc/nSrF4ehCpOEVZtWdVmeVspIypqcoM6CISDswCBgGdgBEi0qlwGVWdoKpdVLUL8BdgcVVUNtDuvvtu7rnnHlq1alVjAzqUTMm8OOTFMhfWcD2FGlc3jri6cSXy8/7OzacfTbfUi6lxfHkypgewU1V3A4jIm8DVwFYv5UcAk/1TvTPLvffeC8DBgwf56aefOHXqFK+88grnnnsu/fv3L1L21KlTrF69moiICH71q18ForrVxpXaKDz3+uC2g1n+3XKvc7EXlrYpDRHB3+m/m5fczPgV4zmcfbjMOhgTCnwJ6C2Aws3RDKCnp4IikgAkAau97B8LjAWIjw/eoWmuug8dOpSVK1cSFRXFxx9/TJcuXdxlrrvuOpYtW0ZkZCTHjx8nMjIyUNWtFqnJqRUKlq552f21wHVhuQW57gU8XJODARbUTcjy9yiXG4C3VTXf005VnaOqKaqa0qRJEz+/dfUZNmwYQ4YMYeXKlaSmphIbG8uIESMoKHAEpWPHjrF8+XLatGlDTk4OO3bsCHCNzyyFR6mMfmd0lc3LXlzh3Hp555CxOWdMMPAloO8HWhV63dK5zZMbgAWVrdSZrn79+ixbtoz9+/czf/58/vCHP7B9+3ZWrVoFwNq1a8nPz+f+++8H4JtvvnEf+5e//MW9vSYqPq1uvud7f5VJP5pO42mNGbl4ZJGpfW9ecjONpzX2GLBtKmATLMoctigitYBvgYE4AvkXwI2quqVYuQ7AP4Ek9SEZGizDFn1x+vRpWrZsSd++fXnnnXe47777ePnllzl48CCxsbHcfffdqCr33HMPQ4YMYf/+/Rw9epSwsJr3GEBlJv/yB18mEIOiQx+91dmW2jOBUKlhi6qaB9wDrAS2AQtVdYuIPC0iVxUqegPwpi/BPNTUrl2b2267jaVLl/L999/z73//m379+hEdHU2nTp2YO3cuM2fO5LHHHmPHjh2cOHEiZJ80LUt5RrO4RsT4ky/BHBzpmdHvjOau9+/yegNKP5pe4fSLpXBMVfCpiaiqy1W1naq2UdWpzm1PqurSQmWmqGqJMeo1xR133IGqctNNN7F9+3auvvpqAJKTkzl58iQAixYtcpffsmWLx/OEOl+eNI2rG8cbw97g0COHmDlopse5ZapDvuYze/3sUstUJP1iKRxTVWreb/4qkpiYyBVXXMHatWuJj4/n5ptvBqBz584AdOvWDfjfJF+FA/rjjz/O7373u2qucWCUNk+LIOhk5dAjh9wjUbzNLVMdk4T5qrwPMtlqTqaqWED3o/vuuw+Ap556itq1awNwxRVX0Lt3b9566y1q167NgAEDaNGiBZs3b3Yf9/rrrxdpvYey1ORUr2kUb613T3PLlLaEXiC4Ukm+pFK8pZ32Hd1nqRhTKTaXi5/t2LGDdu3aIVIyuLz//vskJibywAMPcOjQIb788kuOHz9OgwYNOOusszh48GAAalz9PM0HU5H5V9I2pRV5mMn14FCgOl7j6sZxPOc4Ofk57m2erstb/eLqxpGdl20rOJlSldYpagE9AB588EFmz57N8ePH2bBhg3tx6lOnTrlb9qHOWzD217n9PYFYZRQfDeOpfoJQL7IeJ3JOlHm8qdlKC+ihtyhmEOjVqxfPP/88q1evLrKU3YEDB0hKSgpgzapPRZ8s9fXcAKPfGV3t49w9cY19dz21Wi+iHnn5eUXKKOoxmIPvI4Oq8iZpgoPl0APgyiuvpFGjRrz88sts27bNvT0jIyOAtQotqcmpVTKdQEW5gjnAydyT5BTklFK6qNi6sWWWqcjIGcvXhx4L6AFQp04dRo4cyTvvvMO6deuoU6cO4D2g//DDD1x00UXs2rWrOqsZ9EJlKbvjOcdJ25RWagAu78gZGzoZmiygB8gdd9xBQUEB69at46KLLgK8r1O6aNEi1q1bxz/+8Y/qrGLQmzpwakBHvvhLTn4Odyy7g1GLRxUJwCMXj6TxtMakbUrzmpZxPfxU/Cbg7QYwfsV4a7kHMQvoAXLuueeyYMECwsPD6du3Lw0aNPDaQl+5ciUAa9asqc4qBr3U5FTGpYyrUFCPqxtXbQ8w+eJk7kmPT7lmZmcycvHIUp+ALX4TCH863OsooMzsTG5595YyW+4W9M9MNsolwHbu3EmLFi1ISUmhffv2LF78v7VB8vPzOXXqFE2bNiU7O5s6derwyy+/hPxUvP5WvLOw8FztsXVjvQ41BBi5eGSgqn1GcS0TOH7F+CL9AS42vLL62LDFIHDZZZexfft2fv3rX9O9e3duuukmRo8ezbJly8jOzmbMmDG89tprLFy4kF69etGiRYsaOblXVShtdIi3MeO+TvIVSiLCIkqd6ri8wytdn3v60XTCJZx8zXffOOzG4J0F9CBw22238fLLLxMREUFubi5dunRh48aNdOjQgdOnT7N27VqSkpLcc66fd955fPbZZ0RFRTF48GD69OnDpEn26Li/eXsIavT5o4usyHQi54THlmtNIggFk0sfWVQ4iHu7KVprv3SVXiTaVL2RI0dyxx13cODAAV544QU2btxIUlISX331Fbt37yY+Pp7ly5fz+uuv8/vf/57Nmzczc+ZMfvrpJ1asWMGLL76IqpKRkUFycrItquEn3uaSeeGKF4pMR+BpErGyRIRFEBleNH12JuXty6v4qKLiefa73r/LPbIGvM986eqc9aas/H1l9wcza6GfoRYtWkS7du1ITk72uP/qq69mzZo1PPfcc4wd61ha7YsvvuDLL79k3LhxPP/880yYMKE6q1zjecrVL9yysMgDRXVq1SmyxilQIt3jasEGE0EYlzKOPvF9ymyB+yqubhwzB80s0lL39IspIiyCBrUbcDj7cKl9IqnJqT7/4jqT0z6WcglBmzZtonPnzjRq1Ijs7Gxyc3N59NFHSU9PJy0tjdTUVN54441AV9NUgK9TF9SUPH5c3TiuO/c6ln+3vFI3uoSYBDKzMz0+kVv8szyT0z6WcglBycnJXHzxxfzyyy/07t2b/v37s2DBAv7zn/8AYDfL4FU4zeNNQkwC84fN9zhzpa/DNF3lzvSx+pnZmcxeP7vSv1rSj6Z7nV6h+I0xKzeLkYtH+j0lU9XpHgvoQezee+8FoF+/fkyYMIE9e/aQkZFBixYt+Pbbbzl27FiAa2gqyjVl8BvD3vC4wIcrJXDokUO8MeyNIjn+cSnjyszFh0s484fNRyer1xuDKbqAiT9y91X9dK6lXIJYfn4+zz//PCNHjuTss8+mX79+rFu3jt///vdMnDiRKVOm0KVLF4YMGQLA9OnTGTlyJC1atAhwzU15VGTSrdJGk3hLJ6RtSvM6zrwwV/CvaaN6SvscvaXJaofX5nT+aQDCJMzj/ELlHe5pOfQaYuvWrcyfP5/x48fTrFkz9/YuXbpw1113MXbsWB544AGee+65ANbSVLeKzsJY2nFpm9K4ecnNpY5Lrwni6sYRHRldqXSQL8M9i5S3gF7z/OlPf6Jp06bk5uYyZswYwsLCKCgoID4+nr1793pcgMOY8ig8JbCpOH+20G0+9BBVeMjiZ599xuzZsxkyZAjvvfcen3/+OT179gxg7UwoOJx92Oey0ZHRXjski6spo3cAIsMjS11nt7ysU7QGeP755/n3v//N/PnziYyMZNy4cbz00kv88ssvJcoWFBTw9ddfE6hfbiZ4lDY9sWvkTEJMAm8Me4PjE4+jk7XMxb2jIqIYlzKuwp20cXXjzvhRO4XVj6zv16GRPgV0EblcRHaIyE4RecxLmetEZKuIbBGRv/uthqbS6tSpw6WXXkrDhg2ZM2cOWVlZ3H777bRq1YpZs2aRl/e/1XOeffZZunTpwrx58wJYYxMMPC3UDY6g6hpB41rUu7RjCgd/11O4hx455DWou24Snkb/zBw0M6jmwS/PrxxflJlDF5Fw4FvgV0AG8AUwQlW3FirTFlgIXKKqv4jIWar6U2nntRx64KgqGzZsYNKkSaxcuZJmzZqRmJhIcnIyCxYs4MSJEzRs2JDNmzfTvHnzQFfXnMEqMwKnrGPKWkzc23nOtDVlS1OR9WIr1SkqIhcCU1T1MufriQCq+vtCZaYB36rqS75WygJ64Kkqy5YtY968eRw+fJh169ZRUFDAokWLGDFiBGeddRZz587l4osvplYt624x1c9fI3TKmjLZxTUNwEsbXqryETwVfRq1sgF9OHC5qt7mfD0K6Kmq9xQqswRHK74PEI7jBvBPD+caC4wFiI+PvyA9Pbjmqwh1e/bs4eDBg/Tq1YsvvviCoUOHcuDAAcLCwkhMTOTRRx/l1ltvJTw83OdzFhQUICI2qsacUcqaurf4mHzXvDKAT2P1i/PnfDHVEdDfA3KB64CWwIdAsqoe8XZea6Gf+U6ePMmKFSvYuHEja9as4ZNPPmHUqFFce+21tG7dmnPPPbfU41WVQYMGkZ2dzbJly2jQoEE11dyY6uFtvvx6EfVoHNW4Sib7quywxf1Aq0KvWzq3FZYBfKaqucAeEfkWaIsj326CVL169Rg+fDjDhw9HVZk6dSpPPPEE8+fPp2nTpmzbto19+/YxcuRI7r//fm699Vb3sXv27OGjjz5yL593+eWXk5aWRlJSUqAuxxi/87aWa1ZuVrlz4/7gyyiXL4C2IpIkIpHADcDSYmWWAAMARKQx0A7Y7cd6mgATER5//HHWrFnDvHnzOHToEFdccQWXXHIJW7du5fbbb+ePf/wjeXl5LFy4kNatWzN69Gi6dOnCW2+9xaZNmzjvvPP485//XGRUjTG+OHXqFD169ODDDz8MdFWK8DaiJlAjbcoM6KqaB9wDrAS2AQtVdYuIPC0iVzmLrQQyRWQrsAZ4WFXtEbIQNGDAAEaNGsXjjz/unsJ306ZNXHXVVTzyyCN07NiRO+64g5SUFCZNmsT8+fO57rrr2LJlC/369WP8+PG0bt2auXPnuse6Fw/we/bsYeLEiXz66aeBuERzBpg/fz7fffed+3V6ejpffPFFQAL6v//9b/eaA8V5GobpmjwtIFQ1IP9ccMEFakJHQUGBLlmyRHv37q2xsbG6c+dOj2Xeffdd7du3rwLat29fvfbaazUiIkKfffZZLSgo0Pfff1+bNGmigAI6YcIELSgoCMAVVVxGRoY++uijOm7cOM3NzdU9e/bosWPHquz9CgoKzvjPqKCgQLt3766vvPJKmWVPnz6tIqL33Xefe9t//vMfBfSee+6pymp6NHbsWAX0yJEjHve/8c0bmvCnBJUpogl/StA3vnmjSusDrFcvcdUCuvG7soJLfn6+zpw5Uzt27KjR0dHaq1cvBbRevXoKaLt27XT9+vV69913K6CXXHKJ3nnnnXrjjTfqN998U+F6/fe//9XWrVvr999/X+FzqDqu74EHHtAPP/zQ4/4hQ4a4b0jvv/++1qtXT5s2baorVqyo1Pt68/zzz2ubNm3O6KD+888/K6DXX399mWX37t2rgA4bNsy9beHChQrotddeW5XV9Ojyyy9XQDds2FDt7+2JBXRzxiooKND8/HydNWuWjh8/XufOnaunT59275s2bZomJSVpdHS0xsTEaHh4uE6bNk2XLVumy5cvd5d1OXDggG7dutXje40YMUIBnTFjRqXqvGfPHq/BKTc3V+vXr6833nij1qpVS9u1a6eANm7cWDt16qTbtm3T/v376759+ypVh8J+9atfKaA//fST387pb59//rkC2rlz5zLLfvLJJwpojx493Nv++te/KqD9+vWrymp61KlTJwX0H//4R7W/tycW0E3QKygo0EOHDuk111zjbv0C2qhRI73tttv0gw8+0IULF2pcXJzWqlVLZ82apadOndJ7771Xn3nmGd28ebPWrl3b3eJXVT1y5IhmZGTo5s2btX///iVuBMeOHfPY6n399dcV0GbNmmlOTo7+/PPPmp2drcOHD9cXXnhBAV2wYIH279/fXe7pp59WwP2rw5eWalmfx/XXX6/vvvuuNmrUSAH99NNPSz1m1qxZOmvWrEq9b0W99dZbCmjt2rX166+/1tmzZxfZv23bNl27dq2qqv7jH/9QQJs3b+7e/8QTT7h/vVWngoICjY6OVkD/8Ic/eNy/Zs0azcvL8/mcv/vd77z+uvOFBXQTMgoKCvTtt9/Wf/7zn/ree+9pamqqO1UDaPv27d0/kVu3bl0k+AN62WWXaa1atXTVqlUaHx+vUVFRmpiYqIDeeuut7vd46KGHFNCmTZvqypUr9e9//7s+88wzqqp66623us93+eWXa2xsrP79739XQMPCwhTQ/fv367PPPquA3nXXXbp27Vp3QHOVmTx5sh4+fFgLCgr0gw8+0CeeeEIPHjzovtbMzEx96qmn9MSJE6qqOn36dE1NTVVV1Q0bNiigCQkJ7rq88UbJ3K3rhpSXl6exsbEaHR3tPp9rvz9TNdnZ2R63uz4LQLt166aA7t27171/6NChGhMTo7m5uTpjxgwFVEQ0JydHVf+Xx46JifFbXX1x+PBhd73Hjh1bYv/y5csV0EWLFumOHTt0x44dpZ7v4MGDKiL61FNPVbhOFtBNSDtx4oQuXbpUV69erVlZWZqfn69PPPGEiohOnz5dd+7cqZMmTdKHHnpIP/74Y/f/oM2aNdOePXtqWFiY9ujRQ6OiovQf//iHu9P2hhtu0A4dOrhb/YC+99572q5dO3cqxfVP06ZN3X+fc845qqq6c+dOPeuss/Szzz7TkydPakREhAL6wAMP6KBBgxTQ3/zmNzpr1iz3sd27d3d3oD711FNFAonrp//27dv1t7/9bYmbVfEgMX36dE1KStKff/5ZP/30U3e5J598Uh944AHdsmWLnn/++Tp+/Hivn+2nn36qTZs21d27d5f5PaxZs0YjIyM9BrVx48aVqO/zzz/v3t+2bVsF9JNPPtGHH37YXcaVmho6dKh7m7ebRlXYuHGj+30HDhxYYv+1117rvjn37NmzSJrIk9dee00B/fLLLytcJwvopkY6fvx4iW35+fn63HPP6d/+9jf98ccfNScnR/fu3avr1693/4/bqlUrnT17thYUFOjGjRs1IiJC4+PjtWPHjhoXF6eATps2TRs3bqy1atXS5s2bu9Mo5513nj744IMe6+Pq/P3Pf/6jqqoPP/ywhoeHa0JCgvbo0UPfeustDQsL07p16+rEiRP1nHPO0cjISAXcvwAAffzxx7Vnz57asmVLBbRu3brarFkzvemmm3T//v16+vRpnTdvnrv8n/70J33iiSc0LCzMfYyrBez6VbF582aPdXb9Gnn22WdVVfWf//ynvvTSS0U+4yVLlujXX3/tTifNnDlTVVXXr1+vy5YtU1XVyy67TNu0aeN+74iICO3bt6+qqp46dcr9q2XKlCl64403ust9/PHHqqp64YUXurelp6eX+d2X51fHRx995PWGtXTpUgW0TZs2mpSUVGRfZmam+/sZOnSo1q5dWyMjI92/KrKzs/Xuu+/WBQsWuI+55pprtHnz5pX6VWQB3RgfTJs2TV9//XX3/5Aun3zyie7evVs3btyogwYN0l69eumuXbv0j3/8oz777LPu/PiiRYs0Ly/P6/+skydP1iZNmrg7crdu3eoOUq7hfB9//LEOHz7cvf3FF1/UFi1aaMOGDRXQs88+Wxs3buz+2d61a1cdMGCA9u/fXxMSEjQiIsKd8+3bt69269ZNO3XqpJ07d9bevXvrnDlzNDk5Wd98803t2rWr/uUvf9EGDRroVVddVaSuzz33nD711FMaGxurgPbu3Vu///57bdCggdauXVuPHTumR44ccd8gWrVq5U5xDR06VPPy8rRt27Zar149zc7O1vbt2+vw4cP17LPP1oiICH3wwQdVRPTuu+92D0kUEe3du7f279/ffb1vvfWWqqq2bt1a69evr4B+/vnn+uOPP+rf/vY392d9+PBhPXz4sKqq7tq1S5s1a+Yx513czp073Z/19OnTS+x3dcbeeuutGh4e7v5vY//+/XrZZZe5g33dunXd59m4caPm5eW5O6u7d++uqo4bV3R0tMfUTXlYQDemCh05ckT/+Mc/lrgRFJeTk6OZmZlFtvXq1Uvr169fJK+dm5urAwcO1AYNGujRo0d18uTJCmidOnV08eLF2rx5c+3Zs6fu2rVLDxw4oD/88IPecsst7tb2TTfdpNOmTdOcnBydM2dOkZuDJ7/73e8U0H/+85+qqrpjxw4NDw93H9ejRw8VEXd6ytXp++STTyqgjzzyiLtsvXr1tFGjRrpgwQL3tmXLlmnt2rX1oYce0uHDh+vQoUP1xx9/1CuuuELDw8PdN4IhQ4ZoWFiYnnXWWfrrX/9aAX3uuedUVTU6Olp79+6tgC5dutSdlvnoo49U1dGC79GjhxYUFOill17qfu+0tDT9+uuvdeLEiSVGRKmquxM7KSlJXTFp7969OnLkSN29e7c+8sgjGhkZqS+//LI73bVr1y53/8tf//pXnThxYpFU0iuvvOLOrbdv315r1aqlJ0+e1H/961/uz6MyLKAbc4bavn27rlu3rsT2nJwc3b9/v6qqfv/99xoWFqYDBgzwep6pU6e6g2JhWVlZOnnyZHfqwpNTp05pu3bttE2bNnro0CG9/vrrtW7duvqb3/xG4+Pj9bPPPlNAo6KidN68eXr22Wdr7969NTo6Wq+99lrNz89358Aff/xxBTQuLk7btm2r9evX18GDByugs2bN0ry8PM3NzXW/t2ufiLjfBxwPlEVFRemECRP05MmTCrjz8HPnznX3YYwdO1a3b9/uPu6+++5zp5n69++vkZGRetZZZymgjz32mA4YMEAnTpzorsPQoUM1MTHRHbh//PFH7dChgwI6cuRIveGGG7RNmza6a9curVWrll5//fWamJiosbGx7nHp8+fPd99wo6Oj9d5779VrrrlGGzdurIsWLXKn2e69916tU6eOnjx50vf/QDywgG5MkJs9e7auWrXK6/63335bAX333XcrdP61a9dq7dq1tUGDBgropEmTVFXdrdr33nvP3UF51113KTiGFbqeCH733Xd1zJgxmpGRoZGRkdq2bVv95JNP3J2GgP73v/8t8b6vvvqqApqYmKiqqj179nSnP9q3b69DhgzR3bt3u28IgI4aNUoBbdCggcbE5Nv4RQAABlJJREFUxOjDDz+sIuJOe/Tu3Vvz8/P18OHD2r59e61fv767/8LVuT1gwADNyMjQBg0a6NixY93DKl2/Ei677DINDw/XevXq6ZVXXqmq6r5Z1K5dWz///HP3NbhGHPXo0UP79u2rHTp00IiICJ0wYYL7garf/e53mpSUVOKGWxEW0I0JcTk5ObpixYpKdbatXr1aO3bsqDNnztT8/Hyv5dLT0/XJJ58skT4qvN91I1izZo2mpKR4fUr28OHDGhERoYMGDVJV1blz57pTOjfffLMC7tb4e++9pzExMe7nCVw3A0AvvfRSvf322zUiIqJIB++RI0d03759+t1332mPHj10+fLlOm/ePK1bt647uL/99ttFcukDBw7UAwcOaFRUlJ5//vl64MABVVU9dOiQ9u3bV998880i13Dy5EkNCwvTO+64QydMmKCARkdH6/bt21VVtX379nrOOeeUmvYqDwvoxpgz1pw5c3T16tWq6hgZ8swzz+jRo0c1JydHX3zxRW3WrJkCumnTJv3Vr36lYWFh7k7cd999V2+77Tb9+OOP9dixY7plyxaf3nPTpk36yCOP6Pjx4zUrK0sLCgrcHbFz585VVceNKSsry6fzLV68WPfs2aOHDh3SZcuWuTtoVVUffPBB98iejIyM8nw0HpUW0Mtc4KKq2AIXxhhfnDx5km+++YYLL7wQV7yqihWwBg4cyIcffsjBgweJjY3123lVlQMHDlBQUECrVq3KPqAMlV3gwhhjAqZevXpceOGFQNUEcpeJEydy7bXX+jWYg6POLVq08Os5vbGAbowxwKWXXsqll14a6GpUii8rFhljjAkCFtCNMSZEWEA3xpgQYQHdGGNChAV0Y4wJERbQjTEmRFhAN8aYEGEB3RhjQkTAHv0XkZ+B9Aoe3hg45MfqBIuaeN12zTWDXbPvElS1iacdAQvolSEi673NZRDKauJ12zXXDHbN/mEpF2OMCREW0I0xJkQEa0CfE+gKBEhNvG675prBrtkPgjKHbowxpqRgbaEbY4wpxgK6McaEiKAL6CJyuYjsEJGdIvJYoOtTVURkr4hsEpGNIrLeuS1WRP4tIt85/90o0PWsDBF5RUR+EpHNhbZ5vEZx+LPze/9GRLoFruYV5+Wap4jIfud3vVFEBhfaN9F5zTtE5LLA1LpyRKSViKwRka0iskVExju3h+x3Xco1V+137W2x0TPxHyAc2AW0BiKBr4FOga5XFV3rXqBxsW3TgMecfz8GPBvoelbyGvsB3YDNZV0jMBhYAQjQC/gs0PX34zVPAR7yULaT87/x2kCS87/98EBfQwWuuRnQzfl3feBb57WF7HddyjVX6XcdbC30HsBOVd2tqjnAm8DVAa5TdboaeN359+vA0ADWpdJU9UPgcLHN3q7xamCeOvwXaCgizaqnpv7j5Zq9uRp4U1VPq+oeYCeO/weCiqr+oKobnH8fB7YBLQjh77qUa/bGL991sAX0FsD3hV5nUPqHFMwU+JeIfCkiY53bmqrqD86/fwSaBqZqVcrbNYb6d3+PM73wSqFUWshds4gkAl2Bz6gh33Wxa4Yq/K6DLaDXJH1VtRswCLhbRPoV3qmO32khPea0Jlyj02ygDdAF+AF4LrDVqRoiEg0sAu5X1WOF94Xqd+3hmqv0uw62gL4faFXodUvntpCjqvud//4JeAfHz6+Drp+ezn//FLgaVhlv1xiy372qHlTVfFUtAObyv5/aIXPNIhKBI7Clqepi5+aQ/q49XXNVf9fBFtC/ANqKSJKIRAI3AEsDXCe/E5F6IlLf9Tfwa2Azjmsd7Sw2Gng3MDWsUt6ucSlwk3MERC/gaKGf60GtWH74Nzi+a3Bc8w0iUltEkoC2wOfVXb/KEhEBXga2qerzhXaF7Hft7Zqr/LsOdG9wBXqPB+PoMd4FTAp0faroGlvj6PH++v/bt3sThKEoDMPvDFplD0sX0DUyhnNkAguX0B1CQgpxFJsU9wg2sfCHi4f3gXQpzsclH+SQANMjJ7AGLsANOAOr2rN+mPNEee28U3aG7VJGyhcPXZz7CGxqz//FzMfINMSD3Tzdf4jMV2BXe/43M28p65QB6OPaZz7rF5l/etb++i9JSfzbykWStMBCl6QkLHRJSsJCl6QkLHRJSsJCl6QkLHRJSmIGqlNQjGSMBa4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'go', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'go', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R19IJQSYoW7J"
      },
      "source": [
        "#Download the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1_รอบแรก_Gender_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1_รอบแรก_Gender_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}