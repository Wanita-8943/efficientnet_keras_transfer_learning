{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/%E0%B9%82%E0%B8%AD%E0%B9%80%E0%B8%84_1G_MAE_dataframe_Gender_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "e418f4c4-ad89-434e-e300-81900e6b7439"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "YZWXwjXeGxZP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "9a62888e-66ce-4883-9076-735b3f76e375"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 792, done.\u001b[K\n",
            "remote: Counting objects: 100% (314/314), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 792 (delta 225), reused 248 (delta 187), pack-reused 478\u001b[K\n",
            "Receiving objects: 100% (792/792), 13.36 MiB | 14.16 MiB/s, done.\n",
            "Resolving deltas: 100% (465/465), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "tjZBRnfo3bN0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "hNZAzbDp3lgA",
        "outputId": "d78cb399-39de-4df3-f1e4-c93e54fd46ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "54cccc6d-3caa-4bc3-d2ab-0451e872d7e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,923\n",
            "Trainable params: 4,031,907\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "22009afc-039f-41ba-d0ae-223e092d9849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 215\n",
            "This is the number of trainable layers after freezing the conv base: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD76D6c_79py",
        "outputId": "2f8fb2be-8838-4cfc-83af-f28055c7713f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Gender.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skoKhKJDngAZ",
        "outputId": "56d869ba-ef79-4a3d-f08e-d48d88b87b04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         0         V1.jpg   \n",
              "1           2               1          7  Y07F         0    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         0         V2.jpg   \n",
              "3           4               2          7  Y07F         0    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25  Y25M        18  Flip_J463.jpg   \n",
              "4746      122              78         25  Y25M        18       J464.jpg   \n",
              "4747      123              78         25  Y25M        18  Flip_J464.jpg   \n",
              "4748      124              79         25  Y25M        18       J465.jpg   \n",
              "4749      125              79         25  Y25M        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee38628b-71ad-4641-9c27-4811f1903a1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee38628b-71ad-4641-9c27-4811f1903a1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee38628b-71ad-4641-9c27-4811f1903a1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee38628b-71ad-4641-9c27-4811f1903a1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[df['Fig_Age'].between(1,75)]\n",
        "val = df[df['Fig_Age'].between(76,100)]"
      ],
      "metadata": {
        "id": "Z1zBw01Gl8Ac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/TVT_Gender\"\n",
        "os.chdir(DATA_PATH)\n",
        "train_dir = os.path.join(DATA_PATH, 'train')\n",
        "print(train_dir)\n",
        "validation_dir = os.path.join(DATA_PATH, 'validation')\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0g-8iOnMC4",
        "outputId": "4413ac01-ff6f-4c7b-a645-af24770ed979"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TVT_Gender/train\n",
            "/content/drive/My Drive/TVT_Gender/validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = '/content/drive/MyDrive/TVT_Male125'\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Directories for our training,\n",
        "# # validation and test splits\n",
        "# train_dir = os.path.join(base_dir, 'train')\n",
        "# os.makedirs(train_dir, exist_ok=True)\n",
        "# validation_dir = os.path.join(base_dir, 'validation')\n",
        "# os.makedirs(validation_dir, exist_ok=True)\n",
        "# test_dir = os.path.join(base_dir, 'test')\n",
        "# os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe = train,\n",
        "        directory = train_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe = val,\n",
        "        directory = validation_dir,\n",
        "        x_col = 'Path_filename',\n",
        "        y_col = 'Class_Re',\n",
        "        class_mode = 'other',\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nVlmAszntK_",
        "outputId": "80e7caba-3b33-427f-99da-26e7ac5c78d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 validated image filenames.\n",
            "Found 950 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse',\n",
        "          optimizer=Adam(lr=2e-6),\n",
        "          metrics=['mae'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "c68e12c0-1853-48f5-919f-f5b27bc9b6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-19-90b2ae0efec2>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 235s 1s/step - loss: 98.7054 - mae: 8.3626 - val_loss: 95.5589 - val_mae: 8.1934\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 41s 228ms/step - loss: 92.7568 - mae: 8.0434 - val_loss: 90.3930 - val_mae: 7.9266\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 87.4457 - mae: 7.7717 - val_loss: 85.0903 - val_mae: 7.6565\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 39s 214ms/step - loss: 82.4977 - mae: 7.5121 - val_loss: 80.5022 - val_mae: 7.4033\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 77.9801 - mae: 7.2626 - val_loss: 75.7112 - val_mae: 7.1549\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 73.7344 - mae: 7.0511 - val_loss: 71.5926 - val_mae: 6.9365\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 69.5753 - mae: 6.8294 - val_loss: 67.3504 - val_mae: 6.7112\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 66.0207 - mae: 6.6393 - val_loss: 63.8297 - val_mae: 6.5210\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 62.4718 - mae: 6.4598 - val_loss: 60.5178 - val_mae: 6.3542\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 59.0943 - mae: 6.2830 - val_loss: 57.7208 - val_mae: 6.2107\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 56.1618 - mae: 6.1220 - val_loss: 54.8210 - val_mae: 6.0471\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 53.3836 - mae: 5.9743 - val_loss: 51.7268 - val_mae: 5.8874\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 50.7528 - mae: 5.8421 - val_loss: 49.3226 - val_mae: 5.7648\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 48.4154 - mae: 5.7198 - val_loss: 47.1239 - val_mae: 5.6427\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 46.1325 - mae: 5.5882 - val_loss: 45.3129 - val_mae: 5.5451\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 41s 228ms/step - loss: 44.1811 - mae: 5.4922 - val_loss: 43.2748 - val_mae: 5.4500\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 42.3459 - mae: 5.3982 - val_loss: 41.4093 - val_mae: 5.3466\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 40.8302 - mae: 5.3164 - val_loss: 39.9864 - val_mae: 5.2642\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 39.2256 - mae: 5.2231 - val_loss: 38.6764 - val_mae: 5.1989\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 38.0008 - mae: 5.1653 - val_loss: 37.4469 - val_mae: 5.1429\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 36.7121 - mae: 5.1011 - val_loss: 36.2120 - val_mae: 5.0803\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 35.7028 - mae: 5.0489 - val_loss: 35.1235 - val_mae: 5.0158\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 34.7346 - mae: 4.9934 - val_loss: 34.3943 - val_mae: 4.9727\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 33.9356 - mae: 4.9465 - val_loss: 33.6546 - val_mae: 4.9403\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 33.2224 - mae: 4.9159 - val_loss: 32.8512 - val_mae: 4.8952\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 42s 228ms/step - loss: 32.5504 - mae: 4.8823 - val_loss: 32.3314 - val_mae: 4.8733\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 32.0461 - mae: 4.8567 - val_loss: 31.9000 - val_mae: 4.8482\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 31.6044 - mae: 4.8297 - val_loss: 31.5600 - val_mae: 4.8335\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 31.2248 - mae: 4.8031 - val_loss: 31.1624 - val_mae: 4.8035\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.9398 - mae: 4.7876 - val_loss: 30.9161 - val_mae: 4.7875\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 30.7833 - mae: 4.7849 - val_loss: 30.7520 - val_mae: 4.7890\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 30.5654 - mae: 4.7759 - val_loss: 30.5177 - val_mae: 4.7761\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 41s 227ms/step - loss: 30.4213 - mae: 4.7700 - val_loss: 30.3341 - val_mae: 4.7717\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.2620 - mae: 4.7622 - val_loss: 30.2421 - val_mae: 4.7616\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.2106 - mae: 4.7610 - val_loss: 30.0284 - val_mae: 4.7476\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.1870 - mae: 4.7604 - val_loss: 30.1175 - val_mae: 4.7544\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.1540 - mae: 4.7599 - val_loss: 30.2156 - val_mae: 4.7669\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 30.0688 - mae: 4.7496 - val_loss: 30.0944 - val_mae: 4.7509\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 39s 215ms/step - loss: 30.0561 - mae: 4.7485 - val_loss: 30.0363 - val_mae: 4.7454\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 30.0541 - mae: 4.7470 - val_loss: 29.9330 - val_mae: 4.7375\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 29.9531 - mae: 4.7372 - val_loss: 29.9576 - val_mae: 4.7374\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 30.0301 - mae: 4.7441 - val_loss: 29.9496 - val_mae: 4.7384\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 44s 238ms/step - loss: 30.0411 - mae: 4.7464 - val_loss: 29.9278 - val_mae: 4.7349\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 30.0543 - mae: 4.7470 - val_loss: 29.9728 - val_mae: 4.7364\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 29.9989 - mae: 4.7385 - val_loss: 30.0489 - val_mae: 4.7416\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 29.9475 - mae: 4.7339 - val_loss: 30.0875 - val_mae: 4.7446\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 29.9724 - mae: 4.7304 - val_loss: 30.0576 - val_mae: 4.7429\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 29.9789 - mae: 4.7349 - val_loss: 29.9138 - val_mae: 4.7269\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 29.9749 - mae: 4.7359 - val_loss: 30.0949 - val_mae: 4.7442\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 30.0272 - mae: 4.7411 - val_loss: 30.1133 - val_mae: 4.7469\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 29.9696 - mae: 4.7336 - val_loss: 30.0308 - val_mae: 4.7406\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 29.9895 - mae: 4.7346 - val_loss: 29.8440 - val_mae: 4.7220\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 29.9984 - mae: 4.7366 - val_loss: 30.0477 - val_mae: 4.7429\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0465 - mae: 4.7412 - val_loss: 29.9756 - val_mae: 4.7385\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.0443 - mae: 4.7406 - val_loss: 30.1359 - val_mae: 4.7507\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0394 - mae: 4.7416 - val_loss: 30.0181 - val_mae: 4.7390\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0075 - mae: 4.7376 - val_loss: 29.8761 - val_mae: 4.7283\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 30.0247 - mae: 4.7397 - val_loss: 29.9631 - val_mae: 4.7326\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 44s 240ms/step - loss: 30.0232 - mae: 4.7394 - val_loss: 30.0561 - val_mae: 4.7427\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 30.0522 - mae: 4.7428 - val_loss: 29.9841 - val_mae: 4.7363\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 29.9300 - mae: 4.7302 - val_loss: 29.9767 - val_mae: 4.7352\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 30.0102 - mae: 4.7381 - val_loss: 29.9670 - val_mae: 4.7322\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 29.9289 - mae: 4.7316 - val_loss: 30.1037 - val_mae: 4.7460\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 29.9747 - mae: 4.7336 - val_loss: 29.9907 - val_mae: 4.7386\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0493 - mae: 4.7424 - val_loss: 29.9540 - val_mae: 4.7356\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 29.9202 - mae: 4.7296 - val_loss: 29.9754 - val_mae: 4.7349\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 29.9264 - mae: 4.7312 - val_loss: 30.0583 - val_mae: 4.7427\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 29.9870 - mae: 4.7360 - val_loss: 30.0105 - val_mae: 4.7417\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 30.0049 - mae: 4.7394 - val_loss: 30.0182 - val_mae: 4.7384\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 29.9317 - mae: 4.7304 - val_loss: 29.9668 - val_mae: 4.7384\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 30.0526 - mae: 4.7439 - val_loss: 30.0359 - val_mae: 4.7379\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0178 - mae: 4.7376 - val_loss: 29.9968 - val_mae: 4.7409\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 30.0055 - mae: 4.7375 - val_loss: 29.9715 - val_mae: 4.7343\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0263 - mae: 4.7396 - val_loss: 30.1525 - val_mae: 4.7524\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 42s 235ms/step - loss: 29.9545 - mae: 4.7330 - val_loss: 30.0783 - val_mae: 4.7438\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 29.9113 - mae: 4.7284 - val_loss: 29.9321 - val_mae: 4.7313\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 30.0364 - mae: 4.7407 - val_loss: 30.0401 - val_mae: 4.7397\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0579 - mae: 4.7419 - val_loss: 30.0859 - val_mae: 4.7449\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 29.9462 - mae: 4.7321 - val_loss: 30.0053 - val_mae: 4.7405\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 29.9725 - mae: 4.7340 - val_loss: 29.9703 - val_mae: 4.7331\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 29.9790 - mae: 4.7349 - val_loss: 30.0647 - val_mae: 4.7430\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 43s 232ms/step - loss: 29.9649 - mae: 4.7325 - val_loss: 29.9661 - val_mae: 4.7331\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 41s 229ms/step - loss: 29.9539 - mae: 4.7314 - val_loss: 29.9226 - val_mae: 4.7301\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0127 - mae: 4.7375 - val_loss: 29.9174 - val_mae: 4.7268\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 42s 235ms/step - loss: 29.9846 - mae: 4.7357 - val_loss: 29.9736 - val_mae: 4.7342\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 29.9531 - mae: 4.7326 - val_loss: 29.9059 - val_mae: 4.7283\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 30.0423 - mae: 4.7393 - val_loss: 30.0954 - val_mae: 4.7459\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 30.0183 - mae: 4.7390 - val_loss: 30.1282 - val_mae: 4.7516\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.0243 - mae: 4.7385 - val_loss: 29.8518 - val_mae: 4.7226\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 30.0176 - mae: 4.7384 - val_loss: 29.9356 - val_mae: 4.7280\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 29.9652 - mae: 4.7342 - val_loss: 29.9218 - val_mae: 4.7271\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0572 - mae: 4.7420 - val_loss: 29.9151 - val_mae: 4.7307\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0523 - mae: 4.7444 - val_loss: 30.1071 - val_mae: 4.7453\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 41s 230ms/step - loss: 30.0029 - mae: 4.7367 - val_loss: 30.0762 - val_mae: 4.7481\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 29.9652 - mae: 4.7328 - val_loss: 29.9662 - val_mae: 4.7374\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 30.0507 - mae: 4.7423 - val_loss: 30.0183 - val_mae: 4.7389\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0454 - mae: 4.7419 - val_loss: 30.1037 - val_mae: 4.7463\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 29.9905 - mae: 4.7362 - val_loss: 29.9323 - val_mae: 4.7316\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0844 - mae: 4.7465 - val_loss: 29.9199 - val_mae: 4.7274\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 29.9940 - mae: 4.7370 - val_loss: 30.0849 - val_mae: 4.7461\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 29.9595 - mae: 4.7337 - val_loss: 30.0940 - val_mae: 4.7476\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 29.9814 - mae: 4.7365 - val_loss: 30.0024 - val_mae: 4.7356\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0395 - mae: 4.7405 - val_loss: 30.0889 - val_mae: 4.7439\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.0339 - mae: 4.7404 - val_loss: 29.9298 - val_mae: 4.7313\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0108 - mae: 4.7376 - val_loss: 30.0636 - val_mae: 4.7415\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0076 - mae: 4.7362 - val_loss: 29.9131 - val_mae: 4.7267\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 30.0213 - mae: 4.7387 - val_loss: 30.0519 - val_mae: 4.7405\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 30.0505 - mae: 4.7422 - val_loss: 29.9968 - val_mae: 4.7363\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 29.9364 - mae: 4.7309 - val_loss: 30.0222 - val_mae: 4.7389\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 41s 228ms/step - loss: 30.0795 - mae: 4.7446 - val_loss: 29.9215 - val_mae: 4.7269\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0479 - mae: 4.7408 - val_loss: 29.9792 - val_mae: 4.7357\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 29.9922 - mae: 4.7375 - val_loss: 29.9195 - val_mae: 4.7289\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0278 - mae: 4.7421 - val_loss: 29.9363 - val_mae: 4.7314\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0114 - mae: 4.7382 - val_loss: 29.9566 - val_mae: 4.7320\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 29.9260 - mae: 4.7297 - val_loss: 29.9475 - val_mae: 4.7337\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 30.0518 - mae: 4.7421 - val_loss: 30.0512 - val_mae: 4.7403\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 29.9755 - mae: 4.7346 - val_loss: 30.0180 - val_mae: 4.7385\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 29.9660 - mae: 4.7329 - val_loss: 30.0149 - val_mae: 4.7374\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 30.0108 - mae: 4.7385 - val_loss: 30.1494 - val_mae: 4.7532\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 30.0710 - mae: 4.7450 - val_loss: 30.0029 - val_mae: 4.7369\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 30.0192 - mae: 4.7386 - val_loss: 29.8962 - val_mae: 4.7276\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 30.0115 - mae: 4.7392 - val_loss: 29.9606 - val_mae: 4.7344\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 43s 242ms/step - loss: 30.0239 - mae: 4.7409 - val_loss: 30.0117 - val_mae: 4.7384\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.0157 - mae: 4.7393 - val_loss: 30.0677 - val_mae: 4.7416\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 30.0402 - mae: 4.7410 - val_loss: 30.0140 - val_mae: 4.7365\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 30.0242 - mae: 4.7403 - val_loss: 30.0108 - val_mae: 4.7378\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 30.0556 - mae: 4.7434 - val_loss: 29.9533 - val_mae: 4.7293\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 30.0124 - mae: 4.7397 - val_loss: 29.9089 - val_mae: 4.7273\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 29.9552 - mae: 4.7319 - val_loss: 30.0222 - val_mae: 4.7406\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 29.9778 - mae: 4.7339 - val_loss: 30.0743 - val_mae: 4.7443\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 29.9828 - mae: 4.7350 - val_loss: 29.9849 - val_mae: 4.7376\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 30.0620 - mae: 4.7431 - val_loss: 30.0693 - val_mae: 4.7452\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 30.0068 - mae: 4.7372 - val_loss: 29.9831 - val_mae: 4.7331\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 30.0202 - mae: 4.7397 - val_loss: 30.0571 - val_mae: 4.7459\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 30.0374 - mae: 4.7401 - val_loss: 29.8973 - val_mae: 4.7257\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0188 - mae: 4.7389 - val_loss: 30.0741 - val_mae: 4.7460\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 30.0138 - mae: 4.7363 - val_loss: 30.0477 - val_mae: 4.7405\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 29.9733 - mae: 4.7352 - val_loss: 30.0252 - val_mae: 4.7418\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 29.9908 - mae: 4.7361 - val_loss: 30.0222 - val_mae: 4.7385\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 29.9858 - mae: 4.7340 - val_loss: 29.9683 - val_mae: 4.7335\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 30.0014 - mae: 4.7374 - val_loss: 30.0965 - val_mae: 4.7455\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 29.9662 - mae: 4.7329 - val_loss: 29.8308 - val_mae: 4.7226\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0275 - mae: 4.7395 - val_loss: 30.0583 - val_mae: 4.7405\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 29.9646 - mae: 4.7339 - val_loss: 29.9408 - val_mae: 4.7312\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 30.0193 - mae: 4.7396 - val_loss: 30.0574 - val_mae: 4.7420\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 29.9975 - mae: 4.7376 - val_loss: 30.0711 - val_mae: 4.7452\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 29.9698 - mae: 4.7352 - val_loss: 29.9769 - val_mae: 4.7350\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 30.0099 - mae: 4.7376 - val_loss: 29.8705 - val_mae: 4.7244\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 30.0567 - mae: 4.7420 - val_loss: 29.9828 - val_mae: 4.7340\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 40s 220ms/step - loss: 30.0188 - mae: 4.7380 - val_loss: 30.0877 - val_mae: 4.7452\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 29.9948 - mae: 4.7374 - val_loss: 29.9995 - val_mae: 4.7410\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 29.9801 - mae: 4.7354 - val_loss: 30.0551 - val_mae: 4.7438\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 30.0432 - mae: 4.7418 - val_loss: 29.9689 - val_mae: 4.7327\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 29.9744 - mae: 4.7343 - val_loss: 29.9894 - val_mae: 4.7355\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 30.0320 - mae: 4.7407 - val_loss: 29.9673 - val_mae: 4.7321\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 29.9666 - mae: 4.7325 - val_loss: 29.9376 - val_mae: 4.7323\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 29.9989 - mae: 4.7367 - val_loss: 29.8485 - val_mae: 4.7214\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 29.9975 - mae: 4.7367 - val_loss: 30.0710 - val_mae: 4.7426\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 30.0579 - mae: 4.7456 - val_loss: 29.9042 - val_mae: 4.7270\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 30.0100 - mae: 4.7388 - val_loss: 29.9629 - val_mae: 4.7320\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 30.0214 - mae: 4.7400 - val_loss: 30.0272 - val_mae: 4.7413\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 43s 242ms/step - loss: 30.0910 - mae: 4.7473 - val_loss: 29.8886 - val_mae: 4.7264\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 30.0183 - mae: 4.7411 - val_loss: 29.8400 - val_mae: 4.7225\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 39s 215ms/step - loss: 29.9441 - mae: 4.7314 - val_loss: 29.8727 - val_mae: 4.7272\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 29.9853 - mae: 4.7363 - val_loss: 29.9926 - val_mae: 4.7368\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 39s 217ms/step - loss: 30.0611 - mae: 4.7444 - val_loss: 29.9248 - val_mae: 4.7278\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 44s 247ms/step - loss: 30.0490 - mae: 4.7413 - val_loss: 29.8979 - val_mae: 4.7286\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 29.9237 - mae: 4.7306 - val_loss: 30.1123 - val_mae: 4.7462\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 29.9713 - mae: 4.7358 - val_loss: 29.9661 - val_mae: 4.7378\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 29.5925 - mae: 4.6988 - val_loss: 30.0565 - val_mae: 4.7452\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 26.7798 - mae: 4.4017 - val_loss: 19.2286 - val_mae: 3.6210\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 20.0221 - mae: 3.6991 - val_loss: 18.5644 - val_mae: 3.4463\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 18.4801 - mae: 3.5652 - val_loss: 18.2966 - val_mae: 3.3842\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 17.8816 - mae: 3.5023 - val_loss: 19.4942 - val_mae: 3.4423\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 16.9405 - mae: 3.3872 - val_loss: 29.5869 - val_mae: 4.2308\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 15.9540 - mae: 3.2826 - val_loss: 15.4836 - val_mae: 3.1234\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 15.7820 - mae: 3.2847 - val_loss: 19.1791 - val_mae: 3.3834\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 15.2789 - mae: 3.2239 - val_loss: 23.7847 - val_mae: 3.7593\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 15.5132 - mae: 3.2580 - val_loss: 13.7267 - val_mae: 3.0212\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 14.6879 - mae: 3.1708 - val_loss: 13.0008 - val_mae: 2.9680\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 14.9386 - mae: 3.1945 - val_loss: 13.2343 - val_mae: 2.9411\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 14.7740 - mae: 3.1612 - val_loss: 12.3082 - val_mae: 2.8771\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 14.4196 - mae: 3.1227 - val_loss: 12.0040 - val_mae: 2.8377\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 14.5583 - mae: 3.1367 - val_loss: 12.5823 - val_mae: 2.9320\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 14.2956 - mae: 3.1155 - val_loss: 12.7404 - val_mae: 2.9608\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 13.4767 - mae: 3.0316 - val_loss: 12.0578 - val_mae: 2.8309\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 13.8418 - mae: 3.0629 - val_loss: 17.7447 - val_mae: 3.2294\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 13.7081 - mae: 3.0423 - val_loss: 16.3010 - val_mae: 3.1043\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 13.5715 - mae: 3.0227 - val_loss: 13.7889 - val_mae: 2.9151\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 13.6936 - mae: 3.0210 - val_loss: 12.5193 - val_mae: 2.8240\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 13.8249 - mae: 3.0029 - val_loss: 11.5461 - val_mae: 2.7691\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 46s 257ms/step - loss: 13.3550 - mae: 2.9779 - val_loss: 11.9829 - val_mae: 2.8388\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 13.5273 - mae: 3.0069 - val_loss: 12.3533 - val_mae: 2.8182\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 13.6955 - mae: 3.0163 - val_loss: 11.8642 - val_mae: 2.8297\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 13.7607 - mae: 3.0153 - val_loss: 12.9760 - val_mae: 2.8714\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 13.7589 - mae: 3.0256 - val_loss: 11.8544 - val_mae: 2.7864\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 13.6407 - mae: 2.9899 - val_loss: 16.4303 - val_mae: 3.1068\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 14.1456 - mae: 3.0319 - val_loss: 12.2420 - val_mae: 2.8603\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 38s 212ms/step - loss: 13.5180 - mae: 2.9897 - val_loss: 12.9094 - val_mae: 2.8502\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 39s 218ms/step - loss: 13.8734 - mae: 3.0138 - val_loss: 11.9610 - val_mae: 2.8058\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 44s 239ms/step - loss: 13.3325 - mae: 2.9646 - val_loss: 13.9256 - val_mae: 2.9257\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 13.7582 - mae: 3.0069 - val_loss: 12.3317 - val_mae: 2.8135\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 13.6143 - mae: 2.9904 - val_loss: 11.7236 - val_mae: 2.7825\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 43s 238ms/step - loss: 13.3473 - mae: 2.9825 - val_loss: 11.8784 - val_mae: 2.7838\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 13.7814 - mae: 3.0206 - val_loss: 17.8200 - val_mae: 3.2273\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 13.6748 - mae: 3.0005 - val_loss: 11.5930 - val_mae: 2.7840\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 14.1148 - mae: 3.0221 - val_loss: 11.9131 - val_mae: 2.8466\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 14.4733 - mae: 3.0816 - val_loss: 12.1116 - val_mae: 2.7866\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 13.9325 - mae: 3.0193 - val_loss: 11.8009 - val_mae: 2.8231\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 44s 244ms/step - loss: 13.5954 - mae: 2.9734 - val_loss: 11.4168 - val_mae: 2.7557\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 13.3546 - mae: 2.9839 - val_loss: 11.2431 - val_mae: 2.7563\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 13.0492 - mae: 2.9371 - val_loss: 11.5859 - val_mae: 2.7900\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 13.3609 - mae: 2.9757 - val_loss: 12.9568 - val_mae: 2.8538\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 13.8510 - mae: 3.0111 - val_loss: 11.6266 - val_mae: 2.7901\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 13.6445 - mae: 2.9813 - val_loss: 15.7195 - val_mae: 3.0564\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 43s 235ms/step - loss: 13.5576 - mae: 2.9891 - val_loss: 18.3248 - val_mae: 3.2380\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 13.9117 - mae: 3.0106 - val_loss: 13.2768 - val_mae: 2.8796\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 13.6860 - mae: 2.9981 - val_loss: 11.7569 - val_mae: 2.7797\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 13.3475 - mae: 2.9777 - val_loss: 11.4014 - val_mae: 2.7490\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 44s 245ms/step - loss: 13.4374 - mae: 2.9722 - val_loss: 12.4430 - val_mae: 2.8171\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 42s 229ms/step - loss: 13.1864 - mae: 2.9576 - val_loss: 11.4619 - val_mae: 2.7567\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 13.8311 - mae: 3.0202 - val_loss: 14.2490 - val_mae: 3.1165\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 42s 230ms/step - loss: 13.7106 - mae: 3.0239 - val_loss: 11.7385 - val_mae: 2.7760\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 12.9792 - mae: 2.9133 - val_loss: 13.6992 - val_mae: 2.9026\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 43s 240ms/step - loss: 13.9676 - mae: 3.0211 - val_loss: 20.7708 - val_mae: 3.4474\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 41s 228ms/step - loss: 13.3244 - mae: 2.9483 - val_loss: 12.3422 - val_mae: 2.8141\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 13.6764 - mae: 2.9957 - val_loss: 12.0522 - val_mae: 2.8593\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 42s 235ms/step - loss: 14.4668 - mae: 3.0835 - val_loss: 13.2759 - val_mae: 2.8712\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 13.0307 - mae: 2.9440 - val_loss: 14.0446 - val_mae: 2.9235\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 41s 226ms/step - loss: 13.6239 - mae: 2.9918 - val_loss: 12.4835 - val_mae: 2.8300\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 45s 247ms/step - loss: 13.4244 - mae: 2.9630 - val_loss: 17.6491 - val_mae: 3.1881\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 45s 248ms/step - loss: 13.7826 - mae: 2.9877 - val_loss: 11.1744 - val_mae: 2.7413\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 13.5037 - mae: 2.9623 - val_loss: 13.1930 - val_mae: 2.8636\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 44s 237ms/step - loss: 13.5854 - mae: 2.9893 - val_loss: 17.9099 - val_mae: 3.2109\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 42s 232ms/step - loss: 13.0632 - mae: 2.9394 - val_loss: 11.5103 - val_mae: 2.7557\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 42s 234ms/step - loss: 13.9545 - mae: 3.0052 - val_loss: 26.8729 - val_mae: 3.9096\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 13.2093 - mae: 2.9481 - val_loss: 20.2931 - val_mae: 3.4143\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 44s 243ms/step - loss: 14.0222 - mae: 2.9846 - val_loss: 21.8420 - val_mae: 3.5387\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 13.3527 - mae: 2.9696 - val_loss: 12.7173 - val_mae: 2.8264\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 43s 233ms/step - loss: 13.7223 - mae: 2.9673 - val_loss: 16.8064 - val_mae: 3.1143\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 42s 231ms/step - loss: 13.2919 - mae: 2.9728 - val_loss: 14.3735 - val_mae: 2.9447\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 44s 241ms/step - loss: 13.3455 - mae: 2.9724 - val_loss: 12.8192 - val_mae: 2.8590\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 44s 246ms/step - loss: 13.0878 - mae: 2.9645 - val_loss: 29.0876 - val_mae: 4.1011\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 43s 239ms/step - loss: 13.7259 - mae: 3.0018 - val_loss: 11.0469 - val_mae: 2.7397\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 43s 234ms/step - loss: 13.3297 - mae: 2.9604 - val_loss: 11.3739 - val_mae: 2.7506\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 43s 241ms/step - loss: 13.5599 - mae: 2.9903 - val_loss: 11.3705 - val_mae: 2.7479\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 44s 242ms/step - loss: 13.5916 - mae: 2.9764 - val_loss: 11.2762 - val_mae: 2.7345\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 43s 236ms/step - loss: 13.4320 - mae: 2.9779 - val_loss: 15.6479 - val_mae: 3.0422\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 42s 233ms/step - loss: 13.7629 - mae: 2.9964 - val_loss: 24.3489 - val_mae: 3.7315\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 43s 237ms/step - loss: 13.3807 - mae: 2.9795 - val_loss: 11.8469 - val_mae: 2.7747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "\n",
        "epochs_x = range(len(loss))\n",
        "\n",
        "\n",
        "plt.plot(epochs_x, mae, 'go', label='Training MAE')\n",
        "plt.plot(epochs_x, val_mae, 'k', label='Validation MAE')\n",
        "plt.title('Training and validation MeanAbsoluteError')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs_x, loss, 'go', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "255dbe88-08eb-4ef6-9382-1c8b4a917a00"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x"
      ],
      "metadata": {
        "id": "N_sP_ZmSY-Jv",
        "outputId": "5d829a28-e8a2-4281-9824-64697dab588f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 250)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/1_New_MAE_Flimpano_Gender18_500.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5YxZ-5QjQ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1.1_รอบแรก_Flimpano_Male125_250.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wY_pDlxkRwxS"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}