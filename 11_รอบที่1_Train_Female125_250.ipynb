{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/efficientnet_keras_transfer_learning/blob/master/11_%E0%B8%A3%E0%B8%AD%E0%B8%9A%E0%B8%97%E0%B8%B5%E0%B9%881_Train_Female125_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เรียกใช้ CSV"
      ],
      "metadata": {
        "id": "ow7eWoNw6U-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "c98e2db4-c242-49ac-929c-b0484942081c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/Data_Female_125.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "3fd156b6-a25e-40e1-faf7-9d2270cc957c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class       Filename  \\\n",
              "0           1               1          7  Y07F         V1.jpg   \n",
              "1           2               1          7  Y07F    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         V2.jpg   \n",
              "3           4               2          7  Y07F    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         V3.jpg   \n",
              "...       ...             ...        ...   ...            ...   \n",
              "2370      121              65         25  Y25F  Flip_J145.jpg   \n",
              "2371      122              66         25  Y25F  Flip_J149.jpg   \n",
              "2372      123              67         25  Y25F  Flip_J158.jpg   \n",
              "2373      124              68         25  Y25F  Flip_J177.jpg   \n",
              "2374      125              69         25  Y25F  Flip_J180.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/cut_panoramic/7 year/7...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "2370  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2371  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2372  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2373  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "2374  /content/drive/My Drive/cut_panoramic/25 year/...  เพศหญิง     Lt  \n",
              "\n",
              "[2375 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ba5b988-1acd-45ff-badd-8374e4a68b71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/7 year/7...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>121</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J145.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2371</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J149.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>123</td>\n",
              "      <td>67</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J158.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2373</th>\n",
              "      <td>124</td>\n",
              "      <td>68</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J177.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25F</td>\n",
              "      <td>Flip_J180.jpg</td>\n",
              "      <td>/content/drive/My Drive/cut_panoramic/25 year/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Lt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2375 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ba5b988-1acd-45ff-badd-8374e4a68b71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ba5b988-1acd-45ff-badd-8374e4a68b71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ba5b988-1acd-45ff-badd-8374e4a68b71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "5qxePnnn7TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ],
      "metadata": {
        "id": "RooqSdBc7QHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 400\n",
        "NUM_TRAIN = 1425\n",
        "NUM_TEST = 475\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ],
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "edf6c1a1-6429-49d7-f707-d14baebb529c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "uhCmH24AKmQ4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary() #ดู Summary"
      ],
      "metadata": {
        "id": "IIWHby0gKpEq",
        "outputId": "5f041e93-a59c-4d69-dfa7-f513aee7e573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 75, 75, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 75, 75, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 75, 75, 32)  288         ['swish_49[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 32)     0           ['swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 1, 1, 8)      264         ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 1, 1, 8)      0           ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 32)     288         ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 32)     0           ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 75, 75, 32)   0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 75, 75, 16)   512         ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 75, 75, 16)  64          ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 75, 75, 96)   1536        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 75, 75, 96)  384         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 75, 75, 96)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 38, 38, 96)  864         ['swish_52[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 38, 38, 96)  384         ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 38, 38, 96)   0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 96)     0           ['swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 1, 1, 4)      388         ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 1, 1, 4)      0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 96)     480         ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 96)     0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 38, 38, 96)   0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 38, 38, 24)   2304        ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 38, 38, 24)  96          ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 38, 38, 144)  3456        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 38, 38, 144)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 38, 38, 144)  1296       ['swish_55[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 38, 38, 144)  576        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 144)    0           ['swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 1, 1, 6)      0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 144)    0           ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 38, 38, 144)  0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 38, 38, 24)  96          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 38, 38, 24)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 38, 38, 24)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 38, 38, 144)  3456        ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 38, 38, 144)  576        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 19, 19, 144)  3600       ['swish_58[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 144)    0           ['swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 1, 1, 6)      0           ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 144)    0           ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 19, 19, 144)  0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 19, 19, 40)  160         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 19, 19, 240)  960        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 19, 19, 240)  6000       ['swish_61[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 240)    0           ['swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 1, 1, 10)     0           ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 240)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 19, 19, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 19, 19, 40)  160         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 19, 19, 240)  9600        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 19, 19, 240)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 10, 10, 240)  2160       ['swish_64[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 240)    0           ['swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 1, 1, 10)     0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 240)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 10, 10, 240)  0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 10, 10, 80)  320         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 10, 10, 480)  4320       ['swish_67[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 480)    0           ['swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 1, 1, 20)     0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 480)    0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 10, 10, 480)  0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 10, 10, 80)  320         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 10, 10, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 10, 10, 480)  4320       ['swish_70[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 480)    0           ['swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 1, 1, 20)     0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 480)    0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 10, 10, 480)  0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 10, 10, 80)  320         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 10, 10, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 10, 10, 480)  12000      ['swish_73[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 480)    0           ['swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 1, 1, 20)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 480)    0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 10, 10, 480)  0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 10, 10, 112)  448        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 10, 10, 672)  16800      ['swish_76[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 672)    0           ['swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_78 (Swish)               (None, 1, 1, 28)     0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_78[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 10, 10, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 10, 10, 112)  448        ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 10, 10, 672)  75264       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_79 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 10, 10, 672)  16800      ['swish_79[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_80 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_26 (Lambda)             (None, 1, 1, 672)    0           ['swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_26[0][0]']              \n",
            "                                                                                                  \n",
            " swish_81 (Swish)               (None, 1, 1, 28)     0           ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_81[0][0]']               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 10, 10, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 10, 10, 112)  448        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 10, 10, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_82 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 5, 5, 672)   16800       ['swish_82[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_83 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1, 1, 672)    0           ['swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            " swish_84 (Swish)               (None, 1, 1, 28)     0           ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_84[0][0]']               \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 5, 5, 672)    0           ['activation_27[0][0]',          \n",
            "                                                                  'swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   768         ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_85 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_85[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_86 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1, 1, 1152)   0           ['swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            " swish_87 (Swish)               (None, 1, 1, 48)     0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_87[0][0]']               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 5, 5, 1152)   0           ['activation_28[0][0]',          \n",
            "                                                                  'swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   768         ['conv2d_116[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_88 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_88[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_89 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_29 (Lambda)             (None, 1, 1, 1152)   0           ['swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_29[0][0]']              \n",
            "                                                                                                  \n",
            " swish_90 (Swish)               (None, 1, 1, 48)     0           ['conv2d_118[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_90[0][0]']               \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 5, 5, 1152)   0           ['activation_29[0][0]',          \n",
            "                                                                  'swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 192)   768         ['conv2d_120[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_91 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_91[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_92 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_30 (Lambda)             (None, 1, 1, 1152)   0           ['swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_30[0][0]']              \n",
            "                                                                                                  \n",
            " swish_93 (Swish)               (None, 1, 1, 48)     0           ['conv2d_122[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_93[0][0]']               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_123[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 5, 5, 1152)   0           ['activation_30[0][0]',          \n",
            "                                                                  'swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   768         ['conv2d_124[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_94 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_94[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_95 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_31 (Lambda)             (None, 1, 1, 1152)   0           ['swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_31[0][0]']              \n",
            "                                                                                                  \n",
            " swish_96 (Swish)               (None, 1, 1, 48)     0           ['conv2d_126[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_96[0][0]']               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_127[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 5, 5, 1152)   0           ['activation_31[0][0]',          \n",
            "                                                                  'swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_128[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_97 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 4,007,548\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ],
      "metadata": {
        "id": "J36J9EAE7qSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Female125'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Train"
      ],
      "metadata": {
        "id": "bWEnlTSwazL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "xGPrsn9no_pa",
        "outputId": "a86c9867-f7d8-4505-96b9-5eaa8babbe2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1425 images belonging to 19 classes.\n",
            "Found 475 images belonging to 19 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ],
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "NadBB12251jh",
        "outputId": "3d205047-0cf0-49c8-abc9-247bf9ed2b1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "GepWq3yy53t5",
        "outputId": "a2e64f5d-8a64-42e8-cbd6-0435b03bf547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "metadata": {
        "id": "N6qUmmF856ZE",
        "outputId": "653b9c44-6177-4ac4-cbf4-4d28a54f21cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "<ipython-input-32-bbda3a575f01>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "89/89 [==============================] - 78s 806ms/step - loss: 4.5167 - acc: 0.0511 - val_loss: 4.0713 - val_acc: 0.0366\n",
            "Epoch 2/400\n",
            "89/89 [==============================] - 70s 773ms/step - loss: 4.2319 - acc: 0.0639 - val_loss: 3.8217 - val_acc: 0.0366\n",
            "Epoch 3/400\n",
            "89/89 [==============================] - 67s 730ms/step - loss: 4.1311 - acc: 0.0490 - val_loss: 3.7093 - val_acc: 0.0345\n",
            "Epoch 4/400\n",
            "89/89 [==============================] - 67s 732ms/step - loss: 4.0504 - acc: 0.0511 - val_loss: 3.6541 - val_acc: 0.0366\n",
            "Epoch 5/400\n",
            "89/89 [==============================] - 72s 788ms/step - loss: 4.0956 - acc: 0.0575 - val_loss: 3.6107 - val_acc: 0.0409\n",
            "Epoch 6/400\n",
            "89/89 [==============================] - 67s 732ms/step - loss: 4.0204 - acc: 0.0625 - val_loss: 3.5585 - val_acc: 0.0431\n",
            "Epoch 7/400\n",
            "89/89 [==============================] - 67s 737ms/step - loss: 3.8737 - acc: 0.0738 - val_loss: 3.5257 - val_acc: 0.0474\n",
            "Epoch 8/400\n",
            "89/89 [==============================] - 71s 782ms/step - loss: 3.9480 - acc: 0.0617 - val_loss: 3.5331 - val_acc: 0.0474\n",
            "Epoch 9/400\n",
            "89/89 [==============================] - 67s 736ms/step - loss: 4.0052 - acc: 0.0596 - val_loss: 3.4486 - val_acc: 0.0582\n",
            "Epoch 10/400\n",
            "89/89 [==============================] - 67s 736ms/step - loss: 3.9324 - acc: 0.0802 - val_loss: 3.4295 - val_acc: 0.0582\n",
            "Epoch 11/400\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 3.9005 - acc: 0.0660 - val_loss: 3.3854 - val_acc: 0.0539\n",
            "Epoch 12/400\n",
            "89/89 [==============================] - 68s 742ms/step - loss: 3.9138 - acc: 0.0603 - val_loss: 3.3734 - val_acc: 0.0539\n",
            "Epoch 13/400\n",
            "89/89 [==============================] - 68s 740ms/step - loss: 3.7768 - acc: 0.0816 - val_loss: 3.3490 - val_acc: 0.0539\n",
            "Epoch 14/400\n",
            "89/89 [==============================] - 68s 742ms/step - loss: 3.7928 - acc: 0.0681 - val_loss: 3.3121 - val_acc: 0.0560\n",
            "Epoch 15/400\n",
            "89/89 [==============================] - 72s 791ms/step - loss: 3.7634 - acc: 0.0724 - val_loss: 3.2977 - val_acc: 0.0603\n",
            "Epoch 16/400\n",
            "89/89 [==============================] - 67s 736ms/step - loss: 3.7428 - acc: 0.0781 - val_loss: 3.2914 - val_acc: 0.0560\n",
            "Epoch 17/400\n",
            "89/89 [==============================] - 67s 734ms/step - loss: 3.7816 - acc: 0.0745 - val_loss: 3.2598 - val_acc: 0.0625\n",
            "Epoch 18/400\n",
            "89/89 [==============================] - 68s 742ms/step - loss: 3.6460 - acc: 0.0802 - val_loss: 3.2249 - val_acc: 0.0690\n",
            "Epoch 19/400\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 3.7065 - acc: 0.0795 - val_loss: 3.2295 - val_acc: 0.0668\n",
            "Epoch 20/400\n",
            "89/89 [==============================] - 68s 740ms/step - loss: 3.6729 - acc: 0.0724 - val_loss: 3.2102 - val_acc: 0.0625\n",
            "Epoch 21/400\n",
            "89/89 [==============================] - 68s 738ms/step - loss: 3.6384 - acc: 0.0852 - val_loss: 3.1996 - val_acc: 0.0733\n",
            "Epoch 22/400\n",
            "89/89 [==============================] - 68s 740ms/step - loss: 3.5812 - acc: 0.0923 - val_loss: 3.1756 - val_acc: 0.0711\n",
            "Epoch 23/400\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 3.7377 - acc: 0.0688 - val_loss: 3.1610 - val_acc: 0.0754\n",
            "Epoch 24/400\n",
            "89/89 [==============================] - 67s 740ms/step - loss: 3.6144 - acc: 0.0816 - val_loss: 3.1541 - val_acc: 0.0797\n",
            "Epoch 25/400\n",
            "89/89 [==============================] - 67s 735ms/step - loss: 3.5993 - acc: 0.0923 - val_loss: 3.1284 - val_acc: 0.0862\n",
            "Epoch 26/400\n",
            "89/89 [==============================] - 68s 740ms/step - loss: 3.6051 - acc: 0.0774 - val_loss: 3.1153 - val_acc: 0.0841\n",
            "Epoch 27/400\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 3.5199 - acc: 0.0937 - val_loss: 3.0870 - val_acc: 0.0905\n",
            "Epoch 28/400\n",
            "89/89 [==============================] - 67s 737ms/step - loss: 3.5106 - acc: 0.0972 - val_loss: 3.0918 - val_acc: 0.0841\n",
            "Epoch 29/400\n",
            "89/89 [==============================] - 68s 741ms/step - loss: 3.5316 - acc: 0.1015 - val_loss: 3.0917 - val_acc: 0.0884\n",
            "Epoch 30/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 3.5653 - acc: 0.1001 - val_loss: 3.0524 - val_acc: 0.0841\n",
            "Epoch 31/400\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 3.5021 - acc: 0.1022 - val_loss: 3.0242 - val_acc: 0.0948\n",
            "Epoch 32/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.4590 - acc: 0.0923 - val_loss: 3.0189 - val_acc: 0.0948\n",
            "Epoch 33/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.4746 - acc: 0.1065 - val_loss: 3.0210 - val_acc: 0.0905\n",
            "Epoch 34/400\n",
            "89/89 [==============================] - 68s 742ms/step - loss: 3.4994 - acc: 0.0951 - val_loss: 2.9986 - val_acc: 0.0927\n",
            "Epoch 35/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.4932 - acc: 0.1001 - val_loss: 3.0046 - val_acc: 0.0970\n",
            "Epoch 36/400\n",
            "89/89 [==============================] - 68s 747ms/step - loss: 3.5658 - acc: 0.0901 - val_loss: 2.9901 - val_acc: 0.0948\n",
            "Epoch 37/400\n",
            "89/89 [==============================] - 68s 743ms/step - loss: 3.4484 - acc: 0.0894 - val_loss: 2.9825 - val_acc: 0.0927\n",
            "Epoch 38/400\n",
            "89/89 [==============================] - 68s 741ms/step - loss: 3.4121 - acc: 0.1100 - val_loss: 2.9660 - val_acc: 0.0970\n",
            "Epoch 39/400\n",
            "89/89 [==============================] - 72s 795ms/step - loss: 3.4419 - acc: 0.1107 - val_loss: 2.9800 - val_acc: 0.0905\n",
            "Epoch 40/400\n",
            "89/89 [==============================] - 67s 739ms/step - loss: 3.4751 - acc: 0.1008 - val_loss: 2.9807 - val_acc: 0.0991\n",
            "Epoch 41/400\n",
            "89/89 [==============================] - 68s 741ms/step - loss: 3.3983 - acc: 0.1065 - val_loss: 2.9747 - val_acc: 0.0927\n",
            "Epoch 42/400\n",
            "89/89 [==============================] - 68s 747ms/step - loss: 3.4430 - acc: 0.0979 - val_loss: 2.9507 - val_acc: 0.0948\n",
            "Epoch 43/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.3879 - acc: 0.1001 - val_loss: 2.9397 - val_acc: 0.0991\n",
            "Epoch 44/400\n",
            "89/89 [==============================] - 68s 742ms/step - loss: 3.3572 - acc: 0.1150 - val_loss: 2.9509 - val_acc: 0.1034\n",
            "Epoch 45/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.3405 - acc: 0.0944 - val_loss: 2.9387 - val_acc: 0.1099\n",
            "Epoch 46/400\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.3791 - acc: 0.1093 - val_loss: 2.9114 - val_acc: 0.1099\n",
            "Epoch 47/400\n",
            "89/89 [==============================] - 71s 778ms/step - loss: 3.3599 - acc: 0.1079 - val_loss: 2.9259 - val_acc: 0.1099\n",
            "Epoch 48/400\n",
            "89/89 [==============================] - 69s 750ms/step - loss: 3.3412 - acc: 0.1150 - val_loss: 2.8883 - val_acc: 0.1034\n",
            "Epoch 49/400\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.3015 - acc: 0.1128 - val_loss: 2.9082 - val_acc: 0.1078\n",
            "Epoch 50/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 3.3453 - acc: 0.1072 - val_loss: 2.9033 - val_acc: 0.1034\n",
            "Epoch 51/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 3.3087 - acc: 0.1121 - val_loss: 2.9030 - val_acc: 0.1078\n",
            "Epoch 52/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 3.2986 - acc: 0.1264 - val_loss: 2.9047 - val_acc: 0.0970\n",
            "Epoch 53/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 3.2785 - acc: 0.1207 - val_loss: 2.8998 - val_acc: 0.0970\n",
            "Epoch 54/400\n",
            "89/89 [==============================] - 68s 748ms/step - loss: 3.3725 - acc: 0.0994 - val_loss: 2.8735 - val_acc: 0.0991\n",
            "Epoch 55/400\n",
            "89/89 [==============================] - 68s 739ms/step - loss: 3.2912 - acc: 0.1157 - val_loss: 2.8713 - val_acc: 0.1013\n",
            "Epoch 56/400\n",
            "89/89 [==============================] - 68s 748ms/step - loss: 3.2674 - acc: 0.1214 - val_loss: 2.8601 - val_acc: 0.0991\n",
            "Epoch 57/400\n",
            "89/89 [==============================] - 68s 743ms/step - loss: 3.2975 - acc: 0.1143 - val_loss: 2.8654 - val_acc: 0.1056\n",
            "Epoch 58/400\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 3.3244 - acc: 0.1121 - val_loss: 2.8528 - val_acc: 0.1056\n",
            "Epoch 59/400\n",
            "89/89 [==============================] - 68s 742ms/step - loss: 3.2790 - acc: 0.1157 - val_loss: 2.8574 - val_acc: 0.1056\n",
            "Epoch 60/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.2799 - acc: 0.1242 - val_loss: 2.8584 - val_acc: 0.0991\n",
            "Epoch 61/400\n",
            "89/89 [==============================] - 68s 768ms/step - loss: 3.1991 - acc: 0.1327 - val_loss: 2.8393 - val_acc: 0.1078\n",
            "Epoch 62/400\n",
            "89/89 [==============================] - 73s 799ms/step - loss: 3.2890 - acc: 0.1114 - val_loss: 2.8444 - val_acc: 0.1056\n",
            "Epoch 63/400\n",
            "89/89 [==============================] - 69s 757ms/step - loss: 3.2298 - acc: 0.1164 - val_loss: 2.8505 - val_acc: 0.0970\n",
            "Epoch 64/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 3.2638 - acc: 0.1164 - val_loss: 2.8459 - val_acc: 0.1056\n",
            "Epoch 65/400\n",
            "89/89 [==============================] - 68s 747ms/step - loss: 3.1439 - acc: 0.1306 - val_loss: 2.8451 - val_acc: 0.1013\n",
            "Epoch 66/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.2587 - acc: 0.1143 - val_loss: 2.8161 - val_acc: 0.1099\n",
            "Epoch 67/400\n",
            "89/89 [==============================] - 68s 746ms/step - loss: 3.1760 - acc: 0.1249 - val_loss: 2.8343 - val_acc: 0.0991\n",
            "Epoch 68/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 3.2770 - acc: 0.1214 - val_loss: 2.8335 - val_acc: 0.1013\n",
            "Epoch 69/400\n",
            "89/89 [==============================] - 68s 749ms/step - loss: 3.1806 - acc: 0.1341 - val_loss: 2.8170 - val_acc: 0.1078\n",
            "Epoch 70/400\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 3.1695 - acc: 0.1370 - val_loss: 2.8188 - val_acc: 0.1056\n",
            "Epoch 71/400\n",
            "89/89 [==============================] - 68s 743ms/step - loss: 3.2386 - acc: 0.1171 - val_loss: 2.8294 - val_acc: 0.1056\n",
            "Epoch 72/400\n",
            "89/89 [==============================] - 69s 761ms/step - loss: 3.1571 - acc: 0.1370 - val_loss: 2.8299 - val_acc: 0.1013\n",
            "Epoch 73/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 3.1876 - acc: 0.1235 - val_loss: 2.8153 - val_acc: 0.1034\n",
            "Epoch 74/400\n",
            "89/89 [==============================] - 74s 814ms/step - loss: 3.1263 - acc: 0.1391 - val_loss: 2.8188 - val_acc: 0.0970\n",
            "Epoch 75/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 3.1899 - acc: 0.1313 - val_loss: 2.8010 - val_acc: 0.1034\n",
            "Epoch 76/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 3.1169 - acc: 0.1348 - val_loss: 2.8195 - val_acc: 0.0970\n",
            "Epoch 77/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.1126 - acc: 0.1306 - val_loss: 2.8118 - val_acc: 0.1078\n",
            "Epoch 78/400\n",
            "89/89 [==============================] - 70s 741ms/step - loss: 3.1646 - acc: 0.1299 - val_loss: 2.8081 - val_acc: 0.1034\n",
            "Epoch 79/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 3.1770 - acc: 0.1278 - val_loss: 2.8057 - val_acc: 0.1056\n",
            "Epoch 80/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 3.0830 - acc: 0.1334 - val_loss: 2.7917 - val_acc: 0.1056\n",
            "Epoch 81/400\n",
            "89/89 [==============================] - 72s 790ms/step - loss: 3.1022 - acc: 0.1469 - val_loss: 2.7808 - val_acc: 0.1099\n",
            "Epoch 82/400\n",
            "89/89 [==============================] - 68s 747ms/step - loss: 3.1540 - acc: 0.1171 - val_loss: 2.7817 - val_acc: 0.1034\n",
            "Epoch 83/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.1374 - acc: 0.1377 - val_loss: 2.7843 - val_acc: 0.1034\n",
            "Epoch 84/400\n",
            "89/89 [==============================] - 68s 744ms/step - loss: 3.1712 - acc: 0.1384 - val_loss: 2.7895 - val_acc: 0.1013\n",
            "Epoch 85/400\n",
            "89/89 [==============================] - 68s 744ms/step - loss: 3.1519 - acc: 0.1242 - val_loss: 2.7863 - val_acc: 0.1034\n",
            "Epoch 86/400\n",
            "89/89 [==============================] - 68s 745ms/step - loss: 3.0665 - acc: 0.1405 - val_loss: 2.7925 - val_acc: 0.1142\n",
            "Epoch 87/400\n",
            "89/89 [==============================] - 68s 749ms/step - loss: 3.2219 - acc: 0.1207 - val_loss: 2.7918 - val_acc: 0.1034\n",
            "Epoch 88/400\n",
            "89/89 [==============================] - 68s 749ms/step - loss: 3.0980 - acc: 0.1377 - val_loss: 2.7958 - val_acc: 0.1121\n",
            "Epoch 89/400\n",
            "89/89 [==============================] - 68s 748ms/step - loss: 3.0654 - acc: 0.1285 - val_loss: 2.7801 - val_acc: 0.1185\n",
            "Epoch 90/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 3.0560 - acc: 0.1476 - val_loss: 2.7673 - val_acc: 0.1142\n",
            "Epoch 91/400\n",
            "89/89 [==============================] - 69s 749ms/step - loss: 3.0927 - acc: 0.1540 - val_loss: 2.7802 - val_acc: 0.1142\n",
            "Epoch 92/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 3.1033 - acc: 0.1391 - val_loss: 2.7857 - val_acc: 0.1121\n",
            "Epoch 93/400\n",
            "89/89 [==============================] - 73s 807ms/step - loss: 3.0815 - acc: 0.1370 - val_loss: 2.7758 - val_acc: 0.1164\n",
            "Epoch 94/400\n",
            "89/89 [==============================] - 69s 749ms/step - loss: 3.0985 - acc: 0.1313 - val_loss: 2.7660 - val_acc: 0.1121\n",
            "Epoch 95/400\n",
            "89/89 [==============================] - 68s 744ms/step - loss: 3.0701 - acc: 0.1299 - val_loss: 2.7790 - val_acc: 0.1142\n",
            "Epoch 96/400\n",
            "89/89 [==============================] - 68s 744ms/step - loss: 3.0294 - acc: 0.1448 - val_loss: 2.7466 - val_acc: 0.1142\n",
            "Epoch 97/400\n",
            "89/89 [==============================] - 74s 808ms/step - loss: 3.0593 - acc: 0.1292 - val_loss: 2.7572 - val_acc: 0.1185\n",
            "Epoch 98/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 3.0182 - acc: 0.1590 - val_loss: 2.7616 - val_acc: 0.1207\n",
            "Epoch 99/400\n",
            "89/89 [==============================] - 69s 750ms/step - loss: 3.1327 - acc: 0.1178 - val_loss: 2.7654 - val_acc: 0.1142\n",
            "Epoch 100/400\n",
            "89/89 [==============================] - 68s 748ms/step - loss: 3.0749 - acc: 0.1412 - val_loss: 2.7562 - val_acc: 0.1228\n",
            "Epoch 101/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 3.0522 - acc: 0.1370 - val_loss: 2.7780 - val_acc: 0.1228\n",
            "Epoch 102/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.9944 - acc: 0.1483 - val_loss: 2.7459 - val_acc: 0.1164\n",
            "Epoch 103/400\n",
            "89/89 [==============================] - 69s 750ms/step - loss: 3.0385 - acc: 0.1292 - val_loss: 2.7527 - val_acc: 0.1142\n",
            "Epoch 104/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.9796 - acc: 0.1618 - val_loss: 2.7621 - val_acc: 0.1142\n",
            "Epoch 105/400\n",
            "89/89 [==============================] - 74s 810ms/step - loss: 2.9860 - acc: 0.1391 - val_loss: 2.7429 - val_acc: 0.1185\n",
            "Epoch 106/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 3.0161 - acc: 0.1654 - val_loss: 2.7484 - val_acc: 0.1164\n",
            "Epoch 107/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.9937 - acc: 0.1490 - val_loss: 2.7503 - val_acc: 0.1185\n",
            "Epoch 108/400\n",
            "89/89 [==============================] - 68s 746ms/step - loss: 3.0334 - acc: 0.1377 - val_loss: 2.7503 - val_acc: 0.1228\n",
            "Epoch 109/400\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 3.0390 - acc: 0.1263 - val_loss: 2.7593 - val_acc: 0.1164\n",
            "Epoch 110/400\n",
            "89/89 [==============================] - 69s 749ms/step - loss: 3.0404 - acc: 0.1391 - val_loss: 2.7454 - val_acc: 0.1207\n",
            "Epoch 111/400\n",
            "89/89 [==============================] - 68s 748ms/step - loss: 2.9711 - acc: 0.1554 - val_loss: 2.7512 - val_acc: 0.1185\n",
            "Epoch 112/400\n",
            "89/89 [==============================] - 70s 764ms/step - loss: 3.0034 - acc: 0.1398 - val_loss: 2.7563 - val_acc: 0.1272\n",
            "Epoch 113/400\n",
            "89/89 [==============================] - 71s 753ms/step - loss: 3.0251 - acc: 0.1455 - val_loss: 2.7442 - val_acc: 0.1228\n",
            "Epoch 114/400\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.9566 - acc: 0.1519 - val_loss: 2.7512 - val_acc: 0.1272\n",
            "Epoch 115/400\n",
            "89/89 [==============================] - 70s 761ms/step - loss: 2.9882 - acc: 0.1419 - val_loss: 2.7318 - val_acc: 0.1272\n",
            "Epoch 116/400\n",
            "89/89 [==============================] - 74s 806ms/step - loss: 3.0326 - acc: 0.1377 - val_loss: 2.7470 - val_acc: 0.1272\n",
            "Epoch 117/400\n",
            "89/89 [==============================] - 69s 757ms/step - loss: 2.9793 - acc: 0.1405 - val_loss: 2.7479 - val_acc: 0.1250\n",
            "Epoch 118/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 3.0044 - acc: 0.1462 - val_loss: 2.7594 - val_acc: 0.1164\n",
            "Epoch 119/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.9890 - acc: 0.1370 - val_loss: 2.7499 - val_acc: 0.1250\n",
            "Epoch 120/400\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.9779 - acc: 0.1370 - val_loss: 2.7414 - val_acc: 0.1207\n",
            "Epoch 121/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.9822 - acc: 0.1469 - val_loss: 2.7360 - val_acc: 0.1272\n",
            "Epoch 122/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 3.0018 - acc: 0.1391 - val_loss: 2.7387 - val_acc: 0.1228\n",
            "Epoch 123/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 2.9373 - acc: 0.1540 - val_loss: 2.7370 - val_acc: 0.1228\n",
            "Epoch 124/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.9985 - acc: 0.1363 - val_loss: 2.7410 - val_acc: 0.1272\n",
            "Epoch 125/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.9120 - acc: 0.1661 - val_loss: 2.7237 - val_acc: 0.1379\n",
            "Epoch 126/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.9920 - acc: 0.1391 - val_loss: 2.7338 - val_acc: 0.1336\n",
            "Epoch 127/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 2.9421 - acc: 0.1434 - val_loss: 2.7378 - val_acc: 0.1315\n",
            "Epoch 128/400\n",
            "89/89 [==============================] - 70s 764ms/step - loss: 2.9858 - acc: 0.1468 - val_loss: 2.7236 - val_acc: 0.1272\n",
            "Epoch 129/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.9888 - acc: 0.1512 - val_loss: 2.7506 - val_acc: 0.1315\n",
            "Epoch 130/400\n",
            "89/89 [==============================] - 69s 759ms/step - loss: 2.9484 - acc: 0.1441 - val_loss: 2.7376 - val_acc: 0.1358\n",
            "Epoch 131/400\n",
            "89/89 [==============================] - 71s 777ms/step - loss: 2.9710 - acc: 0.1512 - val_loss: 2.7281 - val_acc: 0.1293\n",
            "Epoch 132/400\n",
            "89/89 [==============================] - 74s 783ms/step - loss: 2.9346 - acc: 0.1519 - val_loss: 2.7223 - val_acc: 0.1315\n",
            "Epoch 133/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 2.8929 - acc: 0.1576 - val_loss: 2.7074 - val_acc: 0.1336\n",
            "Epoch 134/400\n",
            "89/89 [==============================] - 70s 759ms/step - loss: 2.9544 - acc: 0.1405 - val_loss: 2.7234 - val_acc: 0.1315\n",
            "Epoch 135/400\n",
            "89/89 [==============================] - 76s 823ms/step - loss: 2.9662 - acc: 0.1356 - val_loss: 2.7308 - val_acc: 0.1358\n",
            "Epoch 136/400\n",
            "89/89 [==============================] - 70s 766ms/step - loss: 2.9104 - acc: 0.1739 - val_loss: 2.7380 - val_acc: 0.1336\n",
            "Epoch 137/400\n",
            "89/89 [==============================] - 70s 763ms/step - loss: 2.9811 - acc: 0.1370 - val_loss: 2.7205 - val_acc: 0.1250\n",
            "Epoch 138/400\n",
            "89/89 [==============================] - 69s 758ms/step - loss: 2.9417 - acc: 0.1590 - val_loss: 2.7165 - val_acc: 0.1207\n",
            "Epoch 139/400\n",
            "89/89 [==============================] - 73s 801ms/step - loss: 2.8723 - acc: 0.1611 - val_loss: 2.7432 - val_acc: 0.1358\n",
            "Epoch 140/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.9400 - acc: 0.1505 - val_loss: 2.7484 - val_acc: 0.1336\n",
            "Epoch 141/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.9241 - acc: 0.1568 - val_loss: 2.7279 - val_acc: 0.1336\n",
            "Epoch 142/400\n",
            "89/89 [==============================] - 69s 761ms/step - loss: 2.9301 - acc: 0.1547 - val_loss: 2.7076 - val_acc: 0.1336\n",
            "Epoch 143/400\n",
            "89/89 [==============================] - 77s 846ms/step - loss: 2.8513 - acc: 0.1625 - val_loss: 2.7331 - val_acc: 0.1379\n",
            "Epoch 144/400\n",
            "89/89 [==============================] - 70s 762ms/step - loss: 2.9400 - acc: 0.1547 - val_loss: 2.7193 - val_acc: 0.1358\n",
            "Epoch 145/400\n",
            "89/89 [==============================] - 69s 757ms/step - loss: 2.8325 - acc: 0.1512 - val_loss: 2.7501 - val_acc: 0.1379\n",
            "Epoch 146/400\n",
            "89/89 [==============================] - 69s 759ms/step - loss: 2.8658 - acc: 0.1533 - val_loss: 2.7226 - val_acc: 0.1358\n",
            "Epoch 147/400\n",
            "89/89 [==============================] - 73s 805ms/step - loss: 2.9225 - acc: 0.1618 - val_loss: 2.7294 - val_acc: 0.1336\n",
            "Epoch 148/400\n",
            "89/89 [==============================] - 70s 761ms/step - loss: 2.8904 - acc: 0.1448 - val_loss: 2.7282 - val_acc: 0.1228\n",
            "Epoch 149/400\n",
            "89/89 [==============================] - 69s 759ms/step - loss: 2.8610 - acc: 0.1604 - val_loss: 2.7281 - val_acc: 0.1315\n",
            "Epoch 150/400\n",
            "89/89 [==============================] - 69s 760ms/step - loss: 2.9229 - acc: 0.1427 - val_loss: 2.7373 - val_acc: 0.1336\n",
            "Epoch 151/400\n",
            "89/89 [==============================] - 76s 838ms/step - loss: 2.8904 - acc: 0.1604 - val_loss: 2.7354 - val_acc: 0.1293\n",
            "Epoch 152/400\n",
            "89/89 [==============================] - 69s 758ms/step - loss: 2.8584 - acc: 0.1554 - val_loss: 2.7322 - val_acc: 0.1358\n",
            "Epoch 153/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 2.9048 - acc: 0.1576 - val_loss: 2.7107 - val_acc: 0.1358\n",
            "Epoch 154/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.8342 - acc: 0.1703 - val_loss: 2.7317 - val_acc: 0.1358\n",
            "Epoch 155/400\n",
            "89/89 [==============================] - 73s 803ms/step - loss: 2.9064 - acc: 0.1498 - val_loss: 2.7114 - val_acc: 0.1358\n",
            "Epoch 156/400\n",
            "89/89 [==============================] - 69s 757ms/step - loss: 2.8666 - acc: 0.1547 - val_loss: 2.7126 - val_acc: 0.1379\n",
            "Epoch 157/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 2.8747 - acc: 0.1583 - val_loss: 2.7217 - val_acc: 0.1272\n",
            "Epoch 158/400\n",
            "89/89 [==============================] - 69s 758ms/step - loss: 2.8660 - acc: 0.1490 - val_loss: 2.6924 - val_acc: 0.1466\n",
            "Epoch 159/400\n",
            "89/89 [==============================] - 71s 755ms/step - loss: 2.9288 - acc: 0.1412 - val_loss: 2.7108 - val_acc: 0.1358\n",
            "Epoch 160/400\n",
            "89/89 [==============================] - 69s 759ms/step - loss: 2.8635 - acc: 0.1632 - val_loss: 2.7079 - val_acc: 0.1401\n",
            "Epoch 161/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 2.9030 - acc: 0.1476 - val_loss: 2.7044 - val_acc: 0.1336\n",
            "Epoch 162/400\n",
            "89/89 [==============================] - 69s 757ms/step - loss: 2.9081 - acc: 0.1519 - val_loss: 2.6963 - val_acc: 0.1315\n",
            "Epoch 163/400\n",
            "89/89 [==============================] - 68s 751ms/step - loss: 2.8159 - acc: 0.1625 - val_loss: 2.7479 - val_acc: 0.1379\n",
            "Epoch 164/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 2.8460 - acc: 0.1512 - val_loss: 2.7169 - val_acc: 0.1379\n",
            "Epoch 165/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 2.8745 - acc: 0.1647 - val_loss: 2.7271 - val_acc: 0.1487\n",
            "Epoch 166/400\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.8576 - acc: 0.1604 - val_loss: 2.7130 - val_acc: 0.1401\n",
            "Epoch 167/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 2.8623 - acc: 0.1732 - val_loss: 2.7125 - val_acc: 0.1422\n",
            "Epoch 168/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 2.8051 - acc: 0.1661 - val_loss: 2.7282 - val_acc: 0.1358\n",
            "Epoch 169/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.8141 - acc: 0.1739 - val_loss: 2.7396 - val_acc: 0.1336\n",
            "Epoch 170/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 2.8513 - acc: 0.1519 - val_loss: 2.7244 - val_acc: 0.1422\n",
            "Epoch 171/400\n",
            "89/89 [==============================] - 70s 763ms/step - loss: 2.8674 - acc: 0.1576 - val_loss: 2.7499 - val_acc: 0.1336\n",
            "Epoch 172/400\n",
            "89/89 [==============================] - 70s 760ms/step - loss: 2.8727 - acc: 0.1540 - val_loss: 2.7275 - val_acc: 0.1422\n",
            "Epoch 173/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 2.8593 - acc: 0.1725 - val_loss: 2.7320 - val_acc: 0.1401\n",
            "Epoch 174/400\n",
            "89/89 [==============================] - 78s 853ms/step - loss: 2.8077 - acc: 0.1661 - val_loss: 2.7287 - val_acc: 0.1422\n",
            "Epoch 175/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 2.8860 - acc: 0.1568 - val_loss: 2.7255 - val_acc: 0.1401\n",
            "Epoch 176/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.8283 - acc: 0.1696 - val_loss: 2.7259 - val_acc: 0.1401\n",
            "Epoch 177/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.8617 - acc: 0.1625 - val_loss: 2.7270 - val_acc: 0.1358\n",
            "Epoch 178/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.8333 - acc: 0.1618 - val_loss: 2.7379 - val_acc: 0.1315\n",
            "Epoch 179/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.8481 - acc: 0.1583 - val_loss: 2.7138 - val_acc: 0.1466\n",
            "Epoch 180/400\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.7432 - acc: 0.1789 - val_loss: 2.7056 - val_acc: 0.1444\n",
            "Epoch 181/400\n",
            "89/89 [==============================] - 69s 750ms/step - loss: 2.8386 - acc: 0.1632 - val_loss: 2.7314 - val_acc: 0.1422\n",
            "Epoch 182/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 2.7986 - acc: 0.1611 - val_loss: 2.7078 - val_acc: 0.1487\n",
            "Epoch 183/400\n",
            "89/89 [==============================] - 72s 786ms/step - loss: 2.8620 - acc: 0.1568 - val_loss: 2.7072 - val_acc: 0.1487\n",
            "Epoch 184/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 2.8147 - acc: 0.1796 - val_loss: 2.7109 - val_acc: 0.1401\n",
            "Epoch 185/400\n",
            "89/89 [==============================] - 69s 755ms/step - loss: 2.7379 - acc: 0.1632 - val_loss: 2.7040 - val_acc: 0.1379\n",
            "Epoch 186/400\n",
            "89/89 [==============================] - 69s 759ms/step - loss: 2.7953 - acc: 0.1725 - val_loss: 2.6959 - val_acc: 0.1422\n",
            "Epoch 187/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.7650 - acc: 0.1789 - val_loss: 2.7070 - val_acc: 0.1422\n",
            "Epoch 188/400\n",
            "89/89 [==============================] - 69s 750ms/step - loss: 2.7828 - acc: 0.1753 - val_loss: 2.7000 - val_acc: 0.1466\n",
            "Epoch 189/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.7360 - acc: 0.1831 - val_loss: 2.6979 - val_acc: 0.1509\n",
            "Epoch 190/400\n",
            "89/89 [==============================] - 69s 751ms/step - loss: 2.7880 - acc: 0.1725 - val_loss: 2.7180 - val_acc: 0.1444\n",
            "Epoch 191/400\n",
            "89/89 [==============================] - 72s 792ms/step - loss: 2.7741 - acc: 0.1661 - val_loss: 2.7139 - val_acc: 0.1509\n",
            "Epoch 192/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 2.7578 - acc: 0.1760 - val_loss: 2.7159 - val_acc: 0.1422\n",
            "Epoch 193/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.8421 - acc: 0.1526 - val_loss: 2.6782 - val_acc: 0.1552\n",
            "Epoch 194/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 2.8161 - acc: 0.1774 - val_loss: 2.6937 - val_acc: 0.1509\n",
            "Epoch 195/400\n",
            "89/89 [==============================] - 73s 796ms/step - loss: 2.7598 - acc: 0.1767 - val_loss: 2.6848 - val_acc: 0.1466\n",
            "Epoch 196/400\n",
            "89/89 [==============================] - 69s 750ms/step - loss: 2.7826 - acc: 0.1568 - val_loss: 2.6964 - val_acc: 0.1466\n",
            "Epoch 197/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 2.7517 - acc: 0.1753 - val_loss: 2.6939 - val_acc: 0.1422\n",
            "Epoch 198/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.7748 - acc: 0.1725 - val_loss: 2.7095 - val_acc: 0.1401\n",
            "Epoch 199/400\n",
            "89/89 [==============================] - 72s 793ms/step - loss: 2.7987 - acc: 0.1654 - val_loss: 2.6819 - val_acc: 0.1444\n",
            "Epoch 200/400\n",
            "89/89 [==============================] - 68s 751ms/step - loss: 2.8076 - acc: 0.1632 - val_loss: 2.6834 - val_acc: 0.1573\n",
            "Epoch 201/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.7624 - acc: 0.1781 - val_loss: 2.6771 - val_acc: 0.1509\n",
            "Epoch 202/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 2.7678 - acc: 0.1732 - val_loss: 2.6921 - val_acc: 0.1401\n",
            "Epoch 203/400\n",
            "89/89 [==============================] - 69s 753ms/step - loss: 2.7661 - acc: 0.1874 - val_loss: 2.7033 - val_acc: 0.1509\n",
            "Epoch 204/400\n",
            "89/89 [==============================] - 73s 798ms/step - loss: 2.7758 - acc: 0.1718 - val_loss: 2.7179 - val_acc: 0.1573\n",
            "Epoch 205/400\n",
            "89/89 [==============================] - 69s 756ms/step - loss: 2.7626 - acc: 0.1689 - val_loss: 2.7010 - val_acc: 0.1530\n",
            "Epoch 206/400\n",
            "89/89 [==============================] - 68s 746ms/step - loss: 2.7365 - acc: 0.1824 - val_loss: 2.6919 - val_acc: 0.1487\n",
            "Epoch 207/400\n",
            "89/89 [==============================] - 69s 754ms/step - loss: 2.8134 - acc: 0.1590 - val_loss: 2.6922 - val_acc: 0.1466\n",
            "Epoch 208/400\n",
            "89/89 [==============================] - 69s 760ms/step - loss: 2.7218 - acc: 0.1796 - val_loss: 2.6945 - val_acc: 0.1444\n",
            "Epoch 209/400\n",
            "89/89 [==============================] - 73s 800ms/step - loss: 2.7924 - acc: 0.1718 - val_loss: 2.7165 - val_acc: 0.1466\n",
            "Epoch 210/400\n",
            "89/89 [==============================] - 69s 752ms/step - loss: 2.7514 - acc: 0.1767 - val_loss: 2.7078 - val_acc: 0.1422\n",
            "Epoch 211/400\n",
            "89/89 [==============================] - 69s 758ms/step - loss: 2.8027 - acc: 0.1661 - val_loss: 2.7020 - val_acc: 0.1509\n",
            "Epoch 212/400\n",
            "89/89 [==============================] - 70s 763ms/step - loss: 2.7702 - acc: 0.1718 - val_loss: 2.7093 - val_acc: 0.1444\n",
            "Epoch 213/400\n",
            "89/89 [==============================] - 70s 764ms/step - loss: 2.8133 - acc: 0.1568 - val_loss: 2.6945 - val_acc: 0.1595\n",
            "Epoch 214/400\n",
            "89/89 [==============================] - 74s 812ms/step - loss: 2.7491 - acc: 0.1732 - val_loss: 2.7153 - val_acc: 0.1487\n",
            "Epoch 215/400\n",
            "89/89 [==============================] - 71s 771ms/step - loss: 2.7815 - acc: 0.1639 - val_loss: 2.7094 - val_acc: 0.1466\n",
            "Epoch 216/400\n",
            "61/89 [===================>..........] - ETA: 17s - loss: 2.7406 - acc: 0.2070"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'mo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'mo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3K89-CM-dfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the model\n"
      ],
      "metadata": {
        "id": "R19IJQSYoW7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female125_400.h5')"
      ],
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('./content/drive/My Drive/cut_panoramic/Model/11_รอบแรก_Flimpano_Female_400.h5')"
      ],
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}